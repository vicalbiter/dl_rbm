{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.- Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_sexo</th>\n",
       "      <th>Aedad</th>\n",
       "      <th>AAedad</th>\n",
       "      <th>Apuesto</th>\n",
       "      <th>id_gestud</th>\n",
       "      <th>AIMC</th>\n",
       "      <th>fuma</th>\n",
       "      <th>fuma_act</th>\n",
       "      <th>ejer_act</th>\n",
       "      <th>ejer1</th>\n",
       "      <th>...</th>\n",
       "      <th>locout5</th>\n",
       "      <th>locout10</th>\n",
       "      <th>locout20</th>\n",
       "      <th>locout30</th>\n",
       "      <th>rest_act</th>\n",
       "      <th>rest1</th>\n",
       "      <th>rest5</th>\n",
       "      <th>rest10</th>\n",
       "      <th>rest20</th>\n",
       "      <th>rest30</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dp_folio</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>51</td>\n",
       "      <td>6</td>\n",
       "      <td>Admin</td>\n",
       "      <td>CarTec</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>Sec</td>\n",
       "      <td>Bach</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>Int</td>\n",
       "      <td>Sec</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>63</td>\n",
       "      <td>8</td>\n",
       "      <td>Jef</td>\n",
       "      <td>CarTec</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>EM</td>\n",
       "      <td>Sec</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id_sexo  Aedad  AAedad Apuesto id_gestud  AIMC  fuma  fuma_act  \\\n",
       "dp_folio                                                                  \n",
       "1              F     51       6   Admin    CarTec     4     1         3   \n",
       "2              F     38       4     Sec      Bach     3     2        -1   \n",
       "3              F     34       3     Int       Sec     5     1         1   \n",
       "4              M     63       8     Jef    CarTec     4     2        -1   \n",
       "5              M     42       4      EM       Sec     3     1         2   \n",
       "\n",
       "          ejer_act  ejer1  ...  locout5  locout10  locout20  locout30  \\\n",
       "dp_folio                   ...                                          \n",
       "1                0      2  ...        1         1         1         1   \n",
       "2                0      0  ...        0         0         0         0   \n",
       "3                0      0  ...        1        -1        -1        -1   \n",
       "4                2      2  ...        0         0         0        -1   \n",
       "5                2      2  ...        0         0         0         0   \n",
       "\n",
       "          rest_act  rest1  rest5  rest10  rest20  rest30  \n",
       "dp_folio                                                  \n",
       "1                0      0      0       0       0       0  \n",
       "2                1      3      0       0       0       0  \n",
       "3                0      0      0      -1      -1      -1  \n",
       "4                0      0      0       0       0       0  \n",
       "5                0      0      0       0       0       0  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdata = pd.read_csv('data_histories.csv', index_col=\"dp_folio\")\n",
    "fdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones para clusterizar/discretizar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to clusterize categories of a certain feature, and add the new clusterized feature as a new column\n",
    "# Clusters should be an input of the form {cluster_A: {categories}, cluster_B: [categories]}\n",
    "# Ex. obesity = {0:[1,2,3], 1:[4,5,6]}\n",
    "def clusterizeDiscrete(feature, clusters, new_name, data):\n",
    "    new_data = data.copy()\n",
    "    original_list = data.loc[1:1080, feature]\n",
    "    new_list = []\n",
    "    for index in original_list.index:\n",
    "        cat = False\n",
    "        if original_list[index] == -1 or original_list[index] == \"-1\":\n",
    "            new_list.append(\"N\")\n",
    "            continue\n",
    "        for cluster in clusters:\n",
    "            if original_list[index] in clusters[cluster]:\n",
    "                new_list.append(cluster)\n",
    "                cat = True\n",
    "        if cat == False:\n",
    "            new_list.append(\"N\")\n",
    "    new_data[new_name] = new_list\n",
    "    return new_data\n",
    "\n",
    "# Function to clusterize categories of a certain continous feature, and add the new clusterized feature as a\n",
    "# new column\n",
    "# Clusters shoud be an input of the form {cluster_A: {lambdaFunction1}, cluster_B: lambdaFunction2}\n",
    "def clusterizeContinuous(feature, clusters, new_name, data):\n",
    "    new_data = data.copy()\n",
    "    original_list = data.loc[1:1080, feature]\n",
    "    new_list = []\n",
    "    for index in original_list.index:\n",
    "        if original_list[index] == -1 or original_list[index] == \"-1\":\n",
    "            new_list.append(\"N\")\n",
    "            continue\n",
    "        for cluster in clusters:\n",
    "            if eval(clusters[cluster])(original_list[index]):\n",
    "                new_list.append(cluster)\n",
    "                break\n",
    "    new_data[new_name] = new_list\n",
    "    return new_data\n",
    "        \n",
    "\n",
    "# Set of auxiliary high-order functions that will evaluate the conditions to binarize a history\n",
    "def lessThan(num):\n",
    "    return lambda n: n < num\n",
    "\n",
    "def lessQThan(num):\n",
    "    return lambda n: n <= num\n",
    "\n",
    "def greaterThan(num):\n",
    "    return lambda n: n > num\n",
    "\n",
    "def greaterQThan(num):\n",
    "    return lambda n: n >= num\n",
    "\n",
    "def between(num1, num2):\n",
    "    return lambda n: n <= num2 and n >= num1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición y creación de los clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clusterize between obese and non obese\n",
    "obesity = {0:[1,2,3], 1:[4,5,6]}\n",
    "ndata = clusterizeDiscrete(\"AIMC\", obesity, \"obesity\", fdata)\n",
    "\n",
    "# Clusterize between degrees of study (higher degree vs. non higher degree)\n",
    "degree = {0:[\"Prim\", \"Sec\", \"Bach\", \"CarTec\", \"Otro\"], 1:[\"Lic\", \"Mast\", \"Doc\", \"PDoc\"]}\n",
    "ndata = clusterizeDiscrete(\"id_gestud\", degree, \"hdegree\", ndata)\n",
    "\n",
    "# Clusterize excercise features\n",
    "ejer = {\"A\":\"greaterQThan(2.5)\", \"B\":\"lessThan(2.5)\"}\n",
    "ndata = clusterizeContinuous(\"ejer_act\", ejer, \"ejer0B\", ndata)\n",
    "ndata = clusterizeContinuous(\"ejer1\", ejer, \"ejer1B\", ndata)\n",
    "ndata = clusterizeContinuous(\"ejer5\", ejer, \"ejer5B\", ndata)\n",
    "ndata = clusterizeContinuous(\"ejer10\", ejer, \"ejer10B\", ndata)\n",
    "ndata = clusterizeContinuous(\"ejer20\", ejer, \"ejer20B\", ndata)\n",
    "ndata = clusterizeContinuous(\"ejer30\", ejer, \"ejer30B\", ndata)\n",
    "\n",
    "# Clusterize stress features\n",
    "estres = {\"A\":[4,5], \"B\":[1,2,3]}\n",
    "ndata = clusterizeDiscrete(\"estres_act\", estres, \"estres0B\", ndata)\n",
    "ndata = clusterizeDiscrete(\"estres1\", estres, \"estres1B\", ndata)\n",
    "ndata = clusterizeDiscrete(\"estres5\", estres, \"estres5B\", ndata)\n",
    "ndata = clusterizeDiscrete(\"estres10\", estres, \"estres10B\", ndata)\n",
    "ndata = clusterizeDiscrete(\"estres20\", estres, \"estres20B\", ndata)\n",
    "ndata = clusterizeDiscrete(\"estres30\", estres, \"estres30B\", ndata)\n",
    "\n",
    "# Clusterize weight features\n",
    "peso = {\"A\":[1,2,3], \"B\":[4,5]}\n",
    "ndata = clusterizeDiscrete(\"peso_act\", peso, \"peso0B\", ndata)\n",
    "ndata = clusterizeDiscrete(\"peso1\", peso, \"peso1B\", ndata)\n",
    "ndata = clusterizeDiscrete(\"peso5\", peso, \"peso5B\", ndata)\n",
    "ndata = clusterizeDiscrete(\"peso10\", peso, \"peso10B\", ndata)\n",
    "ndata = clusterizeDiscrete(\"peso20\", peso, \"peso20B\", ndata)\n",
    "ndata = clusterizeDiscrete(\"peso30\", peso, \"peso30B\", ndata)\n",
    "\n",
    "# Clusterize weight features\n",
    "condi = {\"A\":[4,5], \"B\":[1,2,3]}\n",
    "ndata = clusterizeDiscrete(\"condi_act\", condi, \"condi0B\", ndata)\n",
    "ndata = clusterizeDiscrete(\"condi1\", condi, \"condi1B\", ndata)\n",
    "ndata = clusterizeDiscrete(\"condi5\", condi, \"condi5B\", ndata)\n",
    "ndata = clusterizeDiscrete(\"condi10\", condi, \"condi10B\", ndata)\n",
    "ndata = clusterizeDiscrete(\"condi20\", condi, \"condi20B\", ndata)\n",
    "ndata = clusterizeDiscrete(\"condi30\", condi, \"condi30B\", ndata)\n",
    "\n",
    "# Clusterize health features\n",
    "salud = {\"A\":[4,5], \"B\":[1,2,3]}\n",
    "ndata = clusterizeDiscrete(\"salud_act\", salud, \"salud0B\", ndata)\n",
    "ndata = clusterizeDiscrete(\"salud1\", salud, \"salud1B\", ndata)\n",
    "ndata = clusterizeDiscrete(\"salud5\", salud, \"salud5B\", ndata)\n",
    "ndata = clusterizeDiscrete(\"salud10\", salud, \"salud10B\", ndata)\n",
    "ndata = clusterizeDiscrete(\"salud20\", salud, \"salud20B\", ndata)\n",
    "ndata = clusterizeDiscrete(\"salud30\", salud, \"salud30B\", ndata)\n",
    "\n",
    "# Clusterize job features\n",
    "academic = {0:[\"Admin\", \"Asi\", \"Coo\", \"E\", \"ED\", \"EM\", \"Int\", \"Jef\", \"Lab\", \"Sec\", \"Tec\", \"Vig\"], 1:[\"Acade\", \"Inv\", \"InvE\"]}\n",
    "ndata = clusterizeDiscrete(\"Apuesto\", academic, \"academic\", ndata)\n",
    "\n",
    "# Clusterize walking features\n",
    "walking = {\"A\":\"greaterQThan(1800.0)\", \"B\":\"lessThan(1800.0)\"}\n",
    "ndata = clusterizeContinuous(\"dis_dia\", walking, \"dis_dia0B\", ndata)\n",
    "ndata = clusterizeContinuous(\"dis1_dia\", walking, \"dis_dia1B\", ndata)\n",
    "ndata = clusterizeContinuous(\"dis5_dia\", walking, \"dis_dia5B\", ndata)\n",
    "ndata = clusterizeContinuous(\"dis10_dia\", walking, \"dis_dia10B\", ndata)\n",
    "ndata = clusterizeContinuous(\"dis20_dia\", walking, \"dis_dia20B\", ndata)\n",
    "ndata = clusterizeContinuous(\"dis30_dia\", walking, \"dis_dia30B\", ndata)\n",
    "\n",
    "\n",
    "# Clusterize age features\n",
    "age = {0:\"between(15.0, 28.0)\", 1:\"between(28.1, 40.0)\", 2:\"between(40.1, 60.0)\", 3:\"between(60.1, 90.0)\"}\n",
    "ndata = clusterizeContinuous(\"Aedad\", age, \"AedadC\", ndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_sexo</th>\n",
       "      <th>Aedad</th>\n",
       "      <th>AAedad</th>\n",
       "      <th>Apuesto</th>\n",
       "      <th>id_gestud</th>\n",
       "      <th>AIMC</th>\n",
       "      <th>fuma</th>\n",
       "      <th>fuma_act</th>\n",
       "      <th>ejer_act</th>\n",
       "      <th>ejer1</th>\n",
       "      <th>...</th>\n",
       "      <th>salud20B</th>\n",
       "      <th>salud30B</th>\n",
       "      <th>academic</th>\n",
       "      <th>dis_dia0B</th>\n",
       "      <th>dis_dia1B</th>\n",
       "      <th>dis_dia5B</th>\n",
       "      <th>dis_dia10B</th>\n",
       "      <th>dis_dia20B</th>\n",
       "      <th>dis_dia30B</th>\n",
       "      <th>AedadC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dp_folio</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>51</td>\n",
       "      <td>6</td>\n",
       "      <td>Admin</td>\n",
       "      <td>CarTec</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>Sec</td>\n",
       "      <td>Bach</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>Int</td>\n",
       "      <td>Sec</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>63</td>\n",
       "      <td>8</td>\n",
       "      <td>Jef</td>\n",
       "      <td>CarTec</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>EM</td>\n",
       "      <td>Sec</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id_sexo  Aedad  AAedad Apuesto id_gestud  AIMC  fuma  fuma_act  \\\n",
       "dp_folio                                                                  \n",
       "1              F     51       6   Admin    CarTec     4     1         3   \n",
       "2              F     38       4     Sec      Bach     3     2        -1   \n",
       "3              F     34       3     Int       Sec     5     1         1   \n",
       "4              M     63       8     Jef    CarTec     4     2        -1   \n",
       "5              M     42       4      EM       Sec     3     1         2   \n",
       "\n",
       "          ejer_act  ejer1  ...  salud20B  salud30B  academic  dis_dia0B  \\\n",
       "dp_folio                   ...                                            \n",
       "1                0      2  ...         A         A         0          B   \n",
       "2                0      0  ...         A         A         0          A   \n",
       "3                0      0  ...         A         N         0          B   \n",
       "4                2      2  ...         A         A         0          A   \n",
       "5                2      2  ...         N         N         0          B   \n",
       "\n",
       "          dis_dia1B  dis_dia5B  dis_dia10B  dis_dia20B  dis_dia30B  AedadC  \n",
       "dp_folio                                                                    \n",
       "1                 B          A           N           N           N       2  \n",
       "2                 B          B           B           A           B       1  \n",
       "3                 B          B           B           B           B       1  \n",
       "4                 A          A           A           A           A       3  \n",
       "5                 B          B           N           N           N       2  \n",
       "\n",
       "[5 rows x 112 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de la matriz de variables (features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build profile based on excercise, health and stress in the last 0, 1, 5 and 10 years\n",
    "profiles_0_to_10 = ndata[[\"ejer0B\", \"salud0B\", \"estres0B\", \"ejer1B\", \"salud1B\", \"estres1B\", \"ejer5B\", \"salud5B\", \"estres5B\", \"ejer10B\", \"salud10B\", \"estres10B\"]]\n",
    "profiles_1_to_10 = ndata[[\"ejer1B\", \"salud1B\", \"estres1B\", \"ejer1B\", \"salud1B\", \"estres1B\", \"ejer5B\", \"salud5B\", \"estres5B\", \"ejer10B\", \"salud10B\", \"estres10B\"]]\n",
    "\n",
    "# Replace \"A\" with 1, and \"B\" with 0, in order to have binary values, and save this in the feature matrix X\n",
    "X_0 = profiles_0_to_10.replace(\"A\", 1).replace(\"B\", 0).replace(\"N\", 0)\n",
    "X_1 = profiles_1_to_10.replace(\"A\", 1).replace(\"B\", 0).replace(\"N\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ejer0B</th>\n",
       "      <th>salud0B</th>\n",
       "      <th>estres0B</th>\n",
       "      <th>ejer1B</th>\n",
       "      <th>salud1B</th>\n",
       "      <th>estres1B</th>\n",
       "      <th>ejer5B</th>\n",
       "      <th>salud5B</th>\n",
       "      <th>estres5B</th>\n",
       "      <th>ejer10B</th>\n",
       "      <th>salud10B</th>\n",
       "      <th>estres10B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dp_folio</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ejer0B  salud0B  estres0B  ejer1B  salud1B  estres1B  ejer5B  \\\n",
       "dp_folio                                                                 \n",
       "1              0        1         1       0        1         0       0   \n",
       "2              0        1         0       0        1         0       1   \n",
       "3              0        0         1       0        0         1       0   \n",
       "4              0        1         0       0        1         1       1   \n",
       "5              0        1         0       0        1         0       0   \n",
       "\n",
       "          salud5B  estres5B  ejer10B  salud10B  estres10B  \n",
       "dp_folio                                                   \n",
       "1               1         1        0         1          0  \n",
       "2               0         1        1         1          0  \n",
       "3               1         1        1         1          1  \n",
       "4               1         0        1         1          0  \n",
       "5               0         0        0         0          1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.- RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function to split a set between batches\n",
    "def batch_iterator(X, y=None, batch_size=64):\n",
    "    n_samples = X.shape[0]\n",
    "    for i in np.arange(0, n_samples, batch_size):\n",
    "        begin, end = i, min(i+batch_size, n_samples)\n",
    "        if y is not None:\n",
    "            yield X[begin:end], y[begin:end]\n",
    "        else:\n",
    "            yield X[begin:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classic Restricted Boltzmann Machine\n",
    "class RBM :\n",
    "    \n",
    "    def __init__(self, num_visible, num_hidden, learning_rate, batch_size, num_epochs):\n",
    "        self.num_visible = num_visible\n",
    "        self.num_hidden = num_hidden\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        \n",
    "        self.W = np.random.normal(scale=0.1, size=(num_visible, num_hidden))\n",
    "        self.a = np.zeros(num_visible)\n",
    "        self.b = np.zeros(num_hidden)\n",
    "    \n",
    "    # Calculate the sigmoid of X \n",
    "    def sigmoid(self, X):\n",
    "        return 1 / (1 + np.exp(-1*X))\n",
    "    \n",
    "    # Sample the activations given a certain matrix of probabilities\n",
    "    def sample(self, X):\n",
    "        return X > np.random.random_sample(size=X.shape)\n",
    "    \n",
    "    # Perform a reconstruction of the input data X\n",
    "    def gibbs_sample(self, X):\n",
    "        # Positive phase: Calculate the activations of the hidden layer\n",
    "        positive_hidden = self.sigmoid(X.dot(self.W) + self.b)\n",
    "        hidden_states = self.sample(positive_hidden)\n",
    "        # Negative phase: Given the activations of the hidden layer, reconstruct the states at the visible layer\n",
    "        negative_visible = self.sigmoid(hidden_states.dot(self.W.T) + self.a)\n",
    "        visible_states = self.sample(negative_visible)\n",
    "        return visible_states\n",
    "    \n",
    "    # Get the hidden probabilities for a certain input\n",
    "    def transform(self, X):\n",
    "        return self.sigmoid(X.dot(self.W) + self.b)\n",
    "    \n",
    "    def train(self, X):\n",
    "        \n",
    "        # Define matrix to keep track of the training MSE\n",
    "        self.training_errors = []\n",
    "        \n",
    "        for epoch in range(self.num_epochs):\n",
    "            \n",
    "            batch_errors = []\n",
    "            \n",
    "            for batch in batch_iterator(X, batch_size=self.batch_size):\n",
    "                # Positive phase: Calculate the activations of the hidden layer\n",
    "                positive_hidden_probs = self.sigmoid(batch.dot(self.W) + self.b)\n",
    "                positive_hidden_states = self.sample(positive_hidden_probs)\n",
    "                \n",
    "                # Calculate vh_data using the positive hidden states activations, rather than their probabilities\n",
    "                # as per Hinton (2010)\n",
    "                vh_data = batch.T.dot(positive_hidden_probs)\n",
    "                \n",
    "                # Negative phase\n",
    "                negative_visible_probs = self.sigmoid(positive_hidden_states.dot(self.W.T) + self.a)\n",
    "                negative_visible_states = self.sample(negative_visible_probs)\n",
    "                negative_hidden_probs = self.sigmoid(negative_visible_states.dot(self.W) + self.b)\n",
    "                negative_hidden_states = self.sample(negative_hidden_probs)\n",
    "                \n",
    "                # Calculate vh_reconstruction using the negative hidden states activations\n",
    "                vh_reconstruction = negative_visible_states.T.dot(negative_hidden_probs)\n",
    "                \n",
    "                # Update weights and biases\n",
    "                self.W += self.learning_rate * (vh_data - vh_reconstruction)\n",
    "                self.b += self.learning_rate * (positive_hidden_probs.sum(axis=0) - negative_hidden_probs.sum(axis=0))\n",
    "                self.a += self.learning_rate * (batch.sum(axis=0) - negative_visible_probs.sum(axis=0))\n",
    "                \n",
    "                batch_errors.append(np.mean((batch - negative_visible_states) ** 2))\n",
    "                                    \n",
    "            self.training_errors.append(np.mean(batch_errors))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm = RBM(12, 100, 0.001, 10, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm.train(X_0.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rbm.training_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 1 0 0 1 1 0 1 0]\n",
      "[0.45563637 0.13447236 0.19599848 0.69979971 0.26675212 0.47944314\n",
      " 0.82066918 0.26620582 0.16830225 0.27615749 0.31852053 0.91182707\n",
      " 0.59581526 0.82594039 0.10816511 0.35821711 0.46560322 0.68274718\n",
      " 0.57748348 0.85117388 0.29124058 0.27504063 0.89311576 0.39435244\n",
      " 0.1252799  0.11534753 0.36626307 0.08998397 0.68530103 0.0843418\n",
      " 0.50107446 0.30758271 0.7537875  0.73723264 0.55508418 0.27650186\n",
      " 0.66677256 0.70901189 0.56133186 0.22978427 0.80693958 0.66646107\n",
      " 0.28614596 0.63995837 0.6086813  0.30599607 0.71330057 0.24803107\n",
      " 0.58190218 0.39482271 0.28608284 0.11921054 0.16616146 0.19904229\n",
      " 0.42260831 0.35844555 0.05254014 0.55746517 0.33025267 0.23706873\n",
      " 0.35378862 0.19924487 0.06199506 0.16720627 0.49220731 0.12386191\n",
      " 0.88646991 0.17999417 0.23698486 0.39055666 0.37432712 0.93181658\n",
      " 0.39689718 0.10958925 0.49049599 0.16214901 0.85866197 0.37485209\n",
      " 0.84195246 0.15480324 0.03382075 0.06092177 0.57670153 0.4019607\n",
      " 0.1326676  0.65488931 0.20044968 0.09708168 0.26526031 0.73409846\n",
      " 0.19504715 0.88165572 0.30702321 0.45691573 0.17171645 0.10674055\n",
      " 0.26946966 0.45058756 0.27884529 0.09654222]\n",
      "[False  True False False  True False  True  True False False  True False]\n"
     ]
    }
   ],
   "source": [
    "print X_0.iloc[0].values\n",
    "print rbm.transform(X_0.iloc[0])\n",
    "print rbm.gibbs_sample(X_0.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.- CRBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional / Temporally Restricted Boltzmann Machine\n",
    "class CRBM :\n",
    "    \n",
    "    def __init__(self, num_visible, num_hidden, num_historic, learning_rate, batch_size, num_epochs):\n",
    "        self.num_visible = num_visible\n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_historic = num_historic\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        \n",
    "        # Initialize weights and biases\n",
    "        self.W = np.random.normal(scale=0.1, size=(num_visible, num_hidden))\n",
    "        self.a = np.zeros(num_visible)\n",
    "        self.b = np.zeros(num_hidden)\n",
    "        \n",
    "        # Initialize autoregreesive parameters\n",
    "        self.A = np.random.normal(scale=0.01, size=(num_visible, num_historic))\n",
    "        self.B = np.random.normal(scale=0.01, size=(num_hidden, num_historic))\n",
    "    \n",
    "    # Calculate the sigmoid of X \n",
    "    def sigmoid(self, X):\n",
    "        return 1 / (1 + np.exp(-1*X))\n",
    "    \n",
    "    # Sample the activations given a certain matrix of probabilities\n",
    "    def sample(self, X):\n",
    "        return X > np.random.random_sample(size=X.shape)\n",
    "    \n",
    "    # Perform a reconstruction of the input data X\n",
    "    def gibbs_sample(self, X):\n",
    "        \n",
    "        # Separate input vector\n",
    "        V = np.array(X.values[:, :3])\n",
    "        H = np.array(X.values[:, 3:])\n",
    "\n",
    "        # Positive phase\n",
    "\n",
    "        # Calculate the contributions from the Historic layer\n",
    "        dinamic_b = self.b + H.dot(self.B.T)\n",
    "\n",
    "        # Calculate the activations of the Hidden layer\n",
    "        positive_hidden = sigmoid(V.dot(self.W) + dinamic_b)\n",
    "        hidden_states = sample(positive_hidden)\n",
    "\n",
    "        # Negative phase\n",
    "\n",
    "        #Calculate the contributions from the Historic layer\n",
    "        dinamic_a = self.a + H.dot(self.A.T)\n",
    "        \n",
    "        # Calculate the activations of the Visible layer\n",
    "        negative_visible = sigmoid(hidden_states.dot(self.W.T) + dinamic_a)\n",
    "        visible_states = sample(negative_visible)\n",
    "        return visible_states\n",
    "    \n",
    "    # Get the hidden probabilities for a certain input\n",
    "    def transform(self, X):\n",
    "        V = np.array(X.values[:, :3])\n",
    "        H = np.array(X.values[:, 3:])\n",
    "        dinamic_b = self.b + H.dot(self.B.T)\n",
    "        return self.sigmoid(X.dot(self.W) + dinamic_b)\n",
    "    \n",
    "    def train(self, X):\n",
    "        \n",
    "        # Define matrix to keep track of the training MSE\n",
    "        self.training_errors = []\n",
    "        \n",
    "        for epoch in range(self.num_epochs):\n",
    "            \n",
    "            batch_errors = []\n",
    "            \n",
    "            for batch in batch_iterator(X, batch_size=self.batch_size):\n",
    "                \n",
    "                # Separate input vector\n",
    "                V = np.array(batch.values[:, :3])\n",
    "                H = np.array(batch.values[:, 3:])\n",
    "                \n",
    "                \n",
    "                # Positive phase\n",
    "                # Calculate the contributions from the Historic layer\n",
    "                dinamic_b = self.b + H.dot(self.B.T)\n",
    "                \n",
    "                # Calculate the activations of the hidden layer\n",
    "                positive_hidden_probs = self.sigmoid(V.dot(self.W) + dinamic_b)\n",
    "                positive_hidden_states = self.sample(positive_hidden_probs)\n",
    "                \n",
    "                # Calculate vh_data using the positive hidden probabilities, rather than their activations\n",
    "                # as per Hinton (2010)\n",
    "                vh_data = V.T.dot(positive_hidden_probs)\n",
    "                \n",
    "                # Calculate vH_data (H: Historic layer)\n",
    "                vH_data = V.T.dot(H)\n",
    "                # Calculate hH_data (H: Historic layer)\n",
    "                hH_data = positive_hidden_states.T.dot(H)\n",
    "                \n",
    "                \n",
    "                \n",
    "                # Negative phase\n",
    "                \n",
    "                # Calculate the contributions from the Historic layer\n",
    "                dinamic_a = self.a + H.dot(self.A.T)\n",
    "                \n",
    "                negative_visible_probs = self.sigmoid(positive_hidden_states.dot(self.W.T) + dinamic_a)\n",
    "                negative_visible_states = self.sample(negative_visible_probs)\n",
    "                negative_hidden_probs = self.sigmoid(negative_visible_states.dot(self.W) + dinamic_b)\n",
    "                negative_hidden_states = self.sample(negative_hidden_probs)\n",
    "                \n",
    "                # Calculate vh_reconstruction using the negative hidden states probabilities\n",
    "                vh_reconstruction = negative_visible_states.T.dot(negative_hidden_probs)\n",
    "                \n",
    "                # Calculate vH_reconstruction (H: Historic layer)\n",
    "                vH_reconstruction = negative_visible_states.T.dot(H)\n",
    "                # Calculate hH_reconstruction (H: Historic layer)\n",
    "                hH_reconstruction = negative_hidden_states.T.dot(H)\n",
    "                \n",
    "                # Update weights and biases\n",
    "                self.W += self.learning_rate * (vh_data - vh_reconstruction)\n",
    "                self.b += self.learning_rate * (positive_hidden_probs.sum(axis=0) - negative_hidden_probs.sum(axis=0))\n",
    "                self.a += self.learning_rate * (V.sum(axis=0) - negative_visible_probs.sum(axis=0))\n",
    "                self.B += self.learning_rate * 0.01 * (hH_data - hH_reconstruction)\n",
    "                self.A += self.learning_rate * 0.01 * (vH_data - vH_reconstruction)\n",
    "                \n",
    "                batch_errors.append(np.mean((V - negative_visible_states) ** 2))\n",
    "            print \"Epoch \" + str(epoch) + \" - MSE: \" + str(np.mean(batch_errors))                        \n",
    "            self.training_errors.append(np.mean(batch_errors))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "crbm = CRBM(3, 100, 9, 0.001, 10, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - MSE: 0.45493827160493827\n",
      "Epoch 1 - MSE: 0.46419753086419746\n",
      "Epoch 2 - MSE: 0.44074074074074077\n",
      "Epoch 3 - MSE: 0.46296296296296297\n",
      "Epoch 4 - MSE: 0.43703703703703706\n",
      "Epoch 5 - MSE: 0.45637860082304516\n",
      "Epoch 6 - MSE: 0.4671810699588476\n",
      "Epoch 7 - MSE: 0.45884773662551437\n",
      "Epoch 8 - MSE: 0.4441358024691358\n",
      "Epoch 9 - MSE: 0.444238683127572\n",
      "Epoch 10 - MSE: 0.4525720164609053\n",
      "Epoch 11 - MSE: 0.4435185185185185\n",
      "Epoch 12 - MSE: 0.4472222222222222\n",
      "Epoch 13 - MSE: 0.4488683127572017\n",
      "Epoch 14 - MSE: 0.45092592592592595\n",
      "Epoch 15 - MSE: 0.44362139917695464\n",
      "Epoch 16 - MSE: 0.4371399176954732\n",
      "Epoch 17 - MSE: 0.43888888888888894\n",
      "Epoch 18 - MSE: 0.4409465020576131\n",
      "Epoch 19 - MSE: 0.45493827160493827\n",
      "Epoch 20 - MSE: 0.4381687242798354\n",
      "Epoch 21 - MSE: 0.46141975308641975\n",
      "Epoch 22 - MSE: 0.4248971193415637\n",
      "Epoch 23 - MSE: 0.4402263374485596\n",
      "Epoch 24 - MSE: 0.45596707818930043\n",
      "Epoch 25 - MSE: 0.44259259259259265\n",
      "Epoch 26 - MSE: 0.4203703703703705\n",
      "Epoch 27 - MSE: 0.4419753086419754\n",
      "Epoch 28 - MSE: 0.4291152263374486\n",
      "Epoch 29 - MSE: 0.4356995884773663\n",
      "Epoch 30 - MSE: 0.45246913580246906\n",
      "Epoch 31 - MSE: 0.42973251028806586\n",
      "Epoch 32 - MSE: 0.43569958847736623\n",
      "Epoch 33 - MSE: 0.44074074074074077\n",
      "Epoch 34 - MSE: 0.44814814814814813\n",
      "Epoch 35 - MSE: 0.434670781893004\n",
      "Epoch 36 - MSE: 0.4310699588477366\n",
      "Epoch 37 - MSE: 0.42510288065843616\n",
      "Epoch 38 - MSE: 0.42530864197530877\n",
      "Epoch 39 - MSE: 0.4302469135802469\n",
      "Epoch 40 - MSE: 0.4244855967078188\n",
      "Epoch 41 - MSE: 0.41831275720164607\n",
      "Epoch 42 - MSE: 0.4198559670781893\n",
      "Epoch 43 - MSE: 0.4193415637860082\n",
      "Epoch 44 - MSE: 0.43014403292181075\n",
      "Epoch 45 - MSE: 0.4502057613168724\n",
      "Epoch 46 - MSE: 0.42376543209876544\n",
      "Epoch 47 - MSE: 0.42839506172839503\n",
      "Epoch 48 - MSE: 0.42222222222222217\n",
      "Epoch 49 - MSE: 0.4231481481481481\n",
      "Epoch 50 - MSE: 0.4405349794238684\n",
      "Epoch 51 - MSE: 0.42181069958847733\n",
      "Epoch 52 - MSE: 0.42222222222222217\n",
      "Epoch 53 - MSE: 0.4020576131687243\n",
      "Epoch 54 - MSE: 0.41522633744855963\n",
      "Epoch 55 - MSE: 0.42355967078189305\n",
      "Epoch 56 - MSE: 0.40267489711934157\n",
      "Epoch 57 - MSE: 0.41316872427983536\n",
      "Epoch 58 - MSE: 0.39609053497942387\n",
      "Epoch 59 - MSE: 0.41954732510288073\n",
      "Epoch 60 - MSE: 0.4204732510288065\n",
      "Epoch 61 - MSE: 0.4173868312757201\n",
      "Epoch 62 - MSE: 0.4059670781893004\n",
      "Epoch 63 - MSE: 0.4320987654320988\n",
      "Epoch 64 - MSE: 0.42119341563786006\n",
      "Epoch 65 - MSE: 0.40648148148148144\n",
      "Epoch 66 - MSE: 0.4059670781893004\n",
      "Epoch 67 - MSE: 0.410082304526749\n",
      "Epoch 68 - MSE: 0.4072016460905349\n",
      "Epoch 69 - MSE: 0.4143004115226337\n",
      "Epoch 70 - MSE: 0.4089506172839506\n",
      "Epoch 71 - MSE: 0.4031893004115227\n",
      "Epoch 72 - MSE: 0.396604938271605\n",
      "Epoch 73 - MSE: 0.4198559670781893\n",
      "Epoch 74 - MSE: 0.39372427983539093\n",
      "Epoch 75 - MSE: 0.38724279835390946\n",
      "Epoch 76 - MSE: 0.39691358024691353\n",
      "Epoch 77 - MSE: 0.39629629629629626\n",
      "Epoch 78 - MSE: 0.40133744855967074\n",
      "Epoch 79 - MSE: 0.3912551440329217\n",
      "Epoch 80 - MSE: 0.41234567901234565\n",
      "Epoch 81 - MSE: 0.40596707818930045\n",
      "Epoch 82 - MSE: 0.4059670781893004\n",
      "Epoch 83 - MSE: 0.3842592592592593\n",
      "Epoch 84 - MSE: 0.409567901234568\n",
      "Epoch 85 - MSE: 0.40709876543209883\n",
      "Epoch 86 - MSE: 0.39104938271604944\n",
      "Epoch 87 - MSE: 0.40113168724279824\n",
      "Epoch 88 - MSE: 0.39783950617283953\n",
      "Epoch 89 - MSE: 0.37006172839506174\n",
      "Epoch 90 - MSE: 0.3988683127572016\n",
      "Epoch 91 - MSE: 0.3871399176954732\n",
      "Epoch 92 - MSE: 0.3879629629629629\n",
      "Epoch 93 - MSE: 0.3901234567901235\n",
      "Epoch 94 - MSE: 0.3791152263374486\n",
      "Epoch 95 - MSE: 0.39218106995884766\n",
      "Epoch 96 - MSE: 0.39197530864197533\n",
      "Epoch 97 - MSE: 0.4134773662551439\n",
      "Epoch 98 - MSE: 0.398045267489712\n",
      "Epoch 99 - MSE: 0.3887860082304527\n",
      "Epoch 100 - MSE: 0.3832304526748971\n",
      "Epoch 101 - MSE: 0.37304526748971184\n",
      "Epoch 102 - MSE: 0.3887860082304526\n",
      "Epoch 103 - MSE: 0.3824074074074075\n",
      "Epoch 104 - MSE: 0.4056584362139918\n",
      "Epoch 105 - MSE: 0.3921810699588477\n",
      "Epoch 106 - MSE: 0.387037037037037\n",
      "Epoch 107 - MSE: 0.39043209876543217\n",
      "Epoch 108 - MSE: 0.3744855967078189\n",
      "Epoch 109 - MSE: 0.39146090534979416\n",
      "Epoch 110 - MSE: 0.3848765432098765\n",
      "Epoch 111 - MSE: 0.36913580246913574\n",
      "Epoch 112 - MSE: 0.38106995884773665\n",
      "Epoch 113 - MSE: 0.3912551440329218\n",
      "Epoch 114 - MSE: 0.38641975308641974\n",
      "Epoch 115 - MSE: 0.3883744855967078\n",
      "Epoch 116 - MSE: 0.3779835390946502\n",
      "Epoch 117 - MSE: 0.3924897119341563\n",
      "Epoch 118 - MSE: 0.39300411522633744\n",
      "Epoch 119 - MSE: 0.39351851851851855\n",
      "Epoch 120 - MSE: 0.39300411522633744\n",
      "Epoch 121 - MSE: 0.36574074074074076\n",
      "Epoch 122 - MSE: 0.3825102880658436\n",
      "Epoch 123 - MSE: 0.37561728395061733\n",
      "Epoch 124 - MSE: 0.378395061728395\n",
      "Epoch 125 - MSE: 0.3730452674897119\n",
      "Epoch 126 - MSE: 0.38796296296296295\n",
      "Epoch 127 - MSE: 0.36810699588477364\n",
      "Epoch 128 - MSE: 0.3768518518518519\n",
      "Epoch 129 - MSE: 0.3626543209876544\n",
      "Epoch 130 - MSE: 0.3725308641975308\n",
      "Epoch 131 - MSE: 0.3872427983539094\n",
      "Epoch 132 - MSE: 0.37397119341563784\n",
      "Epoch 133 - MSE: 0.3712962962962964\n",
      "Epoch 134 - MSE: 0.3773662551440329\n",
      "Epoch 135 - MSE: 0.3556584362139917\n",
      "Epoch 136 - MSE: 0.36995884773662546\n",
      "Epoch 137 - MSE: 0.3621399176954732\n",
      "Epoch 138 - MSE: 0.3777777777777779\n",
      "Epoch 139 - MSE: 0.37479423868312756\n",
      "Epoch 140 - MSE: 0.37427983539094645\n",
      "Epoch 141 - MSE: 0.38487654320987663\n",
      "Epoch 142 - MSE: 0.3671810699588477\n",
      "Epoch 143 - MSE: 0.36213991769547327\n",
      "Epoch 144 - MSE: 0.37983539094650204\n",
      "Epoch 145 - MSE: 0.3791152263374485\n",
      "Epoch 146 - MSE: 0.3738683127572016\n",
      "Epoch 147 - MSE: 0.3653292181069958\n",
      "Epoch 148 - MSE: 0.3698559670781893\n",
      "Epoch 149 - MSE: 0.37139917695473246\n",
      "Epoch 150 - MSE: 0.3720164609053498\n",
      "Epoch 151 - MSE: 0.3585390946502056\n",
      "Epoch 152 - MSE: 0.363477366255144\n",
      "Epoch 153 - MSE: 0.3648148148148148\n",
      "Epoch 154 - MSE: 0.37325102880658434\n",
      "Epoch 155 - MSE: 0.3658436213991769\n",
      "Epoch 156 - MSE: 0.3725308641975308\n",
      "Epoch 157 - MSE: 0.35689300411522623\n",
      "Epoch 158 - MSE: 0.3804526748971194\n",
      "Epoch 159 - MSE: 0.3683127572016461\n",
      "Epoch 160 - MSE: 0.3602880658436214\n",
      "Epoch 161 - MSE: 0.3709876543209877\n",
      "Epoch 162 - MSE: 0.3463991769547325\n",
      "Epoch 163 - MSE: 0.3800411522633745\n",
      "Epoch 164 - MSE: 0.3450617283950617\n",
      "Epoch 165 - MSE: 0.3553497942386831\n",
      "Epoch 166 - MSE: 0.3605967078189301\n",
      "Epoch 167 - MSE: 0.3619341563786008\n",
      "Epoch 168 - MSE: 0.36862139917695474\n",
      "Epoch 169 - MSE: 0.3501028806584362\n",
      "Epoch 170 - MSE: 0.3630658436213991\n",
      "Epoch 171 - MSE: 0.3531893004115226\n",
      "Epoch 172 - MSE: 0.3582304526748971\n",
      "Epoch 173 - MSE: 0.35617283950617284\n",
      "Epoch 174 - MSE: 0.3498971193415637\n",
      "Epoch 175 - MSE: 0.3504115226337448\n",
      "Epoch 176 - MSE: 0.3567901234567901\n",
      "Epoch 177 - MSE: 0.3646090534979424\n",
      "Epoch 178 - MSE: 0.3434156378600822\n",
      "Epoch 179 - MSE: 0.3658436213991769\n",
      "Epoch 180 - MSE: 0.3539094650205761\n",
      "Epoch 181 - MSE: 0.35555555555555557\n",
      "Epoch 182 - MSE: 0.35884773662551445\n",
      "Epoch 183 - MSE: 0.3523662551440329\n",
      "Epoch 184 - MSE: 0.353395061728395\n",
      "Epoch 185 - MSE: 0.35586419753086423\n",
      "Epoch 186 - MSE: 0.3570987654320988\n",
      "Epoch 187 - MSE: 0.36738683127572014\n",
      "Epoch 188 - MSE: 0.3567901234567902\n",
      "Epoch 189 - MSE: 0.35401234567901235\n",
      "Epoch 190 - MSE: 0.3687242798353909\n",
      "Epoch 191 - MSE: 0.3516460905349794\n",
      "Epoch 192 - MSE: 0.3674897119341563\n",
      "Epoch 193 - MSE: 0.35452674897119335\n",
      "Epoch 194 - MSE: 0.3497942386831276\n",
      "Epoch 195 - MSE: 0.35751028806584356\n",
      "Epoch 196 - MSE: 0.35102880658436214\n",
      "Epoch 197 - MSE: 0.35812757201646084\n",
      "Epoch 198 - MSE: 0.35699588477366245\n",
      "Epoch 199 - MSE: 0.34351851851851856\n",
      "Epoch 200 - MSE: 0.35401234567901235\n",
      "Epoch 201 - MSE: 0.35102880658436214\n",
      "Epoch 202 - MSE: 0.35730452674897123\n",
      "Epoch 203 - MSE: 0.35390946502057613\n",
      "Epoch 204 - MSE: 0.34773662551440326\n",
      "Epoch 205 - MSE: 0.34053497942386834\n",
      "Epoch 206 - MSE: 0.34753086419753093\n",
      "Epoch 207 - MSE: 0.3553497942386831\n",
      "Epoch 208 - MSE: 0.36224279835390943\n",
      "Epoch 209 - MSE: 0.3478395061728395\n",
      "Epoch 210 - MSE: 0.33868312757201646\n",
      "Epoch 211 - MSE: 0.35452674897119346\n",
      "Epoch 212 - MSE: 0.33919753086419757\n",
      "Epoch 213 - MSE: 0.3540123456790124\n",
      "Epoch 214 - MSE: 0.3485596707818929\n",
      "Epoch 215 - MSE: 0.3455761316872428\n",
      "Epoch 216 - MSE: 0.34938271604938265\n",
      "Epoch 217 - MSE: 0.3388888888888889\n",
      "Epoch 218 - MSE: 0.3530864197530864\n",
      "Epoch 219 - MSE: 0.35658436213991757\n",
      "Epoch 220 - MSE: 0.3627572016460906\n",
      "Epoch 221 - MSE: 0.3310699588477366\n",
      "Epoch 222 - MSE: 0.3611111111111111\n",
      "Epoch 223 - MSE: 0.34619341563786\n",
      "Epoch 224 - MSE: 0.3514403292181069\n",
      "Epoch 225 - MSE: 0.34351851851851856\n",
      "Epoch 226 - MSE: 0.35401234567901235\n",
      "Epoch 227 - MSE: 0.3339506172839506\n",
      "Epoch 228 - MSE: 0.3290123456790124\n",
      "Epoch 229 - MSE: 0.32644032921810695\n",
      "Epoch 230 - MSE: 0.34104938271604934\n",
      "Epoch 231 - MSE: 0.353395061728395\n",
      "Epoch 232 - MSE: 0.3349794238683128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233 - MSE: 0.34475308641975305\n",
      "Epoch 234 - MSE: 0.35390946502057613\n",
      "Epoch 235 - MSE: 0.3128600823045267\n",
      "Epoch 236 - MSE: 0.34670781893004116\n",
      "Epoch 237 - MSE: 0.34259259259259267\n",
      "Epoch 238 - MSE: 0.3457818930041152\n",
      "Epoch 239 - MSE: 0.34382716049382717\n",
      "Epoch 240 - MSE: 0.339917695473251\n",
      "Epoch 241 - MSE: 0.34403292181069955\n",
      "Epoch 242 - MSE: 0.347119341563786\n",
      "Epoch 243 - MSE: 0.34660493827160493\n",
      "Epoch 244 - MSE: 0.3599794238683127\n",
      "Epoch 245 - MSE: 0.3414609053497942\n",
      "Epoch 246 - MSE: 0.34218106995884773\n",
      "Epoch 247 - MSE: 0.3483539094650205\n",
      "Epoch 248 - MSE: 0.3286008230452675\n",
      "Epoch 249 - MSE: 0.3445473251028807\n",
      "Epoch 250 - MSE: 0.3435185185185186\n",
      "Epoch 251 - MSE: 0.3420781893004115\n",
      "Epoch 252 - MSE: 0.34434156378600816\n",
      "Epoch 253 - MSE: 0.33549382716049386\n",
      "Epoch 254 - MSE: 0.3440329218106996\n",
      "Epoch 255 - MSE: 0.35164609053497947\n",
      "Epoch 256 - MSE: 0.33796296296296297\n",
      "Epoch 257 - MSE: 0.33786008230452674\n",
      "Epoch 258 - MSE: 0.35462962962962963\n",
      "Epoch 259 - MSE: 0.3444444444444445\n",
      "Epoch 260 - MSE: 0.337551440329218\n",
      "Epoch 261 - MSE: 0.333641975308642\n",
      "Epoch 262 - MSE: 0.33343621399176954\n",
      "Epoch 263 - MSE: 0.3256172839506173\n",
      "Epoch 264 - MSE: 0.3264403292181069\n",
      "Epoch 265 - MSE: 0.3276748971193416\n",
      "Epoch 266 - MSE: 0.3436213991769546\n",
      "Epoch 267 - MSE: 0.34176954732510284\n",
      "Epoch 268 - MSE: 0.3389917695473251\n",
      "Epoch 269 - MSE: 0.32983539094650205\n",
      "Epoch 270 - MSE: 0.3380658436213991\n",
      "Epoch 271 - MSE: 0.3410493827160494\n",
      "Epoch 272 - MSE: 0.33868312757201635\n",
      "Epoch 273 - MSE: 0.34372427983539094\n",
      "Epoch 274 - MSE: 0.32767489711934156\n",
      "Epoch 275 - MSE: 0.3403292181069958\n",
      "Epoch 276 - MSE: 0.32592592592592595\n",
      "Epoch 277 - MSE: 0.3311728395061728\n",
      "Epoch 278 - MSE: 0.3220164609053498\n",
      "Epoch 279 - MSE: 0.3231481481481482\n",
      "Epoch 280 - MSE: 0.3260288065843621\n",
      "Epoch 281 - MSE: 0.3329218106995884\n",
      "Epoch 282 - MSE: 0.337551440329218\n",
      "Epoch 283 - MSE: 0.33467078189300414\n",
      "Epoch 284 - MSE: 0.34650205761316866\n",
      "Epoch 285 - MSE: 0.34063786008230457\n",
      "Epoch 286 - MSE: 0.32798353909465017\n",
      "Epoch 287 - MSE: 0.32592592592592595\n",
      "Epoch 288 - MSE: 0.32201646090534974\n",
      "Epoch 289 - MSE: 0.32592592592592595\n",
      "Epoch 290 - MSE: 0.3402263374485597\n",
      "Epoch 291 - MSE: 0.34351851851851845\n",
      "Epoch 292 - MSE: 0.321604938271605\n",
      "Epoch 293 - MSE: 0.35370370370370374\n",
      "Epoch 294 - MSE: 0.3372427983539094\n",
      "Epoch 295 - MSE: 0.3175925925925926\n",
      "Epoch 296 - MSE: 0.3253086419753087\n",
      "Epoch 297 - MSE: 0.330761316872428\n",
      "Epoch 298 - MSE: 0.32037037037037036\n",
      "Epoch 299 - MSE: 0.332201646090535\n",
      "Epoch 300 - MSE: 0.34403292181069955\n",
      "Epoch 301 - MSE: 0.35102880658436214\n",
      "Epoch 302 - MSE: 0.33528806584362136\n",
      "Epoch 303 - MSE: 0.3426954732510288\n",
      "Epoch 304 - MSE: 0.3412551440329218\n",
      "Epoch 305 - MSE: 0.32664609053497945\n",
      "Epoch 306 - MSE: 0.3228395061728395\n",
      "Epoch 307 - MSE: 0.31810699588477365\n",
      "Epoch 308 - MSE: 0.3277777777777778\n",
      "Epoch 309 - MSE: 0.33569958847736625\n",
      "Epoch 310 - MSE: 0.3151234567901235\n",
      "Epoch 311 - MSE: 0.32006172839506175\n",
      "Epoch 312 - MSE: 0.32644032921810695\n",
      "Epoch 313 - MSE: 0.3304526748971192\n",
      "Epoch 314 - MSE: 0.332201646090535\n",
      "Epoch 315 - MSE: 0.30761316872427974\n",
      "Epoch 316 - MSE: 0.33086419753086416\n",
      "Epoch 317 - MSE: 0.31522633744855966\n",
      "Epoch 318 - MSE: 0.3273662551440329\n",
      "Epoch 319 - MSE: 0.32818930041152256\n",
      "Epoch 320 - MSE: 0.3195473251028807\n",
      "Epoch 321 - MSE: 0.32222222222222235\n",
      "Epoch 322 - MSE: 0.32211934156378597\n",
      "Epoch 323 - MSE: 0.33220164609053493\n",
      "Epoch 324 - MSE: 0.31841563786008226\n",
      "Epoch 325 - MSE: 0.31790123456790126\n",
      "Epoch 326 - MSE: 0.3246913580246914\n",
      "Epoch 327 - MSE: 0.3162551440329217\n",
      "Epoch 328 - MSE: 0.31635802469135793\n",
      "Epoch 329 - MSE: 0.3153292181069958\n",
      "Epoch 330 - MSE: 0.3078189300411523\n",
      "Epoch 331 - MSE: 0.320679012345679\n",
      "Epoch 332 - MSE: 0.319238683127572\n",
      "Epoch 333 - MSE: 0.31913580246913587\n",
      "Epoch 334 - MSE: 0.3056584362139918\n",
      "Epoch 335 - MSE: 0.31790123456790126\n",
      "Epoch 336 - MSE: 0.3185185185185185\n",
      "Epoch 337 - MSE: 0.3305555555555555\n",
      "Epoch 338 - MSE: 0.32685185185185195\n",
      "Epoch 339 - MSE: 0.3039094650205762\n",
      "Epoch 340 - MSE: 0.32623456790123445\n",
      "Epoch 341 - MSE: 0.3036008230452674\n",
      "Epoch 342 - MSE: 0.31851851851851837\n",
      "Epoch 343 - MSE: 0.3175925925925926\n",
      "Epoch 344 - MSE: 0.3169753086419753\n",
      "Epoch 345 - MSE: 0.3030864197530864\n",
      "Epoch 346 - MSE: 0.32644032921810684\n",
      "Epoch 347 - MSE: 0.30812757201646085\n",
      "Epoch 348 - MSE: 0.3122427983539094\n",
      "Epoch 349 - MSE: 0.314917695473251\n",
      "Epoch 350 - MSE: 0.3286008230452674\n",
      "Epoch 351 - MSE: 0.3186213991769548\n",
      "Epoch 352 - MSE: 0.31131687242798345\n",
      "Epoch 353 - MSE: 0.30185185185185187\n",
      "Epoch 354 - MSE: 0.32181069958847736\n",
      "Epoch 355 - MSE: 0.2996913580246914\n",
      "Epoch 356 - MSE: 0.30442386831275714\n",
      "Epoch 357 - MSE: 0.30360082304526753\n",
      "Epoch 358 - MSE: 0.3199588477366255\n",
      "Epoch 359 - MSE: 0.2970164609053498\n",
      "Epoch 360 - MSE: 0.30514403292181064\n",
      "Epoch 361 - MSE: 0.31790123456790126\n",
      "Epoch 362 - MSE: 0.29413580246913584\n",
      "Epoch 363 - MSE: 0.2954732510288066\n",
      "Epoch 364 - MSE: 0.2916666666666666\n",
      "Epoch 365 - MSE: 0.3111111111111111\n",
      "Epoch 366 - MSE: 0.3102880658436213\n",
      "Epoch 367 - MSE: 0.3112139917695472\n",
      "Epoch 368 - MSE: 0.3181069958847737\n",
      "Epoch 369 - MSE: 0.3004115226337448\n",
      "Epoch 370 - MSE: 0.3029835390946502\n",
      "Epoch 371 - MSE: 0.31481481481481477\n",
      "Epoch 372 - MSE: 0.2978395061728395\n",
      "Epoch 373 - MSE: 0.304835390946502\n",
      "Epoch 374 - MSE: 0.2930041152263374\n",
      "Epoch 375 - MSE: 0.30380658436214\n",
      "Epoch 376 - MSE: 0.31471193415637866\n",
      "Epoch 377 - MSE: 0.31440329218106994\n",
      "Epoch 378 - MSE: 0.2975308641975308\n",
      "Epoch 379 - MSE: 0.3005144032921811\n",
      "Epoch 380 - MSE: 0.2974279835390946\n",
      "Epoch 381 - MSE: 0.2931069958847737\n",
      "Epoch 382 - MSE: 0.29825102880658433\n",
      "Epoch 383 - MSE: 0.2986625514403292\n",
      "Epoch 384 - MSE: 0.2988683127572016\n",
      "Epoch 385 - MSE: 0.2958847736625514\n",
      "Epoch 386 - MSE: 0.28888888888888886\n",
      "Epoch 387 - MSE: 0.3148148148148148\n",
      "Epoch 388 - MSE: 0.31316872427983533\n",
      "Epoch 389 - MSE: 0.2986625514403292\n",
      "Epoch 390 - MSE: 0.3008230452674897\n",
      "Epoch 391 - MSE: 0.2968106995884774\n",
      "Epoch 392 - MSE: 0.2900205761316873\n",
      "Epoch 393 - MSE: 0.30874485596707824\n",
      "Epoch 394 - MSE: 0.3061728395061728\n",
      "Epoch 395 - MSE: 0.29032921810699586\n",
      "Epoch 396 - MSE: 0.3137860082304527\n",
      "Epoch 397 - MSE: 0.2979423868312757\n",
      "Epoch 398 - MSE: 0.2986625514403292\n",
      "Epoch 399 - MSE: 0.2904320987654321\n",
      "Epoch 400 - MSE: 0.270164609053498\n",
      "Epoch 401 - MSE: 0.300514403292181\n",
      "Epoch 402 - MSE: 0.29825102880658433\n",
      "Epoch 403 - MSE: 0.2920781893004115\n",
      "Epoch 404 - MSE: 0.2993827160493827\n",
      "Epoch 405 - MSE: 0.29773662551440333\n",
      "Epoch 406 - MSE: 0.2952674897119341\n",
      "Epoch 407 - MSE: 0.30298353909465014\n",
      "Epoch 408 - MSE: 0.2922839506172839\n",
      "Epoch 409 - MSE: 0.29516460905349795\n",
      "Epoch 410 - MSE: 0.291358024691358\n",
      "Epoch 411 - MSE: 0.29094650205761313\n",
      "Epoch 412 - MSE: 0.29351851851851846\n",
      "Epoch 413 - MSE: 0.2993827160493827\n",
      "Epoch 414 - MSE: 0.2923868312757201\n",
      "Epoch 415 - MSE: 0.3006172839506173\n",
      "Epoch 416 - MSE: 0.27973251028806584\n",
      "Epoch 417 - MSE: 0.28734567901234565\n",
      "Epoch 418 - MSE: 0.287962962962963\n",
      "Epoch 419 - MSE: 0.2974279835390946\n",
      "Epoch 420 - MSE: 0.2885802469135803\n",
      "Epoch 421 - MSE: 0.28672839506172837\n",
      "Epoch 422 - MSE: 0.2866255144032921\n",
      "Epoch 423 - MSE: 0.28816872427983536\n",
      "Epoch 424 - MSE: 0.30318930041152264\n",
      "Epoch 425 - MSE: 0.29269547325102885\n",
      "Epoch 426 - MSE: 0.29259259259259257\n",
      "Epoch 427 - MSE: 0.2960905349794239\n",
      "Epoch 428 - MSE: 0.2911522633744856\n",
      "Epoch 429 - MSE: 0.2887860082304527\n",
      "Epoch 430 - MSE: 0.27788065843621396\n",
      "Epoch 431 - MSE: 0.2960905349794239\n",
      "Epoch 432 - MSE: 0.2828189300411522\n",
      "Epoch 433 - MSE: 0.2994855967078189\n",
      "Epoch 434 - MSE: 0.29094650205761313\n",
      "Epoch 435 - MSE: 0.2832304526748971\n",
      "Epoch 436 - MSE: 0.2725308641975308\n",
      "Epoch 437 - MSE: 0.2733539094650206\n",
      "Epoch 438 - MSE: 0.2752057613168724\n",
      "Epoch 439 - MSE: 0.2772633744855967\n",
      "Epoch 440 - MSE: 0.28775720164609053\n",
      "Epoch 441 - MSE: 0.29248971193415635\n",
      "Epoch 442 - MSE: 0.28641975308641976\n",
      "Epoch 443 - MSE: 0.28858024691358025\n",
      "Epoch 444 - MSE: 0.2766460905349794\n",
      "Epoch 445 - MSE: 0.2780864197530864\n",
      "Epoch 446 - MSE: 0.26985596707818926\n",
      "Epoch 447 - MSE: 0.2809670781893004\n",
      "Epoch 448 - MSE: 0.2758230452674897\n",
      "Epoch 449 - MSE: 0.2972222222222223\n",
      "Epoch 450 - MSE: 0.2852880658436214\n",
      "Epoch 451 - MSE: 0.2781893004115226\n",
      "Epoch 452 - MSE: 0.2814814814814814\n",
      "Epoch 453 - MSE: 0.279320987654321\n",
      "Epoch 454 - MSE: 0.27911522633744856\n",
      "Epoch 455 - MSE: 0.27386831275720164\n",
      "Epoch 456 - MSE: 0.2801440329218107\n",
      "Epoch 457 - MSE: 0.28786008230452675\n",
      "Epoch 458 - MSE: 0.2837448559670782\n",
      "Epoch 459 - MSE: 0.2663580246913581\n",
      "Epoch 460 - MSE: 0.2902263374485597\n",
      "Epoch 461 - MSE: 0.28744855967078187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 462 - MSE: 0.28343621399176955\n",
      "Epoch 463 - MSE: 0.2729423868312757\n",
      "Epoch 464 - MSE: 0.27983539094650206\n",
      "Epoch 465 - MSE: 0.26131687242798357\n",
      "Epoch 466 - MSE: 0.28569958847736626\n",
      "Epoch 467 - MSE: 0.269238683127572\n",
      "Epoch 468 - MSE: 0.2916666666666667\n",
      "Epoch 469 - MSE: 0.275\n",
      "Epoch 470 - MSE: 0.27273662551440325\n",
      "Epoch 471 - MSE: 0.27170781893004115\n",
      "Epoch 472 - MSE: 0.2760288065843622\n",
      "Epoch 473 - MSE: 0.2761316872427983\n",
      "Epoch 474 - MSE: 0.26224279835390946\n",
      "Epoch 475 - MSE: 0.26985596707818926\n",
      "Epoch 476 - MSE: 0.2566872427983539\n",
      "Epoch 477 - MSE: 0.27448559670781886\n",
      "Epoch 478 - MSE: 0.2643004115226337\n",
      "Epoch 479 - MSE: 0.2691358024691358\n",
      "Epoch 480 - MSE: 0.27006172839506176\n",
      "Epoch 481 - MSE: 0.26779835390946505\n",
      "Epoch 482 - MSE: 0.27150205761316876\n",
      "Epoch 483 - MSE: 0.2823045267489712\n",
      "Epoch 484 - MSE: 0.2708847736625514\n",
      "Epoch 485 - MSE: 0.27242798353909464\n",
      "Epoch 486 - MSE: 0.2598765432098765\n",
      "Epoch 487 - MSE: 0.2643004115226337\n",
      "Epoch 488 - MSE: 0.2699588477366255\n",
      "Epoch 489 - MSE: 0.2683127572016461\n",
      "Epoch 490 - MSE: 0.25246913580246916\n",
      "Epoch 491 - MSE: 0.2664609053497942\n",
      "Epoch 492 - MSE: 0.2789094650205761\n",
      "Epoch 493 - MSE: 0.2601851851851852\n",
      "Epoch 494 - MSE: 0.2709876543209877\n",
      "Epoch 495 - MSE: 0.25761316872427986\n",
      "Epoch 496 - MSE: 0.26337448559670784\n",
      "Epoch 497 - MSE: 0.267798353909465\n",
      "Epoch 498 - MSE: 0.2597736625514403\n",
      "Epoch 499 - MSE: 0.27355967078189297\n",
      "Epoch 500 - MSE: 0.27654320987654324\n",
      "Epoch 501 - MSE: 0.2720164609053498\n",
      "Epoch 502 - MSE: 0.2685185185185185\n",
      "Epoch 503 - MSE: 0.27458847736625513\n",
      "Epoch 504 - MSE: 0.26543209876543206\n",
      "Epoch 505 - MSE: 0.2664609053497942\n",
      "Epoch 506 - MSE: 0.25339506172839504\n",
      "Epoch 507 - MSE: 0.2712962962962963\n",
      "Epoch 508 - MSE: 0.27078189300411526\n",
      "Epoch 509 - MSE: 0.252880658436214\n",
      "Epoch 510 - MSE: 0.2697530864197531\n",
      "Epoch 511 - MSE: 0.2600823045267489\n",
      "Epoch 512 - MSE: 0.2522633744855967\n",
      "Epoch 513 - MSE: 0.26131687242798357\n",
      "Epoch 514 - MSE: 0.255761316872428\n",
      "Epoch 515 - MSE: 0.2617283950617284\n",
      "Epoch 516 - MSE: 0.2541152263374486\n",
      "Epoch 517 - MSE: 0.24958847736625514\n",
      "Epoch 518 - MSE: 0.2716049382716049\n",
      "Epoch 519 - MSE: 0.25967078189300413\n",
      "Epoch 520 - MSE: 0.2637860082304527\n",
      "Epoch 521 - MSE: 0.2654320987654321\n",
      "Epoch 522 - MSE: 0.24639917695473254\n",
      "Epoch 523 - MSE: 0.2630658436213992\n",
      "Epoch 524 - MSE: 0.2671810699588477\n",
      "Epoch 525 - MSE: 0.26213991769547323\n",
      "Epoch 526 - MSE: 0.25946502057613163\n",
      "Epoch 527 - MSE: 0.26224279835390946\n",
      "Epoch 528 - MSE: 0.26121399176954735\n",
      "Epoch 529 - MSE: 0.25318930041152266\n",
      "Epoch 530 - MSE: 0.2498971193415638\n",
      "Epoch 531 - MSE: 0.25452674897119343\n",
      "Epoch 532 - MSE: 0.265843621399177\n",
      "Epoch 533 - MSE: 0.25946502057613163\n",
      "Epoch 534 - MSE: 0.2532921810699588\n",
      "Epoch 535 - MSE: 0.2424897119341564\n",
      "Epoch 536 - MSE: 0.23806584362139918\n",
      "Epoch 537 - MSE: 0.24650205761316873\n",
      "Epoch 538 - MSE: 0.26810699588477366\n",
      "Epoch 539 - MSE: 0.2420781893004115\n",
      "Epoch 540 - MSE: 0.2541152263374486\n",
      "Epoch 541 - MSE: 0.24897119341563786\n",
      "Epoch 542 - MSE: 0.2530864197530864\n",
      "Epoch 543 - MSE: 0.25390946502057615\n",
      "Epoch 544 - MSE: 0.2617283950617284\n",
      "Epoch 545 - MSE: 0.24619341563786012\n",
      "Epoch 546 - MSE: 0.2547325102880658\n",
      "Epoch 547 - MSE: 0.23847736625514404\n",
      "Epoch 548 - MSE: 0.23672839506172835\n",
      "Epoch 549 - MSE: 0.23775720164609057\n",
      "Epoch 550 - MSE: 0.25421810699588476\n",
      "Epoch 551 - MSE: 0.2508230452674897\n",
      "Epoch 552 - MSE: 0.25740740740740736\n",
      "Epoch 553 - MSE: 0.24537037037037038\n",
      "Epoch 554 - MSE: 0.25483539094650204\n",
      "Epoch 555 - MSE: 0.24362139917695474\n",
      "Epoch 556 - MSE: 0.24804526748971192\n",
      "Epoch 557 - MSE: 0.2544238683127572\n",
      "Epoch 558 - MSE: 0.24526748971193418\n",
      "Epoch 559 - MSE: 0.2524691358024691\n",
      "Epoch 560 - MSE: 0.24475308641975316\n",
      "Epoch 561 - MSE: 0.24701646090534982\n",
      "Epoch 562 - MSE: 0.2417695473251029\n",
      "Epoch 563 - MSE: 0.23683127572016463\n",
      "Epoch 564 - MSE: 0.23508230452674897\n",
      "Epoch 565 - MSE: 0.25102880658436216\n",
      "Epoch 566 - MSE: 0.24866255144032923\n",
      "Epoch 567 - MSE: 0.24547325102880657\n",
      "Epoch 568 - MSE: 0.24979423868312758\n",
      "Epoch 569 - MSE: 0.24578189300411524\n",
      "Epoch 570 - MSE: 0.24958847736625517\n",
      "Epoch 571 - MSE: 0.23713991769547327\n",
      "Epoch 572 - MSE: 0.2361111111111111\n",
      "Epoch 573 - MSE: 0.2476337448559671\n",
      "Epoch 574 - MSE: 0.24475308641975305\n",
      "Epoch 575 - MSE: 0.23292181069958848\n",
      "Epoch 576 - MSE: 0.24958847736625514\n",
      "Epoch 577 - MSE: 0.2389917695473251\n",
      "Epoch 578 - MSE: 0.23713991769547324\n",
      "Epoch 579 - MSE: 0.24629629629629626\n",
      "Epoch 580 - MSE: 0.23786008230452677\n",
      "Epoch 581 - MSE: 0.24403292181069955\n",
      "Epoch 582 - MSE: 0.24495884773662552\n",
      "Epoch 583 - MSE: 0.24588477366255138\n",
      "Epoch 584 - MSE: 0.2387860082304527\n",
      "Epoch 585 - MSE: 0.2389917695473251\n",
      "Epoch 586 - MSE: 0.2312757201646091\n",
      "Epoch 587 - MSE: 0.24063786008230453\n",
      "Epoch 588 - MSE: 0.23919753086419757\n",
      "Epoch 589 - MSE: 0.2376543209876543\n",
      "Epoch 590 - MSE: 0.24084362139917695\n",
      "Epoch 591 - MSE: 0.23508230452674897\n",
      "Epoch 592 - MSE: 0.2366255144032922\n",
      "Epoch 593 - MSE: 0.24886831275720164\n",
      "Epoch 594 - MSE: 0.24619341563786007\n",
      "Epoch 595 - MSE: 0.2435185185185185\n",
      "Epoch 596 - MSE: 0.24074074074074073\n",
      "Epoch 597 - MSE: 0.23220164609053498\n",
      "Epoch 598 - MSE: 0.22397119341563787\n",
      "Epoch 599 - MSE: 0.24609053497942388\n",
      "Epoch 600 - MSE: 0.24495884773662552\n",
      "Epoch 601 - MSE: 0.23065843621399176\n",
      "Epoch 602 - MSE: 0.2317901234567901\n",
      "Epoch 603 - MSE: 0.23796296296296296\n",
      "Epoch 604 - MSE: 0.2287037037037037\n",
      "Epoch 605 - MSE: 0.24084362139917695\n",
      "Epoch 606 - MSE: 0.22839506172839505\n",
      "Epoch 607 - MSE: 0.22489711934156378\n",
      "Epoch 608 - MSE: 0.24331275720164605\n",
      "Epoch 609 - MSE: 0.23919753086419757\n",
      "Epoch 610 - MSE: 0.23240740740740742\n",
      "Epoch 611 - MSE: 0.2362139917695473\n",
      "Epoch 612 - MSE: 0.23014403292181068\n",
      "Epoch 613 - MSE: 0.23960905349794234\n",
      "Epoch 614 - MSE: 0.2247942386831276\n",
      "Epoch 615 - MSE: 0.2344650205761317\n",
      "Epoch 616 - MSE: 0.22613168724279833\n",
      "Epoch 617 - MSE: 0.20833333333333334\n",
      "Epoch 618 - MSE: 0.23076131687242804\n",
      "Epoch 619 - MSE: 0.22304526748971196\n",
      "Epoch 620 - MSE: 0.23179012345679015\n",
      "Epoch 621 - MSE: 0.24043209876543212\n",
      "Epoch 622 - MSE: 0.23251028806584362\n",
      "Epoch 623 - MSE: 0.22417695473251026\n",
      "Epoch 624 - MSE: 0.2246913580246914\n",
      "Epoch 625 - MSE: 0.23919753086419757\n",
      "Epoch 626 - MSE: 0.22561728395061736\n",
      "Epoch 627 - MSE: 0.2189300411522634\n",
      "Epoch 628 - MSE: 0.23312757201646092\n",
      "Epoch 629 - MSE: 0.21553497942386832\n",
      "Epoch 630 - MSE: 0.23765432098765432\n",
      "Epoch 631 - MSE: 0.22983539094650204\n",
      "Epoch 632 - MSE: 0.22746913580246916\n",
      "Epoch 633 - MSE: 0.23292181069958848\n",
      "Epoch 634 - MSE: 0.2219135802469136\n",
      "Epoch 635 - MSE: 0.2317901234567901\n",
      "Epoch 636 - MSE: 0.22499999999999998\n",
      "Epoch 637 - MSE: 0.21491769547325107\n",
      "Epoch 638 - MSE: 0.21491769547325107\n",
      "Epoch 639 - MSE: 0.23209876543209876\n",
      "Epoch 640 - MSE: 0.21944444444444447\n",
      "Epoch 641 - MSE: 0.21985596707818933\n",
      "Epoch 642 - MSE: 0.2226337448559671\n",
      "Epoch 643 - MSE: 0.22067901234567908\n",
      "Epoch 644 - MSE: 0.2215020576131687\n",
      "Epoch 645 - MSE: 0.22901234567901232\n",
      "Epoch 646 - MSE: 0.2247942386831276\n",
      "Epoch 647 - MSE: 0.20987654320987653\n",
      "Epoch 648 - MSE: 0.2424897119341564\n",
      "Epoch 649 - MSE: 0.22757201646090539\n",
      "Epoch 650 - MSE: 0.22304526748971193\n",
      "Epoch 651 - MSE: 0.21275720164609055\n",
      "Epoch 652 - MSE: 0.21841563786008233\n",
      "Epoch 653 - MSE: 0.22592592592592592\n",
      "Epoch 654 - MSE: 0.2220164609053498\n",
      "Epoch 655 - MSE: 0.22880658436213994\n",
      "Epoch 656 - MSE: 0.22592592592592595\n",
      "Epoch 657 - MSE: 0.22695473251028805\n",
      "Epoch 658 - MSE: 0.23199588477366254\n",
      "Epoch 659 - MSE: 0.21646090534979423\n",
      "Epoch 660 - MSE: 0.2176954732510288\n",
      "Epoch 661 - MSE: 0.2226337448559671\n",
      "Epoch 662 - MSE: 0.21728395061728398\n",
      "Epoch 663 - MSE: 0.2204732510288066\n",
      "Epoch 664 - MSE: 0.23261316872427984\n",
      "Epoch 665 - MSE: 0.22222222222222227\n",
      "Epoch 666 - MSE: 0.20524691358024688\n",
      "Epoch 667 - MSE: 0.21347736625514407\n",
      "Epoch 668 - MSE: 0.21800411522633745\n",
      "Epoch 669 - MSE: 0.22160493827160496\n",
      "Epoch 670 - MSE: 0.21800411522633747\n",
      "Epoch 671 - MSE: 0.22273662551440332\n",
      "Epoch 672 - MSE: 0.2141975308641975\n",
      "Epoch 673 - MSE: 0.20555555555555557\n",
      "Epoch 674 - MSE: 0.22037037037037036\n",
      "Epoch 675 - MSE: 0.21080246913580247\n",
      "Epoch 676 - MSE: 0.22685185185185186\n",
      "Epoch 677 - MSE: 0.2138888888888889\n",
      "Epoch 678 - MSE: 0.22613168724279836\n",
      "Epoch 679 - MSE: 0.2130658436213992\n",
      "Epoch 680 - MSE: 0.21337448559670785\n",
      "Epoch 681 - MSE: 0.21738683127572014\n",
      "Epoch 682 - MSE: 0.21378600823045263\n",
      "Epoch 683 - MSE: 0.2332304526748971\n",
      "Epoch 684 - MSE: 0.19660493827160497\n",
      "Epoch 685 - MSE: 0.21820987654320984\n",
      "Epoch 686 - MSE: 0.2277777777777778\n",
      "Epoch 687 - MSE: 0.21872427983539092\n",
      "Epoch 688 - MSE: 0.19938271604938276\n",
      "Epoch 689 - MSE: 0.20792181069958848\n",
      "Epoch 690 - MSE: 0.2090534979423868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 691 - MSE: 0.21594650205761315\n",
      "Epoch 692 - MSE: 0.21265432098765433\n",
      "Epoch 693 - MSE: 0.21059670781893003\n",
      "Epoch 694 - MSE: 0.21419753086419752\n",
      "Epoch 695 - MSE: 0.19907407407407407\n",
      "Epoch 696 - MSE: 0.20555555555555557\n",
      "Epoch 697 - MSE: 0.202880658436214\n",
      "Epoch 698 - MSE: 0.2152263374485597\n",
      "Epoch 699 - MSE: 0.21172839506172836\n",
      "Epoch 700 - MSE: 0.21574074074074076\n",
      "Epoch 701 - MSE: 0.20462962962962963\n",
      "Epoch 702 - MSE: 0.19660493827160494\n",
      "Epoch 703 - MSE: 0.20709876543209876\n",
      "Epoch 704 - MSE: 0.20390946502057614\n",
      "Epoch 705 - MSE: 0.20072016460905354\n",
      "Epoch 706 - MSE: 0.20586419753086418\n",
      "Epoch 707 - MSE: 0.2020576131687243\n",
      "Epoch 708 - MSE: 0.20072016460905348\n",
      "Epoch 709 - MSE: 0.2059670781893004\n",
      "Epoch 710 - MSE: 0.2070987654320988\n",
      "Epoch 711 - MSE: 0.2042181069958848\n",
      "Epoch 712 - MSE: 0.20977366255144037\n",
      "Epoch 713 - MSE: 0.2205761316872428\n",
      "Epoch 714 - MSE: 0.21676954732510292\n",
      "Epoch 715 - MSE: 0.19948559670781896\n",
      "Epoch 716 - MSE: 0.20853909465020576\n",
      "Epoch 717 - MSE: 0.20226337448559675\n",
      "Epoch 718 - MSE: 0.19660493827160494\n",
      "Epoch 719 - MSE: 0.19537037037037036\n",
      "Epoch 720 - MSE: 0.192283950617284\n",
      "Epoch 721 - MSE: 0.21810699588477364\n",
      "Epoch 722 - MSE: 0.1998971193415638\n",
      "Epoch 723 - MSE: 0.20020576131687243\n",
      "Epoch 724 - MSE: 0.20524691358024694\n",
      "Epoch 725 - MSE: 0.19773662551440335\n",
      "Epoch 726 - MSE: 0.20668724279835396\n",
      "Epoch 727 - MSE: 0.19927983539094646\n",
      "Epoch 728 - MSE: 0.21059670781893003\n",
      "Epoch 729 - MSE: 0.2073045267489712\n",
      "Epoch 730 - MSE: 0.19197530864197535\n",
      "Epoch 731 - MSE: 0.1946502057613169\n",
      "Epoch 732 - MSE: 0.2034979423868313\n",
      "Epoch 733 - MSE: 0.20174897119341567\n",
      "Epoch 734 - MSE: 0.19557613168724283\n",
      "Epoch 735 - MSE: 0.19660493827160488\n",
      "Epoch 736 - MSE: 0.19475308641975314\n",
      "Epoch 737 - MSE: 0.19969135802469135\n",
      "Epoch 738 - MSE: 0.20226337448559673\n",
      "Epoch 739 - MSE: 0.2063786008230453\n",
      "Epoch 740 - MSE: 0.20884773662551445\n",
      "Epoch 741 - MSE: 0.19423868312757206\n",
      "Epoch 742 - MSE: 0.21069958847736625\n",
      "Epoch 743 - MSE: 0.19804526748971196\n",
      "Epoch 744 - MSE: 0.19362139917695476\n",
      "Epoch 745 - MSE: 0.18240740740740743\n",
      "Epoch 746 - MSE: 0.20504115226337458\n",
      "Epoch 747 - MSE: 0.195679012345679\n",
      "Epoch 748 - MSE: 0.20010288065843623\n",
      "Epoch 749 - MSE: 0.185082304526749\n",
      "Epoch 750 - MSE: 0.2004115226337449\n",
      "Epoch 751 - MSE: 0.17993827160493828\n",
      "Epoch 752 - MSE: 0.20246913580246917\n",
      "Epoch 753 - MSE: 0.20144032921810703\n",
      "Epoch 754 - MSE: 0.18827160493827158\n",
      "Epoch 755 - MSE: 0.207201646090535\n",
      "Epoch 756 - MSE: 0.19753086419753088\n",
      "Epoch 757 - MSE: 0.19897119341563785\n",
      "Epoch 758 - MSE: 0.2036008230452675\n",
      "Epoch 759 - MSE: 0.19156378600823046\n",
      "Epoch 760 - MSE: 0.1880658436213992\n",
      "Epoch 761 - MSE: 0.2019547325102881\n",
      "Epoch 762 - MSE: 0.18858024691358025\n",
      "Epoch 763 - MSE: 0.19022633744855966\n",
      "Epoch 764 - MSE: 0.18960905349794235\n",
      "Epoch 765 - MSE: 0.197119341563786\n",
      "Epoch 766 - MSE: 0.19393004115226342\n",
      "Epoch 767 - MSE: 0.18930041152263377\n",
      "Epoch 768 - MSE: 0.19609053497942386\n",
      "Epoch 769 - MSE: 0.18631687242798353\n",
      "Epoch 770 - MSE: 0.18991769547325105\n",
      "Epoch 771 - MSE: 0.18837448559670786\n",
      "Epoch 772 - MSE: 0.20576131687242802\n",
      "Epoch 773 - MSE: 0.19681069958847738\n",
      "Epoch 774 - MSE: 0.1863168724279836\n",
      "Epoch 775 - MSE: 0.19609053497942389\n",
      "Epoch 776 - MSE: 0.20174897119341562\n",
      "Epoch 777 - MSE: 0.18796296296296297\n",
      "Epoch 778 - MSE: 0.19187242798353912\n",
      "Epoch 779 - MSE: 0.19619341563786008\n",
      "Epoch 780 - MSE: 0.18034979423868314\n",
      "Epoch 781 - MSE: 0.20226337448559675\n",
      "Epoch 782 - MSE: 0.1969135802469136\n",
      "Epoch 783 - MSE: 0.18086419753086422\n",
      "Epoch 784 - MSE: 0.17283950617283952\n",
      "Epoch 785 - MSE: 0.1983539094650206\n",
      "Epoch 786 - MSE: 0.1917695473251029\n",
      "Epoch 787 - MSE: 0.19022633744855966\n",
      "Epoch 788 - MSE: 0.18065843621399175\n",
      "Epoch 789 - MSE: 0.18940329218107\n",
      "Epoch 790 - MSE: 0.186522633744856\n",
      "Epoch 791 - MSE: 0.19372427983539098\n",
      "Epoch 792 - MSE: 0.18004115226337444\n",
      "Epoch 793 - MSE: 0.1962962962962963\n",
      "Epoch 794 - MSE: 0.17489711934156377\n",
      "Epoch 795 - MSE: 0.18816872427983544\n",
      "Epoch 796 - MSE: 0.19701646090534983\n",
      "Epoch 797 - MSE: 0.1980452674897119\n",
      "Epoch 798 - MSE: 0.18497942386831276\n",
      "Epoch 799 - MSE: 0.18528806584362142\n",
      "Epoch 800 - MSE: 0.18724279835390945\n",
      "Epoch 801 - MSE: 0.1844650205761317\n",
      "Epoch 802 - MSE: 0.18189300411522635\n",
      "Epoch 803 - MSE: 0.19320987654320992\n",
      "Epoch 804 - MSE: 0.1824074074074074\n",
      "Epoch 805 - MSE: 0.1800411522633745\n",
      "Epoch 806 - MSE: 0.19475308641975306\n",
      "Epoch 807 - MSE: 0.1874485596707819\n",
      "Epoch 808 - MSE: 0.17983539094650206\n",
      "Epoch 809 - MSE: 0.1786008230452675\n",
      "Epoch 810 - MSE: 0.18909465020576133\n",
      "Epoch 811 - MSE: 0.18981481481481483\n",
      "Epoch 812 - MSE: 0.18168724279835388\n",
      "Epoch 813 - MSE: 0.19125514403292185\n",
      "Epoch 814 - MSE: 0.18487654320987656\n",
      "Epoch 815 - MSE: 0.1827160493827161\n",
      "Epoch 816 - MSE: 0.17901234567901236\n",
      "Epoch 817 - MSE: 0.18436213991769548\n",
      "Epoch 818 - MSE: 0.18220164609053505\n",
      "Epoch 819 - MSE: 0.17788065843621403\n",
      "Epoch 820 - MSE: 0.1955761316872428\n",
      "Epoch 821 - MSE: 0.1872427983539095\n",
      "Epoch 822 - MSE: 0.18374485596707824\n",
      "Epoch 823 - MSE: 0.18878600823045272\n",
      "Epoch 824 - MSE: 0.18652263374485598\n",
      "Epoch 825 - MSE: 0.1782921810699589\n",
      "Epoch 826 - MSE: 0.18374485596707824\n",
      "Epoch 827 - MSE: 0.1777777777777778\n",
      "Epoch 828 - MSE: 0.1862139917695473\n",
      "Epoch 829 - MSE: 0.18230452674897116\n",
      "Epoch 830 - MSE: 0.1799382716049383\n",
      "Epoch 831 - MSE: 0.18117283950617283\n",
      "Epoch 832 - MSE: 0.17345679012345683\n",
      "Epoch 833 - MSE: 0.18220164609053505\n",
      "Epoch 834 - MSE: 0.17798353909465023\n",
      "Epoch 835 - MSE: 0.17983539094650206\n",
      "Epoch 836 - MSE: 0.1828189300411523\n",
      "Epoch 837 - MSE: 0.18508230452674898\n",
      "Epoch 838 - MSE: 0.15720164609053502\n",
      "Epoch 839 - MSE: 0.18816872427983536\n",
      "Epoch 840 - MSE: 0.17304526748971194\n",
      "Epoch 841 - MSE: 0.18055555555555555\n",
      "Epoch 842 - MSE: 0.17767489711934153\n",
      "Epoch 843 - MSE: 0.18106995884773663\n",
      "Epoch 844 - MSE: 0.18034979423868314\n",
      "Epoch 845 - MSE: 0.18261316872427985\n",
      "Epoch 846 - MSE: 0.17849794238683134\n",
      "Epoch 847 - MSE: 0.17530864197530865\n",
      "Epoch 848 - MSE: 0.16882716049382718\n",
      "Epoch 849 - MSE: 0.16707818930041152\n",
      "Epoch 850 - MSE: 0.176440329218107\n",
      "Epoch 851 - MSE: 0.17458847736625513\n",
      "Epoch 852 - MSE: 0.18045267489711936\n",
      "Epoch 853 - MSE: 0.16954732510288067\n",
      "Epoch 854 - MSE: 0.18672839506172842\n",
      "Epoch 855 - MSE: 0.17458847736625516\n",
      "Epoch 856 - MSE: 0.16378600823045272\n",
      "Epoch 857 - MSE: 0.17736625514403292\n",
      "Epoch 858 - MSE: 0.18179012345679016\n",
      "Epoch 859 - MSE: 0.1763374485596708\n",
      "Epoch 860 - MSE: 0.16882716049382718\n",
      "Epoch 861 - MSE: 0.16862139917695473\n",
      "Epoch 862 - MSE: 0.17880658436213995\n",
      "Epoch 863 - MSE: 0.17942386831275722\n",
      "Epoch 864 - MSE: 0.17304526748971197\n",
      "Epoch 865 - MSE: 0.17355967078189302\n",
      "Epoch 866 - MSE: 0.17283950617283955\n",
      "Epoch 867 - MSE: 0.17582304526748976\n",
      "Epoch 868 - MSE: 0.17572016460905357\n",
      "Epoch 869 - MSE: 0.17541152263374488\n",
      "Epoch 870 - MSE: 0.17283950617283952\n",
      "Epoch 871 - MSE: 0.16872427983539098\n",
      "Epoch 872 - MSE: 0.1725308641975309\n",
      "Epoch 873 - MSE: 0.17139917695473253\n",
      "Epoch 874 - MSE: 0.1752057613168725\n",
      "Epoch 875 - MSE: 0.17222222222222228\n",
      "Epoch 876 - MSE: 0.16779835390946504\n",
      "Epoch 877 - MSE: 0.16697530864197535\n",
      "Epoch 878 - MSE: 0.17427983539094655\n",
      "Epoch 879 - MSE: 0.17726337448559668\n",
      "Epoch 880 - MSE: 0.16471193415637858\n",
      "Epoch 881 - MSE: 0.1667695473251029\n",
      "Epoch 882 - MSE: 0.17983539094650208\n",
      "Epoch 883 - MSE: 0.16481481481481483\n",
      "Epoch 884 - MSE: 0.17355967078189302\n",
      "Epoch 885 - MSE: 0.1638888888888889\n",
      "Epoch 886 - MSE: 0.16707818930041154\n",
      "Epoch 887 - MSE: 0.17510288065843624\n",
      "Epoch 888 - MSE: 0.17757201646090534\n",
      "Epoch 889 - MSE: 0.1756172839506173\n",
      "Epoch 890 - MSE: 0.16985596707818928\n",
      "Epoch 891 - MSE: 0.15504115226337448\n",
      "Epoch 892 - MSE: 0.17880658436213995\n",
      "Epoch 893 - MSE: 0.1737654320987655\n",
      "Epoch 894 - MSE: 0.1653292181069959\n",
      "Epoch 895 - MSE: 0.17273662551440333\n",
      "Epoch 896 - MSE: 0.17006172839506173\n",
      "Epoch 897 - MSE: 0.17150205761316875\n",
      "Epoch 898 - MSE: 0.16594650205761316\n",
      "Epoch 899 - MSE: 0.16512345679012347\n",
      "Epoch 900 - MSE: 0.16738683127572015\n",
      "Epoch 901 - MSE: 0.15462962962962964\n",
      "Epoch 902 - MSE: 0.16738683127572018\n",
      "Epoch 903 - MSE: 0.1667695473251029\n",
      "Epoch 904 - MSE: 0.1698559670781893\n",
      "Epoch 905 - MSE: 0.15843621399176958\n",
      "Epoch 906 - MSE: 0.172119341563786\n",
      "Epoch 907 - MSE: 0.16975308641975312\n",
      "Epoch 908 - MSE: 0.16090534979423873\n",
      "Epoch 909 - MSE: 0.1578189300411523\n",
      "Epoch 910 - MSE: 0.16738683127572018\n",
      "Epoch 911 - MSE: 0.16039094650205762\n",
      "Epoch 912 - MSE: 0.17705761316872431\n",
      "Epoch 913 - MSE: 0.170679012345679\n",
      "Epoch 914 - MSE: 0.16646090534979427\n",
      "Epoch 915 - MSE: 0.17613168724279835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 916 - MSE: 0.15329218106995887\n",
      "Epoch 917 - MSE: 0.16954732510288067\n",
      "Epoch 918 - MSE: 0.16059670781893004\n",
      "Epoch 919 - MSE: 0.15761316872427983\n",
      "Epoch 920 - MSE: 0.1580246913580247\n",
      "Epoch 921 - MSE: 0.16872427983539098\n",
      "Epoch 922 - MSE: 0.16419753086419753\n",
      "Epoch 923 - MSE: 0.15802469135802472\n",
      "Epoch 924 - MSE: 0.1740740740740741\n",
      "Epoch 925 - MSE: 0.16162551440329218\n",
      "Epoch 926 - MSE: 0.16851851851851854\n",
      "Epoch 927 - MSE: 0.1637860082304527\n",
      "Epoch 928 - MSE: 0.16316872427983536\n",
      "Epoch 929 - MSE: 0.16543209876543213\n",
      "Epoch 930 - MSE: 0.1668724279835391\n",
      "Epoch 931 - MSE: 0.1609053497942387\n",
      "Epoch 932 - MSE: 0.16718106995884774\n",
      "Epoch 933 - MSE: 0.1551440329218107\n",
      "Epoch 934 - MSE: 0.16851851851851854\n",
      "Epoch 935 - MSE: 0.15987654320987657\n",
      "Epoch 936 - MSE: 0.16512345679012347\n",
      "Epoch 937 - MSE: 0.16172839506172848\n",
      "Epoch 938 - MSE: 0.14794238683127572\n",
      "Epoch 939 - MSE: 0.17294238683127575\n",
      "Epoch 940 - MSE: 0.1564814814814815\n",
      "Epoch 941 - MSE: 0.16069958847736632\n",
      "Epoch 942 - MSE: 0.16141975308641973\n",
      "Epoch 943 - MSE: 0.16769547325102888\n",
      "Epoch 944 - MSE: 0.16152263374485598\n",
      "Epoch 945 - MSE: 0.16141975308641976\n",
      "Epoch 946 - MSE: 0.1551440329218107\n",
      "Epoch 947 - MSE: 0.15987654320987657\n",
      "Epoch 948 - MSE: 0.17530864197530865\n",
      "Epoch 949 - MSE: 0.1561728395061729\n",
      "Epoch 950 - MSE: 0.16532921810699588\n",
      "Epoch 951 - MSE: 0.15627572016460908\n",
      "Epoch 952 - MSE: 0.15720164609053497\n",
      "Epoch 953 - MSE: 0.1666666666666667\n",
      "Epoch 954 - MSE: 0.16697530864197535\n",
      "Epoch 955 - MSE: 0.1534979423868313\n",
      "Epoch 956 - MSE: 0.15288065843621398\n",
      "Epoch 957 - MSE: 0.16584362139917694\n",
      "Epoch 958 - MSE: 0.16625514403292177\n",
      "Epoch 959 - MSE: 0.16286008230452675\n",
      "Epoch 960 - MSE: 0.16831275720164612\n",
      "Epoch 961 - MSE: 0.16584362139917694\n",
      "Epoch 962 - MSE: 0.1581275720164609\n",
      "Epoch 963 - MSE: 0.1502057613168724\n",
      "Epoch 964 - MSE: 0.16286008230452675\n",
      "Epoch 965 - MSE: 0.14958847736625513\n",
      "Epoch 966 - MSE: 0.15843621399176955\n",
      "Epoch 967 - MSE: 0.16347736625514403\n",
      "Epoch 968 - MSE: 0.1610082304526749\n",
      "Epoch 969 - MSE: 0.14835390946502058\n",
      "Epoch 970 - MSE: 0.15689300411522636\n",
      "Epoch 971 - MSE: 0.1558641975308642\n",
      "Epoch 972 - MSE: 0.15833333333333335\n",
      "Epoch 973 - MSE: 0.15751028806584363\n",
      "Epoch 974 - MSE: 0.15092592592592596\n",
      "Epoch 975 - MSE: 0.1472222222222222\n",
      "Epoch 976 - MSE: 0.14207818930041152\n",
      "Epoch 977 - MSE: 0.15257201646090535\n",
      "Epoch 978 - MSE: 0.15041152263374485\n",
      "Epoch 979 - MSE: 0.1597736625514403\n",
      "Epoch 980 - MSE: 0.15740740740740744\n",
      "Epoch 981 - MSE: 0.1577160493827161\n",
      "Epoch 982 - MSE: 0.15730452674897122\n",
      "Epoch 983 - MSE: 0.16522633744855966\n",
      "Epoch 984 - MSE: 0.15751028806584366\n",
      "Epoch 985 - MSE: 0.1521604938271605\n",
      "Epoch 986 - MSE: 0.15390946502057612\n",
      "Epoch 987 - MSE: 0.15205761316872426\n",
      "Epoch 988 - MSE: 0.14979423868312758\n",
      "Epoch 989 - MSE: 0.15236625514403296\n",
      "Epoch 990 - MSE: 0.1627572016460906\n",
      "Epoch 991 - MSE: 0.16584362139917697\n",
      "Epoch 992 - MSE: 0.15195473251028807\n",
      "Epoch 993 - MSE: 0.14701646090534978\n",
      "Epoch 994 - MSE: 0.14670781893004115\n",
      "Epoch 995 - MSE: 0.15709876543209877\n",
      "Epoch 996 - MSE: 0.14979423868312758\n",
      "Epoch 997 - MSE: 0.15997942386831276\n",
      "Epoch 998 - MSE: 0.1533950617283951\n",
      "Epoch 999 - MSE: 0.1529835390946502\n",
      "Epoch 1000 - MSE: 0.14722222222222223\n",
      "Epoch 1001 - MSE: 0.15267489711934157\n",
      "Epoch 1002 - MSE: 0.16203703703703703\n",
      "Epoch 1003 - MSE: 0.14886831275720167\n",
      "Epoch 1004 - MSE: 0.15895061728395063\n",
      "Epoch 1005 - MSE: 0.14927983539094652\n",
      "Epoch 1006 - MSE: 0.15267489711934162\n",
      "Epoch 1007 - MSE: 0.14259259259259258\n",
      "Epoch 1008 - MSE: 0.15174897119341565\n",
      "Epoch 1009 - MSE: 0.1620370370370371\n",
      "Epoch 1010 - MSE: 0.13703703703703704\n",
      "Epoch 1011 - MSE: 0.14619341563786006\n",
      "Epoch 1012 - MSE: 0.1448559670781893\n",
      "Epoch 1013 - MSE: 0.13940329218106995\n",
      "Epoch 1014 - MSE: 0.15493827160493828\n",
      "Epoch 1015 - MSE: 0.14835390946502058\n",
      "Epoch 1016 - MSE: 0.15277777777777782\n",
      "Epoch 1017 - MSE: 0.15174897119341565\n",
      "Epoch 1018 - MSE: 0.13786008230452673\n",
      "Epoch 1019 - MSE: 0.14886831275720167\n",
      "Epoch 1020 - MSE: 0.15658436213991772\n",
      "Epoch 1021 - MSE: 0.14156378600823044\n",
      "Epoch 1022 - MSE: 0.145679012345679\n",
      "Epoch 1023 - MSE: 0.15113168724279835\n",
      "Epoch 1024 - MSE: 0.13888888888888887\n",
      "Epoch 1025 - MSE: 0.1549382716049383\n",
      "Epoch 1026 - MSE: 0.14722222222222223\n",
      "Epoch 1027 - MSE: 0.15195473251028804\n",
      "Epoch 1028 - MSE: 0.1478395061728395\n",
      "Epoch 1029 - MSE: 0.15452674897119345\n",
      "Epoch 1030 - MSE: 0.14794238683127572\n",
      "Epoch 1031 - MSE: 0.14475308641975307\n",
      "Epoch 1032 - MSE: 0.1551440329218107\n",
      "Epoch 1033 - MSE: 0.1478395061728395\n",
      "Epoch 1034 - MSE: 0.14917695473251028\n",
      "Epoch 1035 - MSE: 0.13323045267489708\n",
      "Epoch 1036 - MSE: 0.15092592592592594\n",
      "Epoch 1037 - MSE: 0.16841563786008232\n",
      "Epoch 1038 - MSE: 0.15720164609053497\n",
      "Epoch 1039 - MSE: 0.1309670781893004\n",
      "Epoch 1040 - MSE: 0.15390946502057615\n",
      "Epoch 1041 - MSE: 0.15617283950617283\n",
      "Epoch 1042 - MSE: 0.13559670781893005\n",
      "Epoch 1043 - MSE: 0.14465020576131687\n",
      "Epoch 1044 - MSE: 0.13796296296296295\n",
      "Epoch 1045 - MSE: 0.14578189300411523\n",
      "Epoch 1046 - MSE: 0.15174897119341565\n",
      "Epoch 1047 - MSE: 0.14238683127572016\n",
      "Epoch 1048 - MSE: 0.14454732510288065\n",
      "Epoch 1049 - MSE: 0.14927983539094647\n",
      "Epoch 1050 - MSE: 0.1463991769547325\n",
      "Epoch 1051 - MSE: 0.1498971193415638\n",
      "Epoch 1052 - MSE: 0.14259259259259258\n",
      "Epoch 1053 - MSE: 0.14002057613168722\n",
      "Epoch 1054 - MSE: 0.14187242798353908\n",
      "Epoch 1055 - MSE: 0.1523662551440329\n",
      "Epoch 1056 - MSE: 0.14886831275720164\n",
      "Epoch 1057 - MSE: 0.13261316872427983\n",
      "Epoch 1058 - MSE: 0.14382716049382716\n",
      "Epoch 1059 - MSE: 0.15164609053497943\n",
      "Epoch 1060 - MSE: 0.1512345679012346\n",
      "Epoch 1061 - MSE: 0.1518518518518519\n",
      "Epoch 1062 - MSE: 0.1434156378600823\n",
      "Epoch 1063 - MSE: 0.1362139917695473\n",
      "Epoch 1064 - MSE: 0.13652263374485596\n",
      "Epoch 1065 - MSE: 0.1462962962962963\n",
      "Epoch 1066 - MSE: 0.1344650205761317\n",
      "Epoch 1067 - MSE: 0.1420781893004115\n",
      "Epoch 1068 - MSE: 0.1410493827160494\n",
      "Epoch 1069 - MSE: 0.1390946502057613\n",
      "Epoch 1070 - MSE: 0.14279835390946502\n",
      "Epoch 1071 - MSE: 0.14660493827160492\n",
      "Epoch 1072 - MSE: 0.14465020576131687\n",
      "Epoch 1073 - MSE: 0.1476337448559671\n",
      "Epoch 1074 - MSE: 0.14393004115226338\n",
      "Epoch 1075 - MSE: 0.14238683127572016\n",
      "Epoch 1076 - MSE: 0.14310699588477363\n",
      "Epoch 1077 - MSE: 0.14372427983539093\n",
      "Epoch 1078 - MSE: 0.15010288065843622\n",
      "Epoch 1079 - MSE: 0.1448559670781893\n",
      "Epoch 1080 - MSE: 0.13302469135802467\n",
      "Epoch 1081 - MSE: 0.1479423868312757\n",
      "Epoch 1082 - MSE: 0.13878600823045265\n",
      "Epoch 1083 - MSE: 0.15030864197530866\n",
      "Epoch 1084 - MSE: 0.14279835390946502\n",
      "Epoch 1085 - MSE: 0.13816872427983537\n",
      "Epoch 1086 - MSE: 0.13333333333333333\n",
      "Epoch 1087 - MSE: 0.13323045267489708\n",
      "Epoch 1088 - MSE: 0.13034979423868312\n",
      "Epoch 1089 - MSE: 0.14423868312757204\n",
      "Epoch 1090 - MSE: 0.1410493827160494\n",
      "Epoch 1091 - MSE: 0.13672839506172837\n",
      "Epoch 1092 - MSE: 0.14218106995884772\n",
      "Epoch 1093 - MSE: 0.14187242798353908\n",
      "Epoch 1094 - MSE: 0.13580246913580243\n",
      "Epoch 1095 - MSE: 0.14074074074074072\n",
      "Epoch 1096 - MSE: 0.13930041152263375\n",
      "Epoch 1097 - MSE: 0.1228395061728395\n",
      "Epoch 1098 - MSE: 0.1478395061728395\n",
      "Epoch 1099 - MSE: 0.1506172839506173\n",
      "Epoch 1100 - MSE: 0.1345679012345679\n",
      "Epoch 1101 - MSE: 0.1426954732510288\n",
      "Epoch 1102 - MSE: 0.13518518518518519\n",
      "Epoch 1103 - MSE: 0.138477366255144\n",
      "Epoch 1104 - MSE: 0.1426954732510288\n",
      "Epoch 1105 - MSE: 0.1381687242798354\n",
      "Epoch 1106 - MSE: 0.1338477366255144\n",
      "Epoch 1107 - MSE: 0.13508230452674896\n",
      "Epoch 1108 - MSE: 0.13456790123456788\n",
      "Epoch 1109 - MSE: 0.13724279835390946\n",
      "Epoch 1110 - MSE: 0.14495884773662548\n",
      "Epoch 1111 - MSE: 0.13580246913580246\n",
      "Epoch 1112 - MSE: 0.14002057613168722\n",
      "Epoch 1113 - MSE: 0.12818930041152263\n",
      "Epoch 1114 - MSE: 0.1354938271604938\n",
      "Epoch 1115 - MSE: 0.13960905349794236\n",
      "Epoch 1116 - MSE: 0.145679012345679\n",
      "Epoch 1117 - MSE: 0.1448559670781893\n",
      "Epoch 1118 - MSE: 0.13765432098765432\n",
      "Epoch 1119 - MSE: 0.14084362139917697\n",
      "Epoch 1120 - MSE: 0.13919753086419753\n",
      "Epoch 1121 - MSE: 0.13271604938271603\n",
      "Epoch 1122 - MSE: 0.1388888888888889\n",
      "Epoch 1123 - MSE: 0.13621399176954732\n",
      "Epoch 1124 - MSE: 0.1352880658436214\n",
      "Epoch 1125 - MSE: 0.137037037037037\n",
      "Epoch 1126 - MSE: 0.13796296296296295\n",
      "Epoch 1127 - MSE: 0.14146090534979422\n",
      "Epoch 1128 - MSE: 0.1323045267489712\n",
      "Epoch 1129 - MSE: 0.1383744855967078\n",
      "Epoch 1130 - MSE: 0.13600823045267488\n",
      "Epoch 1131 - MSE: 0.13755144032921812\n",
      "Epoch 1132 - MSE: 0.13734567901234565\n",
      "Epoch 1133 - MSE: 0.13343621399176953\n",
      "Epoch 1134 - MSE: 0.14526748971193412\n",
      "Epoch 1135 - MSE: 0.13137860082304526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1136 - MSE: 0.1347736625514403\n",
      "Epoch 1137 - MSE: 0.13621399176954732\n",
      "Epoch 1138 - MSE: 0.12355967078189299\n",
      "Epoch 1139 - MSE: 0.13220164609053497\n",
      "Epoch 1140 - MSE: 0.1478395061728395\n",
      "Epoch 1141 - MSE: 0.14742798353909464\n",
      "Epoch 1142 - MSE: 0.13425925925925924\n",
      "Epoch 1143 - MSE: 0.12469135802469135\n",
      "Epoch 1144 - MSE: 0.13816872427983537\n",
      "Epoch 1145 - MSE: 0.1353909465020576\n",
      "Epoch 1146 - MSE: 0.12201646090534977\n",
      "Epoch 1147 - MSE: 0.1338477366255144\n",
      "Epoch 1148 - MSE: 0.1241769547325103\n",
      "Epoch 1149 - MSE: 0.12150205761316873\n",
      "Epoch 1150 - MSE: 0.12921810699588476\n",
      "Epoch 1151 - MSE: 0.13724279835390943\n",
      "Epoch 1152 - MSE: 0.1406378600823045\n",
      "Epoch 1153 - MSE: 0.13580246913580246\n",
      "Epoch 1154 - MSE: 0.12983539094650204\n",
      "Epoch 1155 - MSE: 0.13549382716049382\n",
      "Epoch 1156 - MSE: 0.1302469135802469\n",
      "Epoch 1157 - MSE: 0.13292181069958847\n",
      "Epoch 1158 - MSE: 0.13436213991769547\n",
      "Epoch 1159 - MSE: 0.14228395061728394\n",
      "Epoch 1160 - MSE: 0.12685185185185183\n",
      "Epoch 1161 - MSE: 0.12561728395061728\n",
      "Epoch 1162 - MSE: 0.130761316872428\n",
      "Epoch 1163 - MSE: 0.13106995884773665\n",
      "Epoch 1164 - MSE: 0.13713991769547326\n",
      "Epoch 1165 - MSE: 0.13940329218106995\n",
      "Epoch 1166 - MSE: 0.13744855967078187\n",
      "Epoch 1167 - MSE: 0.13786008230452673\n",
      "Epoch 1168 - MSE: 0.1416666666666667\n",
      "Epoch 1169 - MSE: 0.13353909465020575\n",
      "Epoch 1170 - MSE: 0.13199588477366253\n",
      "Epoch 1171 - MSE: 0.1266460905349794\n",
      "Epoch 1172 - MSE: 0.11728395061728393\n",
      "Epoch 1173 - MSE: 0.13405349794238683\n",
      "Epoch 1174 - MSE: 0.1259259259259259\n",
      "Epoch 1175 - MSE: 0.13497942386831274\n",
      "Epoch 1176 - MSE: 0.13343621399176953\n",
      "Epoch 1177 - MSE: 0.12489711934156376\n",
      "Epoch 1178 - MSE: 0.1324074074074074\n",
      "Epoch 1179 - MSE: 0.1353909465020576\n",
      "Epoch 1180 - MSE: 0.11430041152263373\n",
      "Epoch 1181 - MSE: 0.13137860082304528\n",
      "Epoch 1182 - MSE: 0.1325102880658436\n",
      "Epoch 1183 - MSE: 0.1316872427983539\n",
      "Epoch 1184 - MSE: 0.1242798353909465\n",
      "Epoch 1185 - MSE: 0.13796296296296295\n",
      "Epoch 1186 - MSE: 0.12386831275720163\n",
      "Epoch 1187 - MSE: 0.12952674897119343\n",
      "Epoch 1188 - MSE: 0.13528806584362138\n",
      "Epoch 1189 - MSE: 0.1323045267489712\n",
      "Epoch 1190 - MSE: 0.12880658436213993\n",
      "Epoch 1191 - MSE: 0.12541152263374486\n",
      "Epoch 1192 - MSE: 0.1156378600823045\n",
      "Epoch 1193 - MSE: 0.1311728395061728\n",
      "Epoch 1194 - MSE: 0.1369341563786008\n",
      "Epoch 1195 - MSE: 0.1339506172839506\n",
      "Epoch 1196 - MSE: 0.12407407407407406\n",
      "Epoch 1197 - MSE: 0.1286008230452675\n",
      "Epoch 1198 - MSE: 0.13806584362139918\n",
      "Epoch 1199 - MSE: 0.1286008230452675\n",
      "Epoch 1200 - MSE: 0.122119341563786\n",
      "Epoch 1201 - MSE: 0.12479423868312757\n",
      "Epoch 1202 - MSE: 0.12109053497942389\n",
      "Epoch 1203 - MSE: 0.12993827160493826\n",
      "Epoch 1204 - MSE: 0.12911522633744857\n",
      "Epoch 1205 - MSE: 0.1199588477366255\n",
      "Epoch 1206 - MSE: 0.1346707818930041\n",
      "Epoch 1207 - MSE: 0.12427983539094647\n",
      "Epoch 1208 - MSE: 0.12469135802469136\n",
      "Epoch 1209 - MSE: 0.11851851851851851\n",
      "Epoch 1210 - MSE: 0.12489711934156376\n",
      "Epoch 1211 - MSE: 0.13271604938271603\n",
      "Epoch 1212 - MSE: 0.12438271604938272\n",
      "Epoch 1213 - MSE: 0.12530864197530864\n",
      "Epoch 1214 - MSE: 0.13004115226337445\n",
      "Epoch 1215 - MSE: 0.12294238683127572\n",
      "Epoch 1216 - MSE: 0.12695473251028805\n",
      "Epoch 1217 - MSE: 0.13425925925925927\n",
      "Epoch 1218 - MSE: 0.12469135802469135\n",
      "Epoch 1219 - MSE: 0.11944444444444441\n",
      "Epoch 1220 - MSE: 0.12921810699588476\n",
      "Epoch 1221 - MSE: 0.13055555555555556\n",
      "Epoch 1222 - MSE: 0.12942386831275718\n",
      "Epoch 1223 - MSE: 0.1273662551440329\n",
      "Epoch 1224 - MSE: 0.12407407407407406\n",
      "Epoch 1225 - MSE: 0.1309670781893004\n",
      "Epoch 1226 - MSE: 0.12232510288065844\n",
      "Epoch 1227 - MSE: 0.12746913580246913\n",
      "Epoch 1228 - MSE: 0.1256172839506173\n",
      "Epoch 1229 - MSE: 0.13580246913580243\n",
      "Epoch 1230 - MSE: 0.12705761316872427\n",
      "Epoch 1231 - MSE: 0.122119341563786\n",
      "Epoch 1232 - MSE: 0.12932098765432098\n",
      "Epoch 1233 - MSE: 0.12582304526748972\n",
      "Epoch 1234 - MSE: 0.125\n",
      "Epoch 1235 - MSE: 0.13004115226337445\n",
      "Epoch 1236 - MSE: 0.12366255144032921\n",
      "Epoch 1237 - MSE: 0.13137860082304526\n",
      "Epoch 1238 - MSE: 0.12273662551440327\n",
      "Epoch 1239 - MSE: 0.1259259259259259\n",
      "Epoch 1240 - MSE: 0.12098765432098764\n",
      "Epoch 1241 - MSE: 0.12633744855967077\n",
      "Epoch 1242 - MSE: 0.13045267489711931\n",
      "Epoch 1243 - MSE: 0.11903292181069958\n",
      "Epoch 1244 - MSE: 0.12870370370370368\n",
      "Epoch 1245 - MSE: 0.12355967078189299\n",
      "Epoch 1246 - MSE: 0.12088477366255145\n",
      "Epoch 1247 - MSE: 0.11934156378600821\n",
      "Epoch 1248 - MSE: 0.1243827160493827\n",
      "Epoch 1249 - MSE: 0.11440329218106997\n",
      "Epoch 1250 - MSE: 0.11286008230452674\n",
      "Epoch 1251 - MSE: 0.12181069958847736\n",
      "Epoch 1252 - MSE: 0.12006172839506173\n",
      "Epoch 1253 - MSE: 0.13497942386831277\n",
      "Epoch 1254 - MSE: 0.1309670781893004\n",
      "Epoch 1255 - MSE: 0.13148148148148148\n",
      "Epoch 1256 - MSE: 0.11903292181069958\n",
      "Epoch 1257 - MSE: 0.1241769547325103\n",
      "Epoch 1258 - MSE: 0.12818930041152263\n",
      "Epoch 1259 - MSE: 0.13045267489711931\n",
      "Epoch 1260 - MSE: 0.11862139917695472\n",
      "Epoch 1261 - MSE: 0.12088477366255142\n",
      "Epoch 1262 - MSE: 0.11687242798353908\n",
      "Epoch 1263 - MSE: 0.12664609053497944\n",
      "Epoch 1264 - MSE: 0.12458847736625513\n",
      "Epoch 1265 - MSE: 0.1222222222222222\n",
      "Epoch 1266 - MSE: 0.122119341563786\n",
      "Epoch 1267 - MSE: 0.1176954732510288\n",
      "Epoch 1268 - MSE: 0.11954732510288064\n",
      "Epoch 1269 - MSE: 0.11430041152263373\n",
      "Epoch 1270 - MSE: 0.12561728395061728\n",
      "Epoch 1271 - MSE: 0.13076131687242798\n",
      "Epoch 1272 - MSE: 0.11224279835390946\n",
      "Epoch 1273 - MSE: 0.1251028806584362\n",
      "Epoch 1274 - MSE: 0.12109053497942389\n",
      "Epoch 1275 - MSE: 0.127880658436214\n",
      "Epoch 1276 - MSE: 0.11790123456790123\n",
      "Epoch 1277 - MSE: 0.11903292181069958\n",
      "Epoch 1278 - MSE: 0.12386831275720163\n",
      "Epoch 1279 - MSE: 0.11306584362139917\n",
      "Epoch 1280 - MSE: 0.12376543209876542\n",
      "Epoch 1281 - MSE: 0.12160493827160491\n",
      "Epoch 1282 - MSE: 0.1288065843621399\n",
      "Epoch 1283 - MSE: 0.12129629629629628\n",
      "Epoch 1284 - MSE: 0.12160493827160493\n",
      "Epoch 1285 - MSE: 0.11532921810699587\n",
      "Epoch 1286 - MSE: 0.12746913580246913\n",
      "Epoch 1287 - MSE: 0.1039094650205761\n",
      "Epoch 1288 - MSE: 0.12530864197530864\n",
      "Epoch 1289 - MSE: 0.12386831275720163\n",
      "Epoch 1290 - MSE: 0.12757201646090535\n",
      "Epoch 1291 - MSE: 0.12520576131687242\n",
      "Epoch 1292 - MSE: 0.1148148148148148\n",
      "Epoch 1293 - MSE: 0.11738683127572015\n",
      "Epoch 1294 - MSE: 0.13189300411522634\n",
      "Epoch 1295 - MSE: 0.116358024691358\n",
      "Epoch 1296 - MSE: 0.1294238683127572\n",
      "Epoch 1297 - MSE: 0.12890946502057612\n",
      "Epoch 1298 - MSE: 0.12427983539094649\n",
      "Epoch 1299 - MSE: 0.11440329218106997\n",
      "Epoch 1300 - MSE: 0.12242798353909465\n",
      "Epoch 1301 - MSE: 0.12767489711934155\n",
      "Epoch 1302 - MSE: 0.13271604938271603\n",
      "Epoch 1303 - MSE: 0.11358024691358022\n",
      "Epoch 1304 - MSE: 0.10967078189300411\n",
      "Epoch 1305 - MSE: 0.12386831275720163\n",
      "Epoch 1306 - MSE: 0.10895061728395061\n",
      "Epoch 1307 - MSE: 0.10977366255144032\n",
      "Epoch 1308 - MSE: 0.11306584362139915\n",
      "Epoch 1309 - MSE: 0.12427983539094649\n",
      "Epoch 1310 - MSE: 0.12798353909465018\n",
      "Epoch 1311 - MSE: 0.11172839506172838\n",
      "Epoch 1312 - MSE: 0.12170781893004116\n",
      "Epoch 1313 - MSE: 0.12345679012345678\n",
      "Epoch 1314 - MSE: 0.12335390946502058\n",
      "Epoch 1315 - MSE: 0.1279835390946502\n",
      "Epoch 1316 - MSE: 0.10534979423868311\n",
      "Epoch 1317 - MSE: 0.12119341563786008\n",
      "Epoch 1318 - MSE: 0.12026748971193416\n",
      "Epoch 1319 - MSE: 0.11172839506172838\n",
      "Epoch 1320 - MSE: 0.11790123456790123\n",
      "Epoch 1321 - MSE: 0.12232510288065843\n",
      "Epoch 1322 - MSE: 0.1140946502057613\n",
      "Epoch 1323 - MSE: 0.1154320987654321\n",
      "Epoch 1324 - MSE: 0.11759259259259258\n",
      "Epoch 1325 - MSE: 0.12469135802469136\n",
      "Epoch 1326 - MSE: 0.11152263374485595\n",
      "Epoch 1327 - MSE: 0.11584362139917695\n",
      "Epoch 1328 - MSE: 0.12541152263374486\n",
      "Epoch 1329 - MSE: 0.1257201646090535\n",
      "Epoch 1330 - MSE: 0.1154320987654321\n",
      "Epoch 1331 - MSE: 0.11316872427983539\n",
      "Epoch 1332 - MSE: 0.1110082304526749\n",
      "Epoch 1333 - MSE: 0.11244855967078189\n",
      "Epoch 1334 - MSE: 0.11090534979423866\n",
      "Epoch 1335 - MSE: 0.11872427983539094\n",
      "Epoch 1336 - MSE: 0.11244855967078189\n",
      "Epoch 1337 - MSE: 0.11759259259259258\n",
      "Epoch 1338 - MSE: 0.11646090534979422\n",
      "Epoch 1339 - MSE: 0.11378600823045266\n",
      "Epoch 1340 - MSE: 0.1140946502057613\n",
      "Epoch 1341 - MSE: 0.10977366255144032\n",
      "Epoch 1342 - MSE: 0.11069958847736625\n",
      "Epoch 1343 - MSE: 0.10987654320987653\n",
      "Epoch 1344 - MSE: 0.10709876543209874\n",
      "Epoch 1345 - MSE: 0.1263374485596708\n",
      "Epoch 1346 - MSE: 0.11676954732510286\n",
      "Epoch 1347 - MSE: 0.1140946502057613\n",
      "Epoch 1348 - MSE: 0.11491769547325104\n",
      "Epoch 1349 - MSE: 0.11553497942386831\n",
      "Epoch 1350 - MSE: 0.1227366255144033\n",
      "Epoch 1351 - MSE: 0.13065843621399176\n",
      "Epoch 1352 - MSE: 0.11687242798353907\n",
      "Epoch 1353 - MSE: 0.11213991769547327\n",
      "Epoch 1354 - MSE: 0.11707818930041151\n",
      "Epoch 1355 - MSE: 0.11656378600823043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1356 - MSE: 0.11358024691358024\n",
      "Epoch 1357 - MSE: 0.11646090534979424\n",
      "Epoch 1358 - MSE: 0.10174897119341564\n",
      "Epoch 1359 - MSE: 0.11625514403292181\n",
      "Epoch 1360 - MSE: 0.11574074074074074\n",
      "Epoch 1361 - MSE: 0.11162551440329217\n",
      "Epoch 1362 - MSE: 0.10987654320987655\n",
      "Epoch 1363 - MSE: 0.11872427983539095\n",
      "Epoch 1364 - MSE: 0.11522633744855966\n",
      "Epoch 1365 - MSE: 0.11059670781893002\n",
      "Epoch 1366 - MSE: 0.10956790123456789\n",
      "Epoch 1367 - MSE: 0.11841563786008227\n",
      "Epoch 1368 - MSE: 0.11646090534979425\n",
      "Epoch 1369 - MSE: 0.1156378600823045\n",
      "Epoch 1370 - MSE: 0.12160493827160493\n",
      "Epoch 1371 - MSE: 0.11296296296296296\n",
      "Epoch 1372 - MSE: 0.10833333333333332\n",
      "Epoch 1373 - MSE: 0.10905349794238682\n",
      "Epoch 1374 - MSE: 0.11059670781893002\n",
      "Epoch 1375 - MSE: 0.1176954732510288\n",
      "Epoch 1376 - MSE: 0.11347736625514403\n",
      "Epoch 1377 - MSE: 0.11069958847736625\n",
      "Epoch 1378 - MSE: 0.11502057613168723\n",
      "Epoch 1379 - MSE: 0.1090534979423868\n",
      "Epoch 1380 - MSE: 0.10113168724279836\n",
      "Epoch 1381 - MSE: 0.10864197530864196\n",
      "Epoch 1382 - MSE: 0.11121399176954733\n",
      "Epoch 1383 - MSE: 0.11059670781893002\n",
      "Epoch 1384 - MSE: 0.12263374485596706\n",
      "Epoch 1385 - MSE: 0.11893004115226338\n",
      "Epoch 1386 - MSE: 0.10967078189300411\n",
      "Epoch 1387 - MSE: 0.10792181069958848\n",
      "Epoch 1388 - MSE: 0.10781893004115226\n",
      "Epoch 1389 - MSE: 0.11069958847736625\n",
      "Epoch 1390 - MSE: 0.1133744855967078\n",
      "Epoch 1391 - MSE: 0.12397119341563785\n",
      "Epoch 1392 - MSE: 0.1140946502057613\n",
      "Epoch 1393 - MSE: 0.11008230452674897\n",
      "Epoch 1394 - MSE: 0.1155349794238683\n",
      "Epoch 1395 - MSE: 0.10462962962962961\n",
      "Epoch 1396 - MSE: 0.11800411522633744\n",
      "Epoch 1397 - MSE: 0.11316872427983539\n",
      "Epoch 1398 - MSE: 0.11676954732510286\n",
      "Epoch 1399 - MSE: 0.1154320987654321\n",
      "Epoch 1400 - MSE: 0.10041152263374487\n",
      "Epoch 1401 - MSE: 0.11296296296296295\n",
      "Epoch 1402 - MSE: 0.10740740740740741\n",
      "Epoch 1403 - MSE: 0.11347736625514403\n",
      "Epoch 1404 - MSE: 0.11234567901234566\n",
      "Epoch 1405 - MSE: 0.11430041152263373\n",
      "Epoch 1406 - MSE: 0.10833333333333332\n",
      "Epoch 1407 - MSE: 0.10462962962962961\n",
      "Epoch 1408 - MSE: 0.10997942386831275\n",
      "Epoch 1409 - MSE: 0.10946502057613168\n",
      "Epoch 1410 - MSE: 0.11224279835390946\n",
      "Epoch 1411 - MSE: 0.11296296296296295\n",
      "Epoch 1412 - MSE: 0.10833333333333332\n",
      "Epoch 1413 - MSE: 0.10956790123456789\n",
      "Epoch 1414 - MSE: 0.10843621399176955\n",
      "Epoch 1415 - MSE: 0.1104938271604938\n",
      "Epoch 1416 - MSE: 0.10925925925925925\n",
      "Epoch 1417 - MSE: 0.11049382716049382\n",
      "Epoch 1418 - MSE: 0.10987654320987653\n",
      "Epoch 1419 - MSE: 0.10967078189300412\n",
      "Epoch 1420 - MSE: 0.11172839506172838\n",
      "Epoch 1421 - MSE: 0.10462962962962961\n",
      "Epoch 1422 - MSE: 0.10751028806584362\n",
      "Epoch 1423 - MSE: 0.11234567901234566\n",
      "Epoch 1424 - MSE: 0.10576131687242797\n",
      "Epoch 1425 - MSE: 0.1030864197530864\n",
      "Epoch 1426 - MSE: 0.10658436213991769\n",
      "Epoch 1427 - MSE: 0.11584362139917694\n",
      "Epoch 1428 - MSE: 0.11985596707818928\n",
      "Epoch 1429 - MSE: 0.1059670781893004\n",
      "Epoch 1430 - MSE: 0.10514403292181067\n",
      "Epoch 1431 - MSE: 0.11244855967078188\n",
      "Epoch 1432 - MSE: 0.11368312757201646\n",
      "Epoch 1433 - MSE: 0.09886831275720162\n",
      "Epoch 1434 - MSE: 0.09948559670781892\n",
      "Epoch 1435 - MSE: 0.11018518518518518\n",
      "Epoch 1436 - MSE: 0.10462962962962961\n",
      "Epoch 1437 - MSE: 0.10205761316872426\n",
      "Epoch 1438 - MSE: 0.11141975308641976\n",
      "Epoch 1439 - MSE: 0.12098765432098765\n",
      "Epoch 1440 - MSE: 0.1132716049382716\n",
      "Epoch 1441 - MSE: 0.1082304526748971\n",
      "Epoch 1442 - MSE: 0.10720164609053498\n",
      "Epoch 1443 - MSE: 0.10864197530864196\n",
      "Epoch 1444 - MSE: 0.1030864197530864\n",
      "Epoch 1445 - MSE: 0.10288065843621398\n",
      "Epoch 1446 - MSE: 0.10473251028806584\n",
      "Epoch 1447 - MSE: 0.10493827160493824\n",
      "Epoch 1448 - MSE: 0.11491769547325102\n",
      "Epoch 1449 - MSE: 0.11080246913580245\n",
      "Epoch 1450 - MSE: 0.11090534979423869\n",
      "Epoch 1451 - MSE: 0.11234567901234566\n",
      "Epoch 1452 - MSE: 0.10884773662551439\n",
      "Epoch 1453 - MSE: 0.09999999999999999\n",
      "Epoch 1454 - MSE: 0.10792181069958845\n",
      "Epoch 1455 - MSE: 0.10997942386831275\n",
      "Epoch 1456 - MSE: 0.10565843621399174\n",
      "Epoch 1457 - MSE: 0.11255144032921809\n",
      "Epoch 1458 - MSE: 0.10823045267489712\n",
      "Epoch 1459 - MSE: 0.10010288065843619\n",
      "Epoch 1460 - MSE: 0.10905349794238682\n",
      "Epoch 1461 - MSE: 0.10617283950617284\n",
      "Epoch 1462 - MSE: 0.10113168724279833\n",
      "Epoch 1463 - MSE: 0.1059670781893004\n",
      "Epoch 1464 - MSE: 0.10339506172839504\n",
      "Epoch 1465 - MSE: 0.10216049382716047\n",
      "Epoch 1466 - MSE: 0.1037037037037037\n",
      "Epoch 1467 - MSE: 0.09845679012345677\n",
      "Epoch 1468 - MSE: 0.10761316872427983\n",
      "Epoch 1469 - MSE: 0.10339506172839506\n",
      "Epoch 1470 - MSE: 0.10010288065843619\n",
      "Epoch 1471 - MSE: 0.10925925925925925\n",
      "Epoch 1472 - MSE: 0.09670781893004116\n",
      "Epoch 1473 - MSE: 0.11738683127572018\n",
      "Epoch 1474 - MSE: 0.1103909465020576\n",
      "Epoch 1475 - MSE: 0.10205761316872426\n",
      "Epoch 1476 - MSE: 0.11049382716049382\n",
      "Epoch 1477 - MSE: 0.10977366255144032\n",
      "Epoch 1478 - MSE: 0.10606995884773661\n",
      "Epoch 1479 - MSE: 0.10318930041152262\n",
      "Epoch 1480 - MSE: 0.1125514403292181\n",
      "Epoch 1481 - MSE: 0.10843621399176955\n",
      "Epoch 1482 - MSE: 0.10668724279835391\n",
      "Epoch 1483 - MSE: 0.10452674897119339\n",
      "Epoch 1484 - MSE: 0.09660493827160492\n",
      "Epoch 1485 - MSE: 0.10473251028806584\n",
      "Epoch 1486 - MSE: 0.09125514403292179\n",
      "Epoch 1487 - MSE: 0.10884773662551439\n",
      "Epoch 1488 - MSE: 0.09670781893004114\n",
      "Epoch 1489 - MSE: 0.10329218106995884\n",
      "Epoch 1490 - MSE: 0.09907407407407405\n",
      "Epoch 1491 - MSE: 0.10051440329218106\n",
      "Epoch 1492 - MSE: 0.1087448559670782\n",
      "Epoch 1493 - MSE: 0.09958847736625513\n",
      "Epoch 1494 - MSE: 0.10514403292181068\n",
      "Epoch 1495 - MSE: 0.10473251028806584\n",
      "Epoch 1496 - MSE: 0.10617283950617283\n",
      "Epoch 1497 - MSE: 0.10740740740740741\n",
      "Epoch 1498 - MSE: 0.11388888888888887\n",
      "Epoch 1499 - MSE: 0.10709876543209874\n",
      "Epoch 1500 - MSE: 0.11594650205761316\n",
      "Epoch 1501 - MSE: 0.11121399176954733\n",
      "Epoch 1502 - MSE: 0.10257201646090533\n",
      "Epoch 1503 - MSE: 0.11327160493827161\n",
      "Epoch 1504 - MSE: 0.09938271604938269\n",
      "Epoch 1505 - MSE: 0.1066872427983539\n",
      "Epoch 1506 - MSE: 0.10360082304526748\n",
      "Epoch 1507 - MSE: 0.09084362139917693\n",
      "Epoch 1508 - MSE: 0.10874485596707818\n",
      "Epoch 1509 - MSE: 0.09773662551440328\n",
      "Epoch 1510 - MSE: 0.10833333333333331\n",
      "Epoch 1511 - MSE: 0.11265432098765434\n",
      "Epoch 1512 - MSE: 0.10195473251028805\n",
      "Epoch 1513 - MSE: 0.1075102880658436\n",
      "Epoch 1514 - MSE: 0.11018518518518518\n",
      "Epoch 1515 - MSE: 0.10514403292181068\n",
      "Epoch 1516 - MSE: 0.09886831275720162\n",
      "Epoch 1517 - MSE: 0.09660493827160492\n",
      "Epoch 1518 - MSE: 0.1126543209876543\n",
      "Epoch 1519 - MSE: 0.10668724279835391\n",
      "Epoch 1520 - MSE: 0.1015432098765432\n",
      "Epoch 1521 - MSE: 0.10946502057613168\n",
      "Epoch 1522 - MSE: 0.10154320987654321\n",
      "Epoch 1523 - MSE: 0.10318930041152263\n",
      "Epoch 1524 - MSE: 0.10144032921810699\n",
      "Epoch 1525 - MSE: 0.10061728395061727\n",
      "Epoch 1526 - MSE: 0.1075102880658436\n",
      "Epoch 1527 - MSE: 0.10329218106995884\n",
      "Epoch 1528 - MSE: 0.09516460905349791\n",
      "Epoch 1529 - MSE: 0.09804526748971192\n",
      "Epoch 1530 - MSE: 0.10102880658436213\n",
      "Epoch 1531 - MSE: 0.10318930041152263\n",
      "Epoch 1532 - MSE: 0.10318930041152262\n",
      "Epoch 1533 - MSE: 0.10524691358024692\n",
      "Epoch 1534 - MSE: 0.10113168724279836\n",
      "Epoch 1535 - MSE: 0.10565843621399175\n",
      "Epoch 1536 - MSE: 0.10195473251028805\n",
      "Epoch 1537 - MSE: 0.09722222222222221\n",
      "Epoch 1538 - MSE: 0.09382716049382714\n",
      "Epoch 1539 - MSE: 0.10123456790123456\n",
      "Epoch 1540 - MSE: 0.10596707818930041\n",
      "Epoch 1541 - MSE: 0.10658436213991768\n",
      "Epoch 1542 - MSE: 0.0943415637860082\n",
      "Epoch 1543 - MSE: 0.10072016460905349\n",
      "Epoch 1544 - MSE: 0.09567901234567902\n",
      "Epoch 1545 - MSE: 0.10041152263374485\n",
      "Epoch 1546 - MSE: 0.09567901234567901\n",
      "Epoch 1547 - MSE: 0.09701646090534978\n",
      "Epoch 1548 - MSE: 0.10154320987654321\n",
      "Epoch 1549 - MSE: 0.10689300411522634\n",
      "Epoch 1550 - MSE: 0.09938271604938273\n",
      "Epoch 1551 - MSE: 0.09588477366255142\n",
      "Epoch 1552 - MSE: 0.09999999999999998\n",
      "Epoch 1553 - MSE: 0.10308641975308641\n",
      "Epoch 1554 - MSE: 0.09825102880658436\n",
      "Epoch 1555 - MSE: 0.10267489711934154\n",
      "Epoch 1556 - MSE: 0.10257201646090533\n",
      "Epoch 1557 - MSE: 0.09969135802469135\n",
      "Epoch 1558 - MSE: 0.09567901234567901\n",
      "Epoch 1559 - MSE: 0.09588477366255142\n",
      "Epoch 1560 - MSE: 0.11121399176954731\n",
      "Epoch 1561 - MSE: 0.10133744855967078\n",
      "Epoch 1562 - MSE: 0.1008230452674897\n",
      "Epoch 1563 - MSE: 0.10092592592592592\n",
      "Epoch 1564 - MSE: 0.09557613168724279\n",
      "Epoch 1565 - MSE: 0.09619341563786009\n",
      "Epoch 1566 - MSE: 0.10195473251028807\n",
      "Epoch 1567 - MSE: 0.09526748971193415\n",
      "Epoch 1568 - MSE: 0.1015432098765432\n",
      "Epoch 1569 - MSE: 0.10637860082304525\n",
      "Epoch 1570 - MSE: 0.10483539094650204\n",
      "Epoch 1571 - MSE: 0.10329218106995884\n",
      "Epoch 1572 - MSE: 0.09753086419753085\n",
      "Epoch 1573 - MSE: 0.10514403292181068\n",
      "Epoch 1574 - MSE: 0.10257201646090533\n",
      "Epoch 1575 - MSE: 0.09619341563786007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1576 - MSE: 0.1045267489711934\n",
      "Epoch 1577 - MSE: 0.10030864197530863\n",
      "Epoch 1578 - MSE: 0.10185185185185183\n",
      "Epoch 1579 - MSE: 0.09537037037037034\n",
      "Epoch 1580 - MSE: 0.09866255144032922\n",
      "Epoch 1581 - MSE: 0.1037037037037037\n",
      "Epoch 1582 - MSE: 0.1030864197530864\n",
      "Epoch 1583 - MSE: 0.09907407407407408\n",
      "Epoch 1584 - MSE: 0.08374485596707816\n",
      "Epoch 1585 - MSE: 0.09660493827160492\n",
      "Epoch 1586 - MSE: 0.09372427983539093\n",
      "Epoch 1587 - MSE: 0.09681069958847735\n",
      "Epoch 1588 - MSE: 0.09989711934156377\n",
      "Epoch 1589 - MSE: 0.1001028806584362\n",
      "Epoch 1590 - MSE: 0.10092592592592592\n",
      "Epoch 1591 - MSE: 0.09866255144032919\n",
      "Epoch 1592 - MSE: 0.1008230452674897\n",
      "Epoch 1593 - MSE: 0.09393004115226337\n",
      "Epoch 1594 - MSE: 0.09773662551440329\n",
      "Epoch 1595 - MSE: 0.09063786008230451\n",
      "Epoch 1596 - MSE: 0.10020576131687242\n",
      "Epoch 1597 - MSE: 0.10318930041152262\n",
      "Epoch 1598 - MSE: 0.10380658436213991\n",
      "Epoch 1599 - MSE: 0.09948559670781892\n",
      "Epoch 1600 - MSE: 0.10483539094650204\n",
      "Epoch 1601 - MSE: 0.09002057613168722\n",
      "Epoch 1602 - MSE: 0.1066872427983539\n",
      "Epoch 1603 - MSE: 0.10236625514403291\n",
      "Epoch 1604 - MSE: 0.10277777777777777\n",
      "Epoch 1605 - MSE: 0.10041152263374487\n",
      "Epoch 1606 - MSE: 0.09866255144032922\n",
      "Epoch 1607 - MSE: 0.09681069958847735\n",
      "Epoch 1608 - MSE: 0.09578189300411522\n",
      "Epoch 1609 - MSE: 0.09259259259259257\n",
      "Epoch 1610 - MSE: 0.0949588477366255\n",
      "Epoch 1611 - MSE: 0.10236625514403291\n",
      "Epoch 1612 - MSE: 0.0926954732510288\n",
      "Epoch 1613 - MSE: 0.09259259259259257\n",
      "Epoch 1614 - MSE: 0.10504115226337449\n",
      "Epoch 1615 - MSE: 0.0904320987654321\n",
      "Epoch 1616 - MSE: 0.10133744855967078\n",
      "Epoch 1617 - MSE: 0.10020576131687242\n",
      "Epoch 1618 - MSE: 0.10318930041152263\n",
      "Epoch 1619 - MSE: 0.09866255144032922\n",
      "Epoch 1620 - MSE: 0.0949588477366255\n",
      "Epoch 1621 - MSE: 0.08930041152263374\n",
      "Epoch 1622 - MSE: 0.09639917695473252\n",
      "Epoch 1623 - MSE: 0.09341563786008228\n",
      "Epoch 1624 - MSE: 0.09969135802469135\n",
      "Epoch 1625 - MSE: 0.09228395061728394\n",
      "Epoch 1626 - MSE: 0.10277777777777779\n",
      "Epoch 1627 - MSE: 0.09578189300411523\n",
      "Epoch 1628 - MSE: 0.0935185185185185\n",
      "Epoch 1629 - MSE: 0.09825102880658435\n",
      "Epoch 1630 - MSE: 0.09506172839506173\n",
      "Epoch 1631 - MSE: 0.08724279835390945\n",
      "Epoch 1632 - MSE: 0.09876543209876544\n",
      "Epoch 1633 - MSE: 0.09855967078189298\n",
      "Epoch 1634 - MSE: 0.09814814814814812\n",
      "Epoch 1635 - MSE: 0.09557613168724279\n",
      "Epoch 1636 - MSE: 0.09547325102880658\n",
      "Epoch 1637 - MSE: 0.097119341563786\n",
      "Epoch 1638 - MSE: 0.092798353909465\n",
      "Epoch 1639 - MSE: 0.10072016460905348\n",
      "Epoch 1640 - MSE: 0.1023662551440329\n",
      "Epoch 1641 - MSE: 0.10041152263374487\n",
      "Epoch 1642 - MSE: 0.09485596707818927\n",
      "Epoch 1643 - MSE: 0.09804526748971192\n",
      "Epoch 1644 - MSE: 0.10144032921810696\n",
      "Epoch 1645 - MSE: 0.09228395061728394\n",
      "Epoch 1646 - MSE: 0.09897119341563784\n",
      "Epoch 1647 - MSE: 0.09763374485596706\n",
      "Epoch 1648 - MSE: 0.10390946502057613\n",
      "Epoch 1649 - MSE: 0.1016460905349794\n",
      "Epoch 1650 - MSE: 0.09763374485596708\n",
      "Epoch 1651 - MSE: 0.09135802469135801\n",
      "Epoch 1652 - MSE: 0.09403292181069958\n",
      "Epoch 1653 - MSE: 0.09156378600823044\n",
      "Epoch 1654 - MSE: 0.09557613168724279\n",
      "Epoch 1655 - MSE: 0.092798353909465\n",
      "Epoch 1656 - MSE: 0.09320987654320988\n",
      "Epoch 1657 - MSE: 0.1044238683127572\n",
      "Epoch 1658 - MSE: 0.08888888888888886\n",
      "Epoch 1659 - MSE: 0.0957818930041152\n",
      "Epoch 1660 - MSE: 0.09516460905349795\n",
      "Epoch 1661 - MSE: 0.09290123456790121\n",
      "Epoch 1662 - MSE: 0.09485596707818929\n",
      "Epoch 1663 - MSE: 0.09310699588477364\n",
      "Epoch 1664 - MSE: 0.10195473251028805\n",
      "Epoch 1665 - MSE: 0.09320987654320986\n",
      "Epoch 1666 - MSE: 0.08775720164609054\n",
      "Epoch 1667 - MSE: 0.08775720164609052\n",
      "Epoch 1668 - MSE: 0.09670781893004114\n",
      "Epoch 1669 - MSE: 0.09053497942386829\n",
      "Epoch 1670 - MSE: 0.09341563786008228\n",
      "Epoch 1671 - MSE: 0.08755144032921809\n",
      "Epoch 1672 - MSE: 0.0772633744855967\n",
      "Epoch 1673 - MSE: 0.09022633744855965\n",
      "Epoch 1674 - MSE: 0.09002057613168722\n",
      "Epoch 1675 - MSE: 0.09156378600823044\n",
      "Epoch 1676 - MSE: 0.09331275720164607\n",
      "Epoch 1677 - MSE: 0.08786008230452673\n",
      "Epoch 1678 - MSE: 0.09104938271604936\n",
      "Epoch 1679 - MSE: 0.10082304526748968\n",
      "Epoch 1680 - MSE: 0.09269547325102881\n",
      "Epoch 1681 - MSE: 0.09783950617283949\n",
      "Epoch 1682 - MSE: 0.08868312757201645\n",
      "Epoch 1683 - MSE: 0.09506172839506172\n",
      "Epoch 1684 - MSE: 0.09948559670781894\n",
      "Epoch 1685 - MSE: 0.10236625514403294\n",
      "Epoch 1686 - MSE: 0.09362139917695472\n",
      "Epoch 1687 - MSE: 0.09320987654320986\n",
      "Epoch 1688 - MSE: 0.09248971193415638\n",
      "Epoch 1689 - MSE: 0.10072016460905349\n",
      "Epoch 1690 - MSE: 0.09526748971193413\n",
      "Epoch 1691 - MSE: 0.08755144032921809\n",
      "Epoch 1692 - MSE: 0.09814814814814815\n",
      "Epoch 1693 - MSE: 0.09701646090534978\n",
      "Epoch 1694 - MSE: 0.09475308641975307\n",
      "Epoch 1695 - MSE: 0.09300411522633743\n",
      "Epoch 1696 - MSE: 0.09290123456790124\n",
      "Epoch 1697 - MSE: 0.09475308641975308\n",
      "Epoch 1698 - MSE: 0.09372427983539094\n",
      "Epoch 1699 - MSE: 0.10030864197530863\n",
      "Epoch 1700 - MSE: 0.08899176954732509\n",
      "Epoch 1701 - MSE: 0.09670781893004114\n",
      "Epoch 1702 - MSE: 0.08477366255144032\n",
      "Epoch 1703 - MSE: 0.08446502057613167\n",
      "Epoch 1704 - MSE: 0.09372427983539093\n",
      "Epoch 1705 - MSE: 0.09310699588477366\n",
      "Epoch 1706 - MSE: 0.08312757201646089\n",
      "Epoch 1707 - MSE: 0.09238683127572014\n",
      "Epoch 1708 - MSE: 0.08744855967078188\n",
      "Epoch 1709 - MSE: 0.10051440329218106\n",
      "Epoch 1710 - MSE: 0.10195473251028807\n",
      "Epoch 1711 - MSE: 0.09948559670781891\n",
      "Epoch 1712 - MSE: 0.08374485596707817\n",
      "Epoch 1713 - MSE: 0.08662551440329215\n",
      "Epoch 1714 - MSE: 0.08991769547325103\n",
      "Epoch 1715 - MSE: 0.09722222222222222\n",
      "Epoch 1716 - MSE: 0.09660493827160492\n",
      "Epoch 1717 - MSE: 0.08024691358024691\n",
      "Epoch 1718 - MSE: 0.0905349794238683\n",
      "Epoch 1719 - MSE: 0.09403292181069958\n",
      "Epoch 1720 - MSE: 0.08909465020576131\n",
      "Epoch 1721 - MSE: 0.0876543209876543\n",
      "Epoch 1722 - MSE: 0.08065843621399174\n",
      "Epoch 1723 - MSE: 0.09516460905349794\n",
      "Epoch 1724 - MSE: 0.09434156378600822\n",
      "Epoch 1725 - MSE: 0.08734567901234566\n",
      "Epoch 1726 - MSE: 0.0868312757201646\n",
      "Epoch 1727 - MSE: 0.09845679012345677\n",
      "Epoch 1728 - MSE: 0.09619341563786007\n",
      "Epoch 1729 - MSE: 0.0904320987654321\n",
      "Epoch 1730 - MSE: 0.08724279835390945\n",
      "Epoch 1731 - MSE: 0.08569958847736625\n",
      "Epoch 1732 - MSE: 0.09290123456790121\n",
      "Epoch 1733 - MSE: 0.08919753086419753\n",
      "Epoch 1734 - MSE: 0.09516460905349794\n",
      "Epoch 1735 - MSE: 0.08631687242798351\n",
      "Epoch 1736 - MSE: 0.09362139917695471\n",
      "Epoch 1737 - MSE: 0.08425925925925926\n",
      "Epoch 1738 - MSE: 0.08971193415637858\n",
      "Epoch 1739 - MSE: 0.09547325102880656\n",
      "Epoch 1740 - MSE: 0.09701646090534978\n",
      "Epoch 1741 - MSE: 0.08971193415637856\n",
      "Epoch 1742 - MSE: 0.09619341563786007\n",
      "Epoch 1743 - MSE: 0.09166666666666666\n",
      "Epoch 1744 - MSE: 0.0833333333333333\n",
      "Epoch 1745 - MSE: 0.09331275720164607\n",
      "Epoch 1746 - MSE: 0.0912551440329218\n",
      "Epoch 1747 - MSE: 0.09526748971193413\n",
      "Epoch 1748 - MSE: 0.08292181069958847\n",
      "Epoch 1749 - MSE: 0.08991769547325103\n",
      "Epoch 1750 - MSE: 0.09218106995884773\n",
      "Epoch 1751 - MSE: 0.09176954732510287\n",
      "Epoch 1752 - MSE: 0.08868312757201646\n",
      "Epoch 1753 - MSE: 0.094238683127572\n",
      "Epoch 1754 - MSE: 0.09362139917695472\n",
      "Epoch 1755 - MSE: 0.08621399176954732\n",
      "Epoch 1756 - MSE: 0.08446502057613167\n",
      "Epoch 1757 - MSE: 0.09804526748971192\n",
      "Epoch 1758 - MSE: 0.0845679012345679\n",
      "Epoch 1759 - MSE: 0.09372427983539094\n",
      "Epoch 1760 - MSE: 0.08950617283950615\n",
      "Epoch 1761 - MSE: 0.08569958847736624\n",
      "Epoch 1762 - MSE: 0.08950617283950617\n",
      "Epoch 1763 - MSE: 0.08539094650205759\n",
      "Epoch 1764 - MSE: 0.08415637860082305\n",
      "Epoch 1765 - MSE: 0.10205761316872426\n",
      "Epoch 1766 - MSE: 0.08816872427983537\n",
      "Epoch 1767 - MSE: 0.09660493827160492\n",
      "Epoch 1768 - MSE: 0.08816872427983537\n",
      "Epoch 1769 - MSE: 0.08179012345679011\n",
      "Epoch 1770 - MSE: 0.0868312757201646\n",
      "Epoch 1771 - MSE: 0.09393004115226337\n",
      "Epoch 1772 - MSE: 0.08497942386831275\n",
      "Epoch 1773 - MSE: 0.08940329218106996\n",
      "Epoch 1774 - MSE: 0.08662551440329219\n",
      "Epoch 1775 - MSE: 0.0912551440329218\n",
      "Epoch 1776 - MSE: 0.08672839506172839\n",
      "Epoch 1777 - MSE: 0.09094650205761316\n",
      "Epoch 1778 - MSE: 0.09619341563786007\n",
      "Epoch 1779 - MSE: 0.098559670781893\n",
      "Epoch 1780 - MSE: 0.08662551440329216\n",
      "Epoch 1781 - MSE: 0.09084362139917693\n",
      "Epoch 1782 - MSE: 0.09176954732510287\n",
      "Epoch 1783 - MSE: 0.0912551440329218\n",
      "Epoch 1784 - MSE: 0.08816872427983537\n",
      "Epoch 1785 - MSE: 0.0911522633744856\n",
      "Epoch 1786 - MSE: 0.08353909465020574\n",
      "Epoch 1787 - MSE: 0.08220164609053497\n",
      "Epoch 1788 - MSE: 0.08878600823045266\n",
      "Epoch 1789 - MSE: 0.08549382716049382\n",
      "Epoch 1790 - MSE: 0.09485596707818929\n",
      "Epoch 1791 - MSE: 0.08672839506172839\n",
      "Epoch 1792 - MSE: 0.0802469135802469\n",
      "Epoch 1793 - MSE: 0.09310699588477366\n",
      "Epoch 1794 - MSE: 0.09876543209876541\n",
      "Epoch 1795 - MSE: 0.0861111111111111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1796 - MSE: 0.08909465020576131\n",
      "Epoch 1797 - MSE: 0.0796296296296296\n",
      "Epoch 1798 - MSE: 0.08888888888888886\n",
      "Epoch 1799 - MSE: 0.09032921810699589\n",
      "Epoch 1800 - MSE: 0.08806584362139916\n",
      "Epoch 1801 - MSE: 0.08271604938271604\n",
      "Epoch 1802 - MSE: 0.0920781893004115\n",
      "Epoch 1803 - MSE: 0.08868312757201645\n",
      "Epoch 1804 - MSE: 0.08600823045267489\n",
      "Epoch 1805 - MSE: 0.09578189300411522\n",
      "Epoch 1806 - MSE: 0.08559670781893002\n",
      "Epoch 1807 - MSE: 0.0838477366255144\n",
      "Epoch 1808 - MSE: 0.09465020576131687\n",
      "Epoch 1809 - MSE: 0.08806584362139916\n",
      "Epoch 1810 - MSE: 0.08508230452674896\n",
      "Epoch 1811 - MSE: 0.09331275720164608\n",
      "Epoch 1812 - MSE: 0.0889917695473251\n",
      "Epoch 1813 - MSE: 0.07993827160493826\n",
      "Epoch 1814 - MSE: 0.0926954732510288\n",
      "Epoch 1815 - MSE: 0.09094650205761316\n",
      "Epoch 1816 - MSE: 0.10051440329218106\n",
      "Epoch 1817 - MSE: 0.08117283950617284\n",
      "Epoch 1818 - MSE: 0.0868312757201646\n",
      "Epoch 1819 - MSE: 0.08127572016460904\n",
      "Epoch 1820 - MSE: 0.0912551440329218\n",
      "Epoch 1821 - MSE: 0.08302469135802468\n",
      "Epoch 1822 - MSE: 0.08580246913580246\n",
      "Epoch 1823 - MSE: 0.08467078189300409\n",
      "Epoch 1824 - MSE: 0.07942386831275718\n",
      "Epoch 1825 - MSE: 0.08415637860082302\n",
      "Epoch 1826 - MSE: 0.08600823045267489\n",
      "Epoch 1827 - MSE: 0.07211934156378601\n",
      "Epoch 1828 - MSE: 0.0911522633744856\n",
      "Epoch 1829 - MSE: 0.08858024691358023\n",
      "Epoch 1830 - MSE: 0.09485596707818927\n",
      "Epoch 1831 - MSE: 0.0853909465020576\n",
      "Epoch 1832 - MSE: 0.094238683127572\n",
      "Epoch 1833 - MSE: 0.08487654320987653\n",
      "Epoch 1834 - MSE: 0.08508230452674896\n",
      "Epoch 1835 - MSE: 0.08240740740740739\n",
      "Epoch 1836 - MSE: 0.09166666666666666\n",
      "Epoch 1837 - MSE: 0.0920781893004115\n",
      "Epoch 1838 - MSE: 0.09156378600823044\n",
      "Epoch 1839 - MSE: 0.07973251028806583\n",
      "Epoch 1840 - MSE: 0.08096707818930039\n",
      "Epoch 1841 - MSE: 0.07860082304526748\n",
      "Epoch 1842 - MSE: 0.08127572016460904\n",
      "Epoch 1843 - MSE: 0.08456790123456788\n",
      "Epoch 1844 - MSE: 0.0788065843621399\n",
      "Epoch 1845 - MSE: 0.08888888888888886\n",
      "Epoch 1846 - MSE: 0.08137860082304525\n",
      "Epoch 1847 - MSE: 0.08734567901234568\n",
      "Epoch 1848 - MSE: 0.07860082304526747\n",
      "Epoch 1849 - MSE: 0.08395061728395062\n",
      "Epoch 1850 - MSE: 0.0796296296296296\n",
      "Epoch 1851 - MSE: 0.09825102880658436\n",
      "Epoch 1852 - MSE: 0.08199588477366254\n",
      "Epoch 1853 - MSE: 0.09300411522633743\n",
      "Epoch 1854 - MSE: 0.0905349794238683\n",
      "Epoch 1855 - MSE: 0.089917695473251\n",
      "Epoch 1856 - MSE: 0.08940329218106996\n",
      "Epoch 1857 - MSE: 0.07644032921810699\n",
      "Epoch 1858 - MSE: 0.0839506172839506\n",
      "Epoch 1859 - MSE: 0.08281893004115225\n",
      "Epoch 1860 - MSE: 0.08024691358024691\n",
      "Epoch 1861 - MSE: 0.09187242798353906\n",
      "Epoch 1862 - MSE: 0.08374485596707819\n",
      "Epoch 1863 - MSE: 0.07602880658436213\n",
      "Epoch 1864 - MSE: 0.0839506172839506\n",
      "Epoch 1865 - MSE: 0.08343621399176954\n",
      "Epoch 1866 - MSE: 0.08744855967078188\n",
      "Epoch 1867 - MSE: 0.08312757201646089\n",
      "Epoch 1868 - MSE: 0.08631687242798351\n",
      "Epoch 1869 - MSE: 0.09032921810699587\n",
      "Epoch 1870 - MSE: 0.09537037037037038\n",
      "Epoch 1871 - MSE: 0.0818930041152263\n",
      "Epoch 1872 - MSE: 0.08631687242798353\n",
      "Epoch 1873 - MSE: 0.09228395061728394\n",
      "Epoch 1874 - MSE: 0.08425925925925924\n",
      "Epoch 1875 - MSE: 0.08755144032921809\n",
      "Epoch 1876 - MSE: 0.08467078189300409\n",
      "Epoch 1877 - MSE: 0.0862139917695473\n",
      "Epoch 1878 - MSE: 0.09320987654320988\n",
      "Epoch 1879 - MSE: 0.08683127572016458\n",
      "Epoch 1880 - MSE: 0.08508230452674895\n",
      "Epoch 1881 - MSE: 0.09084362139917694\n",
      "Epoch 1882 - MSE: 0.09176954732510287\n",
      "Epoch 1883 - MSE: 0.07695473251028806\n",
      "Epoch 1884 - MSE: 0.0890946502057613\n",
      "Epoch 1885 - MSE: 0.08477366255144032\n",
      "Epoch 1886 - MSE: 0.0853909465020576\n",
      "Epoch 1887 - MSE: 0.09002057613168724\n",
      "Epoch 1888 - MSE: 0.08600823045267489\n",
      "Epoch 1889 - MSE: 0.08446502057613169\n",
      "Epoch 1890 - MSE: 0.08724279835390945\n",
      "Epoch 1891 - MSE: 0.08353909465020574\n",
      "Epoch 1892 - MSE: 0.08415637860082305\n",
      "Epoch 1893 - MSE: 0.08127572016460904\n",
      "Epoch 1894 - MSE: 0.08374485596707817\n",
      "Epoch 1895 - MSE: 0.0912551440329218\n",
      "Epoch 1896 - MSE: 0.08014403292181067\n",
      "Epoch 1897 - MSE: 0.094238683127572\n",
      "Epoch 1898 - MSE: 0.08467078189300409\n",
      "Epoch 1899 - MSE: 0.0818930041152263\n",
      "Epoch 1900 - MSE: 0.08508230452674896\n",
      "Epoch 1901 - MSE: 0.09485596707818929\n",
      "Epoch 1902 - MSE: 0.08672839506172839\n",
      "Epoch 1903 - MSE: 0.08456790123456788\n",
      "Epoch 1904 - MSE: 0.08374485596707819\n",
      "Epoch 1905 - MSE: 0.0772633744855967\n",
      "Epoch 1906 - MSE: 0.07993827160493826\n",
      "Epoch 1907 - MSE: 0.0779835390946502\n",
      "Epoch 1908 - MSE: 0.0868312757201646\n",
      "Epoch 1909 - MSE: 0.07592592592592592\n",
      "Epoch 1910 - MSE: 0.08899176954732509\n",
      "Epoch 1911 - MSE: 0.07695473251028806\n",
      "Epoch 1912 - MSE: 0.07973251028806583\n",
      "Epoch 1913 - MSE: 0.0816872427983539\n",
      "Epoch 1914 - MSE: 0.08755144032921809\n",
      "Epoch 1915 - MSE: 0.08631687242798353\n",
      "Epoch 1916 - MSE: 0.08641975308641975\n",
      "Epoch 1917 - MSE: 0.08024691358024691\n",
      "Epoch 1918 - MSE: 0.08261316872427982\n",
      "Epoch 1919 - MSE: 0.0904320987654321\n",
      "Epoch 1920 - MSE: 0.08796296296296297\n",
      "Epoch 1921 - MSE: 0.08271604938271604\n",
      "Epoch 1922 - MSE: 0.08960905349794238\n",
      "Epoch 1923 - MSE: 0.07839506172839504\n",
      "Epoch 1924 - MSE: 0.08518518518518518\n",
      "Epoch 1925 - MSE: 0.07633744855967077\n",
      "Epoch 1926 - MSE: 0.08425925925925924\n",
      "Epoch 1927 - MSE: 0.08786008230452673\n",
      "Epoch 1928 - MSE: 0.07942386831275718\n",
      "Epoch 1929 - MSE: 0.08127572016460903\n",
      "Epoch 1930 - MSE: 0.08940329218106996\n",
      "Epoch 1931 - MSE: 0.08415637860082305\n",
      "Epoch 1932 - MSE: 0.08446502057613167\n",
      "Epoch 1933 - MSE: 0.0905349794238683\n",
      "Epoch 1934 - MSE: 0.08436213991769546\n",
      "Epoch 1935 - MSE: 0.0839506172839506\n",
      "Epoch 1936 - MSE: 0.0890946502057613\n",
      "Epoch 1937 - MSE: 0.08158436213991767\n",
      "Epoch 1938 - MSE: 0.0788065843621399\n",
      "Epoch 1939 - MSE: 0.0889917695473251\n",
      "Epoch 1940 - MSE: 0.08425925925925924\n",
      "Epoch 1941 - MSE: 0.0751028806584362\n",
      "Epoch 1942 - MSE: 0.08076131687242798\n",
      "Epoch 1943 - MSE: 0.0795267489711934\n",
      "Epoch 1944 - MSE: 0.08117283950617281\n",
      "Epoch 1945 - MSE: 0.07109053497942386\n",
      "Epoch 1946 - MSE: 0.07808641975308639\n",
      "Epoch 1947 - MSE: 0.08374485596707817\n",
      "Epoch 1948 - MSE: 0.07767489711934156\n",
      "Epoch 1949 - MSE: 0.07767489711934156\n",
      "Epoch 1950 - MSE: 0.0809670781893004\n",
      "Epoch 1951 - MSE: 0.0912551440329218\n",
      "Epoch 1952 - MSE: 0.08600823045267489\n",
      "Epoch 1953 - MSE: 0.08312757201646089\n",
      "Epoch 1954 - MSE: 0.08600823045267489\n",
      "Epoch 1955 - MSE: 0.08436213991769546\n",
      "Epoch 1956 - MSE: 0.07479423868312757\n",
      "Epoch 1957 - MSE: 0.0935185185185185\n",
      "Epoch 1958 - MSE: 0.08559670781893003\n",
      "Epoch 1959 - MSE: 0.08960905349794238\n",
      "Epoch 1960 - MSE: 0.08703703703703702\n",
      "Epoch 1961 - MSE: 0.08796296296296292\n",
      "Epoch 1962 - MSE: 0.08034979423868312\n",
      "Epoch 1963 - MSE: 0.08148148148148147\n",
      "Epoch 1964 - MSE: 0.09156378600823045\n",
      "Epoch 1965 - MSE: 0.08816872427983537\n",
      "Epoch 1966 - MSE: 0.07777777777777777\n",
      "Epoch 1967 - MSE: 0.07757201646090535\n",
      "Epoch 1968 - MSE: 0.07623456790123456\n",
      "Epoch 1969 - MSE: 0.0796296296296296\n",
      "Epoch 1970 - MSE: 0.0839506172839506\n",
      "Epoch 1971 - MSE: 0.07469135802469136\n",
      "Epoch 1972 - MSE: 0.07757201646090534\n",
      "Epoch 1973 - MSE: 0.07911522633744854\n",
      "Epoch 1974 - MSE: 0.0817901234567901\n",
      "Epoch 1975 - MSE: 0.07901234567901233\n",
      "Epoch 1976 - MSE: 0.08199588477366254\n",
      "Epoch 1977 - MSE: 0.08261316872427982\n",
      "Epoch 1978 - MSE: 0.08251028806584361\n",
      "Epoch 1979 - MSE: 0.08055555555555555\n",
      "Epoch 1980 - MSE: 0.08662551440329219\n",
      "Epoch 1981 - MSE: 0.0736625514403292\n",
      "Epoch 1982 - MSE: 0.08477366255144031\n",
      "Epoch 1983 - MSE: 0.09228395061728395\n",
      "Epoch 1984 - MSE: 0.08065843621399177\n",
      "Epoch 1985 - MSE: 0.08981481481481479\n",
      "Epoch 1986 - MSE: 0.07983539094650205\n",
      "Epoch 1987 - MSE: 0.0823045267489712\n",
      "Epoch 1988 - MSE: 0.07757201646090534\n",
      "Epoch 1989 - MSE: 0.08076131687242798\n",
      "Epoch 1990 - MSE: 0.07716049382716049\n",
      "Epoch 1991 - MSE: 0.08888888888888886\n",
      "Epoch 1992 - MSE: 0.07921810699588476\n",
      "Epoch 1993 - MSE: 0.0832304526748971\n",
      "Epoch 1994 - MSE: 0.07901234567901234\n",
      "Epoch 1995 - MSE: 0.08405349794238681\n",
      "Epoch 1996 - MSE: 0.08343621399176954\n",
      "Epoch 1997 - MSE: 0.08220164609053494\n",
      "Epoch 1998 - MSE: 0.08456790123456788\n",
      "Epoch 1999 - MSE: 0.08703703703703701\n"
     ]
    }
   ],
   "source": [
    "crbm.train(X_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.45493827160493827,\n",
       " 0.46419753086419746,\n",
       " 0.44074074074074077,\n",
       " 0.46296296296296297,\n",
       " 0.43703703703703706,\n",
       " 0.45637860082304516,\n",
       " 0.4671810699588476,\n",
       " 0.45884773662551437,\n",
       " 0.4441358024691358,\n",
       " 0.444238683127572,\n",
       " 0.4525720164609053,\n",
       " 0.4435185185185185,\n",
       " 0.4472222222222222,\n",
       " 0.4488683127572017,\n",
       " 0.45092592592592595,\n",
       " 0.44362139917695464,\n",
       " 0.4371399176954732,\n",
       " 0.43888888888888894,\n",
       " 0.4409465020576131,\n",
       " 0.45493827160493827,\n",
       " 0.4381687242798354,\n",
       " 0.46141975308641975,\n",
       " 0.4248971193415637,\n",
       " 0.4402263374485596,\n",
       " 0.45596707818930043,\n",
       " 0.44259259259259265,\n",
       " 0.4203703703703705,\n",
       " 0.4419753086419754,\n",
       " 0.4291152263374486,\n",
       " 0.4356995884773663,\n",
       " 0.45246913580246906,\n",
       " 0.42973251028806586,\n",
       " 0.43569958847736623,\n",
       " 0.44074074074074077,\n",
       " 0.44814814814814813,\n",
       " 0.434670781893004,\n",
       " 0.4310699588477366,\n",
       " 0.42510288065843616,\n",
       " 0.42530864197530877,\n",
       " 0.4302469135802469,\n",
       " 0.4244855967078188,\n",
       " 0.41831275720164607,\n",
       " 0.4198559670781893,\n",
       " 0.4193415637860082,\n",
       " 0.43014403292181075,\n",
       " 0.4502057613168724,\n",
       " 0.42376543209876544,\n",
       " 0.42839506172839503,\n",
       " 0.42222222222222217,\n",
       " 0.4231481481481481,\n",
       " 0.4405349794238684,\n",
       " 0.42181069958847733,\n",
       " 0.42222222222222217,\n",
       " 0.4020576131687243,\n",
       " 0.41522633744855963,\n",
       " 0.42355967078189305,\n",
       " 0.40267489711934157,\n",
       " 0.41316872427983536,\n",
       " 0.39609053497942387,\n",
       " 0.41954732510288073,\n",
       " 0.4204732510288065,\n",
       " 0.4173868312757201,\n",
       " 0.4059670781893004,\n",
       " 0.4320987654320988,\n",
       " 0.42119341563786006,\n",
       " 0.40648148148148144,\n",
       " 0.4059670781893004,\n",
       " 0.410082304526749,\n",
       " 0.4072016460905349,\n",
       " 0.4143004115226337,\n",
       " 0.4089506172839506,\n",
       " 0.4031893004115227,\n",
       " 0.396604938271605,\n",
       " 0.4198559670781893,\n",
       " 0.39372427983539093,\n",
       " 0.38724279835390946,\n",
       " 0.39691358024691353,\n",
       " 0.39629629629629626,\n",
       " 0.40133744855967074,\n",
       " 0.3912551440329217,\n",
       " 0.41234567901234565,\n",
       " 0.40596707818930045,\n",
       " 0.4059670781893004,\n",
       " 0.3842592592592593,\n",
       " 0.409567901234568,\n",
       " 0.40709876543209883,\n",
       " 0.39104938271604944,\n",
       " 0.40113168724279824,\n",
       " 0.39783950617283953,\n",
       " 0.37006172839506174,\n",
       " 0.3988683127572016,\n",
       " 0.3871399176954732,\n",
       " 0.3879629629629629,\n",
       " 0.3901234567901235,\n",
       " 0.3791152263374486,\n",
       " 0.39218106995884766,\n",
       " 0.39197530864197533,\n",
       " 0.4134773662551439,\n",
       " 0.398045267489712,\n",
       " 0.3887860082304527,\n",
       " 0.3832304526748971,\n",
       " 0.37304526748971184,\n",
       " 0.3887860082304526,\n",
       " 0.3824074074074075,\n",
       " 0.4056584362139918,\n",
       " 0.3921810699588477,\n",
       " 0.387037037037037,\n",
       " 0.39043209876543217,\n",
       " 0.3744855967078189,\n",
       " 0.39146090534979416,\n",
       " 0.3848765432098765,\n",
       " 0.36913580246913574,\n",
       " 0.38106995884773665,\n",
       " 0.3912551440329218,\n",
       " 0.38641975308641974,\n",
       " 0.3883744855967078,\n",
       " 0.3779835390946502,\n",
       " 0.3924897119341563,\n",
       " 0.39300411522633744,\n",
       " 0.39351851851851855,\n",
       " 0.39300411522633744,\n",
       " 0.36574074074074076,\n",
       " 0.3825102880658436,\n",
       " 0.37561728395061733,\n",
       " 0.378395061728395,\n",
       " 0.3730452674897119,\n",
       " 0.38796296296296295,\n",
       " 0.36810699588477364,\n",
       " 0.3768518518518519,\n",
       " 0.3626543209876544,\n",
       " 0.3725308641975308,\n",
       " 0.3872427983539094,\n",
       " 0.37397119341563784,\n",
       " 0.3712962962962964,\n",
       " 0.3773662551440329,\n",
       " 0.3556584362139917,\n",
       " 0.36995884773662546,\n",
       " 0.3621399176954732,\n",
       " 0.3777777777777779,\n",
       " 0.37479423868312756,\n",
       " 0.37427983539094645,\n",
       " 0.38487654320987663,\n",
       " 0.3671810699588477,\n",
       " 0.36213991769547327,\n",
       " 0.37983539094650204,\n",
       " 0.3791152263374485,\n",
       " 0.3738683127572016,\n",
       " 0.3653292181069958,\n",
       " 0.3698559670781893,\n",
       " 0.37139917695473246,\n",
       " 0.3720164609053498,\n",
       " 0.3585390946502056,\n",
       " 0.363477366255144,\n",
       " 0.3648148148148148,\n",
       " 0.37325102880658434,\n",
       " 0.3658436213991769,\n",
       " 0.3725308641975308,\n",
       " 0.35689300411522623,\n",
       " 0.3804526748971194,\n",
       " 0.3683127572016461,\n",
       " 0.3602880658436214,\n",
       " 0.3709876543209877,\n",
       " 0.3463991769547325,\n",
       " 0.3800411522633745,\n",
       " 0.3450617283950617,\n",
       " 0.3553497942386831,\n",
       " 0.3605967078189301,\n",
       " 0.3619341563786008,\n",
       " 0.36862139917695474,\n",
       " 0.3501028806584362,\n",
       " 0.3630658436213991,\n",
       " 0.3531893004115226,\n",
       " 0.3582304526748971,\n",
       " 0.35617283950617284,\n",
       " 0.3498971193415637,\n",
       " 0.3504115226337448,\n",
       " 0.3567901234567901,\n",
       " 0.3646090534979424,\n",
       " 0.3434156378600822,\n",
       " 0.3658436213991769,\n",
       " 0.3539094650205761,\n",
       " 0.35555555555555557,\n",
       " 0.35884773662551445,\n",
       " 0.3523662551440329,\n",
       " 0.353395061728395,\n",
       " 0.35586419753086423,\n",
       " 0.3570987654320988,\n",
       " 0.36738683127572014,\n",
       " 0.3567901234567902,\n",
       " 0.35401234567901235,\n",
       " 0.3687242798353909,\n",
       " 0.3516460905349794,\n",
       " 0.3674897119341563,\n",
       " 0.35452674897119335,\n",
       " 0.3497942386831276,\n",
       " 0.35751028806584356,\n",
       " 0.35102880658436214,\n",
       " 0.35812757201646084,\n",
       " 0.35699588477366245,\n",
       " 0.34351851851851856,\n",
       " 0.35401234567901235,\n",
       " 0.35102880658436214,\n",
       " 0.35730452674897123,\n",
       " 0.35390946502057613,\n",
       " 0.34773662551440326,\n",
       " 0.34053497942386834,\n",
       " 0.34753086419753093,\n",
       " 0.3553497942386831,\n",
       " 0.36224279835390943,\n",
       " 0.3478395061728395,\n",
       " 0.33868312757201646,\n",
       " 0.35452674897119346,\n",
       " 0.33919753086419757,\n",
       " 0.3540123456790124,\n",
       " 0.3485596707818929,\n",
       " 0.3455761316872428,\n",
       " 0.34938271604938265,\n",
       " 0.3388888888888889,\n",
       " 0.3530864197530864,\n",
       " 0.35658436213991757,\n",
       " 0.3627572016460906,\n",
       " 0.3310699588477366,\n",
       " 0.3611111111111111,\n",
       " 0.34619341563786,\n",
       " 0.3514403292181069,\n",
       " 0.34351851851851856,\n",
       " 0.35401234567901235,\n",
       " 0.3339506172839506,\n",
       " 0.3290123456790124,\n",
       " 0.32644032921810695,\n",
       " 0.34104938271604934,\n",
       " 0.353395061728395,\n",
       " 0.3349794238683128,\n",
       " 0.34475308641975305,\n",
       " 0.35390946502057613,\n",
       " 0.3128600823045267,\n",
       " 0.34670781893004116,\n",
       " 0.34259259259259267,\n",
       " 0.3457818930041152,\n",
       " 0.34382716049382717,\n",
       " 0.339917695473251,\n",
       " 0.34403292181069955,\n",
       " 0.347119341563786,\n",
       " 0.34660493827160493,\n",
       " 0.3599794238683127,\n",
       " 0.3414609053497942,\n",
       " 0.34218106995884773,\n",
       " 0.3483539094650205,\n",
       " 0.3286008230452675,\n",
       " 0.3445473251028807,\n",
       " 0.3435185185185186,\n",
       " 0.3420781893004115,\n",
       " 0.34434156378600816,\n",
       " 0.33549382716049386,\n",
       " 0.3440329218106996,\n",
       " 0.35164609053497947,\n",
       " 0.33796296296296297,\n",
       " 0.33786008230452674,\n",
       " 0.35462962962962963,\n",
       " 0.3444444444444445,\n",
       " 0.337551440329218,\n",
       " 0.333641975308642,\n",
       " 0.33343621399176954,\n",
       " 0.3256172839506173,\n",
       " 0.3264403292181069,\n",
       " 0.3276748971193416,\n",
       " 0.3436213991769546,\n",
       " 0.34176954732510284,\n",
       " 0.3389917695473251,\n",
       " 0.32983539094650205,\n",
       " 0.3380658436213991,\n",
       " 0.3410493827160494,\n",
       " 0.33868312757201635,\n",
       " 0.34372427983539094,\n",
       " 0.32767489711934156,\n",
       " 0.3403292181069958,\n",
       " 0.32592592592592595,\n",
       " 0.3311728395061728,\n",
       " 0.3220164609053498,\n",
       " 0.3231481481481482,\n",
       " 0.3260288065843621,\n",
       " 0.3329218106995884,\n",
       " 0.337551440329218,\n",
       " 0.33467078189300414,\n",
       " 0.34650205761316866,\n",
       " 0.34063786008230457,\n",
       " 0.32798353909465017,\n",
       " 0.32592592592592595,\n",
       " 0.32201646090534974,\n",
       " 0.32592592592592595,\n",
       " 0.3402263374485597,\n",
       " 0.34351851851851845,\n",
       " 0.321604938271605,\n",
       " 0.35370370370370374,\n",
       " 0.3372427983539094,\n",
       " 0.3175925925925926,\n",
       " 0.3253086419753087,\n",
       " 0.330761316872428,\n",
       " 0.32037037037037036,\n",
       " 0.332201646090535,\n",
       " 0.34403292181069955,\n",
       " 0.35102880658436214,\n",
       " 0.33528806584362136,\n",
       " 0.3426954732510288,\n",
       " 0.3412551440329218,\n",
       " 0.32664609053497945,\n",
       " 0.3228395061728395,\n",
       " 0.31810699588477365,\n",
       " 0.3277777777777778,\n",
       " 0.33569958847736625,\n",
       " 0.3151234567901235,\n",
       " 0.32006172839506175,\n",
       " 0.32644032921810695,\n",
       " 0.3304526748971192,\n",
       " 0.332201646090535,\n",
       " 0.30761316872427974,\n",
       " 0.33086419753086416,\n",
       " 0.31522633744855966,\n",
       " 0.3273662551440329,\n",
       " 0.32818930041152256,\n",
       " 0.3195473251028807,\n",
       " 0.32222222222222235,\n",
       " 0.32211934156378597,\n",
       " 0.33220164609053493,\n",
       " 0.31841563786008226,\n",
       " 0.31790123456790126,\n",
       " 0.3246913580246914,\n",
       " 0.3162551440329217,\n",
       " 0.31635802469135793,\n",
       " 0.3153292181069958,\n",
       " 0.3078189300411523,\n",
       " 0.320679012345679,\n",
       " 0.319238683127572,\n",
       " 0.31913580246913587,\n",
       " 0.3056584362139918,\n",
       " 0.31790123456790126,\n",
       " 0.3185185185185185,\n",
       " 0.3305555555555555,\n",
       " 0.32685185185185195,\n",
       " 0.3039094650205762,\n",
       " 0.32623456790123445,\n",
       " 0.3036008230452674,\n",
       " 0.31851851851851837,\n",
       " 0.3175925925925926,\n",
       " 0.3169753086419753,\n",
       " 0.3030864197530864,\n",
       " 0.32644032921810684,\n",
       " 0.30812757201646085,\n",
       " 0.3122427983539094,\n",
       " 0.314917695473251,\n",
       " 0.3286008230452674,\n",
       " 0.3186213991769548,\n",
       " 0.31131687242798345,\n",
       " 0.30185185185185187,\n",
       " 0.32181069958847736,\n",
       " 0.2996913580246914,\n",
       " 0.30442386831275714,\n",
       " 0.30360082304526753,\n",
       " 0.3199588477366255,\n",
       " 0.2970164609053498,\n",
       " 0.30514403292181064,\n",
       " 0.31790123456790126,\n",
       " 0.29413580246913584,\n",
       " 0.2954732510288066,\n",
       " 0.2916666666666666,\n",
       " 0.3111111111111111,\n",
       " 0.3102880658436213,\n",
       " 0.3112139917695472,\n",
       " 0.3181069958847737,\n",
       " 0.3004115226337448,\n",
       " 0.3029835390946502,\n",
       " 0.31481481481481477,\n",
       " 0.2978395061728395,\n",
       " 0.304835390946502,\n",
       " 0.2930041152263374,\n",
       " 0.30380658436214,\n",
       " 0.31471193415637866,\n",
       " 0.31440329218106994,\n",
       " 0.2975308641975308,\n",
       " 0.3005144032921811,\n",
       " 0.2974279835390946,\n",
       " 0.2931069958847737,\n",
       " 0.29825102880658433,\n",
       " 0.2986625514403292,\n",
       " 0.2988683127572016,\n",
       " 0.2958847736625514,\n",
       " 0.28888888888888886,\n",
       " 0.3148148148148148,\n",
       " 0.31316872427983533,\n",
       " 0.2986625514403292,\n",
       " 0.3008230452674897,\n",
       " 0.2968106995884774,\n",
       " 0.2900205761316873,\n",
       " 0.30874485596707824,\n",
       " 0.3061728395061728,\n",
       " 0.29032921810699586,\n",
       " 0.3137860082304527,\n",
       " 0.2979423868312757,\n",
       " 0.2986625514403292,\n",
       " 0.2904320987654321,\n",
       " 0.270164609053498,\n",
       " 0.300514403292181,\n",
       " 0.29825102880658433,\n",
       " 0.2920781893004115,\n",
       " 0.2993827160493827,\n",
       " 0.29773662551440333,\n",
       " 0.2952674897119341,\n",
       " 0.30298353909465014,\n",
       " 0.2922839506172839,\n",
       " 0.29516460905349795,\n",
       " 0.291358024691358,\n",
       " 0.29094650205761313,\n",
       " 0.29351851851851846,\n",
       " 0.2993827160493827,\n",
       " 0.2923868312757201,\n",
       " 0.3006172839506173,\n",
       " 0.27973251028806584,\n",
       " 0.28734567901234565,\n",
       " 0.287962962962963,\n",
       " 0.2974279835390946,\n",
       " 0.2885802469135803,\n",
       " 0.28672839506172837,\n",
       " 0.2866255144032921,\n",
       " 0.28816872427983536,\n",
       " 0.30318930041152264,\n",
       " 0.29269547325102885,\n",
       " 0.29259259259259257,\n",
       " 0.2960905349794239,\n",
       " 0.2911522633744856,\n",
       " 0.2887860082304527,\n",
       " 0.27788065843621396,\n",
       " 0.2960905349794239,\n",
       " 0.2828189300411522,\n",
       " 0.2994855967078189,\n",
       " 0.29094650205761313,\n",
       " 0.2832304526748971,\n",
       " 0.2725308641975308,\n",
       " 0.2733539094650206,\n",
       " 0.2752057613168724,\n",
       " 0.2772633744855967,\n",
       " 0.28775720164609053,\n",
       " 0.29248971193415635,\n",
       " 0.28641975308641976,\n",
       " 0.28858024691358025,\n",
       " 0.2766460905349794,\n",
       " 0.2780864197530864,\n",
       " 0.26985596707818926,\n",
       " 0.2809670781893004,\n",
       " 0.2758230452674897,\n",
       " 0.2972222222222223,\n",
       " 0.2852880658436214,\n",
       " 0.2781893004115226,\n",
       " 0.2814814814814814,\n",
       " 0.279320987654321,\n",
       " 0.27911522633744856,\n",
       " 0.27386831275720164,\n",
       " 0.2801440329218107,\n",
       " 0.28786008230452675,\n",
       " 0.2837448559670782,\n",
       " 0.2663580246913581,\n",
       " 0.2902263374485597,\n",
       " 0.28744855967078187,\n",
       " 0.28343621399176955,\n",
       " 0.2729423868312757,\n",
       " 0.27983539094650206,\n",
       " 0.26131687242798357,\n",
       " 0.28569958847736626,\n",
       " 0.269238683127572,\n",
       " 0.2916666666666667,\n",
       " 0.275,\n",
       " 0.27273662551440325,\n",
       " 0.27170781893004115,\n",
       " 0.2760288065843622,\n",
       " 0.2761316872427983,\n",
       " 0.26224279835390946,\n",
       " 0.26985596707818926,\n",
       " 0.2566872427983539,\n",
       " 0.27448559670781886,\n",
       " 0.2643004115226337,\n",
       " 0.2691358024691358,\n",
       " 0.27006172839506176,\n",
       " 0.26779835390946505,\n",
       " 0.27150205761316876,\n",
       " 0.2823045267489712,\n",
       " 0.2708847736625514,\n",
       " 0.27242798353909464,\n",
       " 0.2598765432098765,\n",
       " 0.2643004115226337,\n",
       " 0.2699588477366255,\n",
       " 0.2683127572016461,\n",
       " 0.25246913580246916,\n",
       " 0.2664609053497942,\n",
       " 0.2789094650205761,\n",
       " 0.2601851851851852,\n",
       " 0.2709876543209877,\n",
       " 0.25761316872427986,\n",
       " 0.26337448559670784,\n",
       " 0.267798353909465,\n",
       " 0.2597736625514403,\n",
       " 0.27355967078189297,\n",
       " 0.27654320987654324,\n",
       " 0.2720164609053498,\n",
       " 0.2685185185185185,\n",
       " 0.27458847736625513,\n",
       " 0.26543209876543206,\n",
       " 0.2664609053497942,\n",
       " 0.25339506172839504,\n",
       " 0.2712962962962963,\n",
       " 0.27078189300411526,\n",
       " 0.252880658436214,\n",
       " 0.2697530864197531,\n",
       " 0.2600823045267489,\n",
       " 0.2522633744855967,\n",
       " 0.26131687242798357,\n",
       " 0.255761316872428,\n",
       " 0.2617283950617284,\n",
       " 0.2541152263374486,\n",
       " 0.24958847736625514,\n",
       " 0.2716049382716049,\n",
       " 0.25967078189300413,\n",
       " 0.2637860082304527,\n",
       " 0.2654320987654321,\n",
       " 0.24639917695473254,\n",
       " 0.2630658436213992,\n",
       " 0.2671810699588477,\n",
       " 0.26213991769547323,\n",
       " 0.25946502057613163,\n",
       " 0.26224279835390946,\n",
       " 0.26121399176954735,\n",
       " 0.25318930041152266,\n",
       " 0.2498971193415638,\n",
       " 0.25452674897119343,\n",
       " 0.265843621399177,\n",
       " 0.25946502057613163,\n",
       " 0.2532921810699588,\n",
       " 0.2424897119341564,\n",
       " 0.23806584362139918,\n",
       " 0.24650205761316873,\n",
       " 0.26810699588477366,\n",
       " 0.2420781893004115,\n",
       " 0.2541152263374486,\n",
       " 0.24897119341563786,\n",
       " 0.2530864197530864,\n",
       " 0.25390946502057615,\n",
       " 0.2617283950617284,\n",
       " 0.24619341563786012,\n",
       " 0.2547325102880658,\n",
       " 0.23847736625514404,\n",
       " 0.23672839506172835,\n",
       " 0.23775720164609057,\n",
       " 0.25421810699588476,\n",
       " 0.2508230452674897,\n",
       " 0.25740740740740736,\n",
       " 0.24537037037037038,\n",
       " 0.25483539094650204,\n",
       " 0.24362139917695474,\n",
       " 0.24804526748971192,\n",
       " 0.2544238683127572,\n",
       " 0.24526748971193418,\n",
       " 0.2524691358024691,\n",
       " 0.24475308641975316,\n",
       " 0.24701646090534982,\n",
       " 0.2417695473251029,\n",
       " 0.23683127572016463,\n",
       " 0.23508230452674897,\n",
       " 0.25102880658436216,\n",
       " 0.24866255144032923,\n",
       " 0.24547325102880657,\n",
       " 0.24979423868312758,\n",
       " 0.24578189300411524,\n",
       " 0.24958847736625517,\n",
       " 0.23713991769547327,\n",
       " 0.2361111111111111,\n",
       " 0.2476337448559671,\n",
       " 0.24475308641975305,\n",
       " 0.23292181069958848,\n",
       " 0.24958847736625514,\n",
       " 0.2389917695473251,\n",
       " 0.23713991769547324,\n",
       " 0.24629629629629626,\n",
       " 0.23786008230452677,\n",
       " 0.24403292181069955,\n",
       " 0.24495884773662552,\n",
       " 0.24588477366255138,\n",
       " 0.2387860082304527,\n",
       " 0.2389917695473251,\n",
       " 0.2312757201646091,\n",
       " 0.24063786008230453,\n",
       " 0.23919753086419757,\n",
       " 0.2376543209876543,\n",
       " 0.24084362139917695,\n",
       " 0.23508230452674897,\n",
       " 0.2366255144032922,\n",
       " 0.24886831275720164,\n",
       " 0.24619341563786007,\n",
       " 0.2435185185185185,\n",
       " 0.24074074074074073,\n",
       " 0.23220164609053498,\n",
       " 0.22397119341563787,\n",
       " 0.24609053497942388,\n",
       " 0.24495884773662552,\n",
       " 0.23065843621399176,\n",
       " 0.2317901234567901,\n",
       " 0.23796296296296296,\n",
       " 0.2287037037037037,\n",
       " 0.24084362139917695,\n",
       " 0.22839506172839505,\n",
       " 0.22489711934156378,\n",
       " 0.24331275720164605,\n",
       " 0.23919753086419757,\n",
       " 0.23240740740740742,\n",
       " 0.2362139917695473,\n",
       " 0.23014403292181068,\n",
       " 0.23960905349794234,\n",
       " 0.2247942386831276,\n",
       " 0.2344650205761317,\n",
       " 0.22613168724279833,\n",
       " 0.20833333333333334,\n",
       " 0.23076131687242804,\n",
       " 0.22304526748971196,\n",
       " 0.23179012345679015,\n",
       " 0.24043209876543212,\n",
       " 0.23251028806584362,\n",
       " 0.22417695473251026,\n",
       " 0.2246913580246914,\n",
       " 0.23919753086419757,\n",
       " 0.22561728395061736,\n",
       " 0.2189300411522634,\n",
       " 0.23312757201646092,\n",
       " 0.21553497942386832,\n",
       " 0.23765432098765432,\n",
       " 0.22983539094650204,\n",
       " 0.22746913580246916,\n",
       " 0.23292181069958848,\n",
       " 0.2219135802469136,\n",
       " 0.2317901234567901,\n",
       " 0.22499999999999998,\n",
       " 0.21491769547325107,\n",
       " 0.21491769547325107,\n",
       " 0.23209876543209876,\n",
       " 0.21944444444444447,\n",
       " 0.21985596707818933,\n",
       " 0.2226337448559671,\n",
       " 0.22067901234567908,\n",
       " 0.2215020576131687,\n",
       " 0.22901234567901232,\n",
       " 0.2247942386831276,\n",
       " 0.20987654320987653,\n",
       " 0.2424897119341564,\n",
       " 0.22757201646090539,\n",
       " 0.22304526748971193,\n",
       " 0.21275720164609055,\n",
       " 0.21841563786008233,\n",
       " 0.22592592592592592,\n",
       " 0.2220164609053498,\n",
       " 0.22880658436213994,\n",
       " 0.22592592592592595,\n",
       " 0.22695473251028805,\n",
       " 0.23199588477366254,\n",
       " 0.21646090534979423,\n",
       " 0.2176954732510288,\n",
       " 0.2226337448559671,\n",
       " 0.21728395061728398,\n",
       " 0.2204732510288066,\n",
       " 0.23261316872427984,\n",
       " 0.22222222222222227,\n",
       " 0.20524691358024688,\n",
       " 0.21347736625514407,\n",
       " 0.21800411522633745,\n",
       " 0.22160493827160496,\n",
       " 0.21800411522633747,\n",
       " 0.22273662551440332,\n",
       " 0.2141975308641975,\n",
       " 0.20555555555555557,\n",
       " 0.22037037037037036,\n",
       " 0.21080246913580247,\n",
       " 0.22685185185185186,\n",
       " 0.2138888888888889,\n",
       " 0.22613168724279836,\n",
       " 0.2130658436213992,\n",
       " 0.21337448559670785,\n",
       " 0.21738683127572014,\n",
       " 0.21378600823045263,\n",
       " 0.2332304526748971,\n",
       " 0.19660493827160497,\n",
       " 0.21820987654320984,\n",
       " 0.2277777777777778,\n",
       " 0.21872427983539092,\n",
       " 0.19938271604938276,\n",
       " 0.20792181069958848,\n",
       " 0.2090534979423868,\n",
       " 0.21594650205761315,\n",
       " 0.21265432098765433,\n",
       " 0.21059670781893003,\n",
       " 0.21419753086419752,\n",
       " 0.19907407407407407,\n",
       " 0.20555555555555557,\n",
       " 0.202880658436214,\n",
       " 0.2152263374485597,\n",
       " 0.21172839506172836,\n",
       " 0.21574074074074076,\n",
       " 0.20462962962962963,\n",
       " 0.19660493827160494,\n",
       " 0.20709876543209876,\n",
       " 0.20390946502057614,\n",
       " 0.20072016460905354,\n",
       " 0.20586419753086418,\n",
       " 0.2020576131687243,\n",
       " 0.20072016460905348,\n",
       " 0.2059670781893004,\n",
       " 0.2070987654320988,\n",
       " 0.2042181069958848,\n",
       " 0.20977366255144037,\n",
       " 0.2205761316872428,\n",
       " 0.21676954732510292,\n",
       " 0.19948559670781896,\n",
       " 0.20853909465020576,\n",
       " 0.20226337448559675,\n",
       " 0.19660493827160494,\n",
       " 0.19537037037037036,\n",
       " 0.192283950617284,\n",
       " 0.21810699588477364,\n",
       " 0.1998971193415638,\n",
       " 0.20020576131687243,\n",
       " 0.20524691358024694,\n",
       " 0.19773662551440335,\n",
       " 0.20668724279835396,\n",
       " 0.19927983539094646,\n",
       " 0.21059670781893003,\n",
       " 0.2073045267489712,\n",
       " 0.19197530864197535,\n",
       " 0.1946502057613169,\n",
       " 0.2034979423868313,\n",
       " 0.20174897119341567,\n",
       " 0.19557613168724283,\n",
       " 0.19660493827160488,\n",
       " 0.19475308641975314,\n",
       " 0.19969135802469135,\n",
       " 0.20226337448559673,\n",
       " 0.2063786008230453,\n",
       " 0.20884773662551445,\n",
       " 0.19423868312757206,\n",
       " 0.21069958847736625,\n",
       " 0.19804526748971196,\n",
       " 0.19362139917695476,\n",
       " 0.18240740740740743,\n",
       " 0.20504115226337458,\n",
       " 0.195679012345679,\n",
       " 0.20010288065843623,\n",
       " 0.185082304526749,\n",
       " 0.2004115226337449,\n",
       " 0.17993827160493828,\n",
       " 0.20246913580246917,\n",
       " 0.20144032921810703,\n",
       " 0.18827160493827158,\n",
       " 0.207201646090535,\n",
       " 0.19753086419753088,\n",
       " 0.19897119341563785,\n",
       " 0.2036008230452675,\n",
       " 0.19156378600823046,\n",
       " 0.1880658436213992,\n",
       " 0.2019547325102881,\n",
       " 0.18858024691358025,\n",
       " 0.19022633744855966,\n",
       " 0.18960905349794235,\n",
       " 0.197119341563786,\n",
       " 0.19393004115226342,\n",
       " 0.18930041152263377,\n",
       " 0.19609053497942386,\n",
       " 0.18631687242798353,\n",
       " 0.18991769547325105,\n",
       " 0.18837448559670786,\n",
       " 0.20576131687242802,\n",
       " 0.19681069958847738,\n",
       " 0.1863168724279836,\n",
       " 0.19609053497942389,\n",
       " 0.20174897119341562,\n",
       " 0.18796296296296297,\n",
       " 0.19187242798353912,\n",
       " 0.19619341563786008,\n",
       " 0.18034979423868314,\n",
       " 0.20226337448559675,\n",
       " 0.1969135802469136,\n",
       " 0.18086419753086422,\n",
       " 0.17283950617283952,\n",
       " 0.1983539094650206,\n",
       " 0.1917695473251029,\n",
       " 0.19022633744855966,\n",
       " 0.18065843621399175,\n",
       " 0.18940329218107,\n",
       " 0.186522633744856,\n",
       " 0.19372427983539098,\n",
       " 0.18004115226337444,\n",
       " 0.1962962962962963,\n",
       " 0.17489711934156377,\n",
       " 0.18816872427983544,\n",
       " 0.19701646090534983,\n",
       " 0.1980452674897119,\n",
       " 0.18497942386831276,\n",
       " 0.18528806584362142,\n",
       " 0.18724279835390945,\n",
       " 0.1844650205761317,\n",
       " 0.18189300411522635,\n",
       " 0.19320987654320992,\n",
       " 0.1824074074074074,\n",
       " 0.1800411522633745,\n",
       " 0.19475308641975306,\n",
       " 0.1874485596707819,\n",
       " 0.17983539094650206,\n",
       " 0.1786008230452675,\n",
       " 0.18909465020576133,\n",
       " 0.18981481481481483,\n",
       " 0.18168724279835388,\n",
       " 0.19125514403292185,\n",
       " 0.18487654320987656,\n",
       " 0.1827160493827161,\n",
       " 0.17901234567901236,\n",
       " 0.18436213991769548,\n",
       " 0.18220164609053505,\n",
       " 0.17788065843621403,\n",
       " 0.1955761316872428,\n",
       " 0.1872427983539095,\n",
       " 0.18374485596707824,\n",
       " 0.18878600823045272,\n",
       " 0.18652263374485598,\n",
       " 0.1782921810699589,\n",
       " 0.18374485596707824,\n",
       " 0.1777777777777778,\n",
       " 0.1862139917695473,\n",
       " 0.18230452674897116,\n",
       " 0.1799382716049383,\n",
       " 0.18117283950617283,\n",
       " 0.17345679012345683,\n",
       " 0.18220164609053505,\n",
       " 0.17798353909465023,\n",
       " 0.17983539094650206,\n",
       " 0.1828189300411523,\n",
       " 0.18508230452674898,\n",
       " 0.15720164609053502,\n",
       " 0.18816872427983536,\n",
       " 0.17304526748971194,\n",
       " 0.18055555555555555,\n",
       " 0.17767489711934153,\n",
       " 0.18106995884773663,\n",
       " 0.18034979423868314,\n",
       " 0.18261316872427985,\n",
       " 0.17849794238683134,\n",
       " 0.17530864197530865,\n",
       " 0.16882716049382718,\n",
       " 0.16707818930041152,\n",
       " 0.176440329218107,\n",
       " 0.17458847736625513,\n",
       " 0.18045267489711936,\n",
       " 0.16954732510288067,\n",
       " 0.18672839506172842,\n",
       " 0.17458847736625516,\n",
       " 0.16378600823045272,\n",
       " 0.17736625514403292,\n",
       " 0.18179012345679016,\n",
       " 0.1763374485596708,\n",
       " 0.16882716049382718,\n",
       " 0.16862139917695473,\n",
       " 0.17880658436213995,\n",
       " 0.17942386831275722,\n",
       " 0.17304526748971197,\n",
       " 0.17355967078189302,\n",
       " 0.17283950617283955,\n",
       " 0.17582304526748976,\n",
       " 0.17572016460905357,\n",
       " 0.17541152263374488,\n",
       " 0.17283950617283952,\n",
       " 0.16872427983539098,\n",
       " 0.1725308641975309,\n",
       " 0.17139917695473253,\n",
       " 0.1752057613168725,\n",
       " 0.17222222222222228,\n",
       " 0.16779835390946504,\n",
       " 0.16697530864197535,\n",
       " 0.17427983539094655,\n",
       " 0.17726337448559668,\n",
       " 0.16471193415637858,\n",
       " 0.1667695473251029,\n",
       " 0.17983539094650208,\n",
       " 0.16481481481481483,\n",
       " 0.17355967078189302,\n",
       " 0.1638888888888889,\n",
       " 0.16707818930041154,\n",
       " 0.17510288065843624,\n",
       " 0.17757201646090534,\n",
       " 0.1756172839506173,\n",
       " 0.16985596707818928,\n",
       " 0.15504115226337448,\n",
       " 0.17880658436213995,\n",
       " 0.1737654320987655,\n",
       " 0.1653292181069959,\n",
       " 0.17273662551440333,\n",
       " 0.17006172839506173,\n",
       " 0.17150205761316875,\n",
       " 0.16594650205761316,\n",
       " 0.16512345679012347,\n",
       " 0.16738683127572015,\n",
       " 0.15462962962962964,\n",
       " 0.16738683127572018,\n",
       " 0.1667695473251029,\n",
       " 0.1698559670781893,\n",
       " 0.15843621399176958,\n",
       " 0.172119341563786,\n",
       " 0.16975308641975312,\n",
       " 0.16090534979423873,\n",
       " 0.1578189300411523,\n",
       " 0.16738683127572018,\n",
       " 0.16039094650205762,\n",
       " 0.17705761316872431,\n",
       " 0.170679012345679,\n",
       " 0.16646090534979427,\n",
       " 0.17613168724279835,\n",
       " 0.15329218106995887,\n",
       " 0.16954732510288067,\n",
       " 0.16059670781893004,\n",
       " 0.15761316872427983,\n",
       " 0.1580246913580247,\n",
       " 0.16872427983539098,\n",
       " 0.16419753086419753,\n",
       " 0.15802469135802472,\n",
       " 0.1740740740740741,\n",
       " 0.16162551440329218,\n",
       " 0.16851851851851854,\n",
       " 0.1637860082304527,\n",
       " 0.16316872427983536,\n",
       " 0.16543209876543213,\n",
       " 0.1668724279835391,\n",
       " 0.1609053497942387,\n",
       " 0.16718106995884774,\n",
       " 0.1551440329218107,\n",
       " 0.16851851851851854,\n",
       " 0.15987654320987657,\n",
       " 0.16512345679012347,\n",
       " 0.16172839506172848,\n",
       " 0.14794238683127572,\n",
       " 0.17294238683127575,\n",
       " 0.1564814814814815,\n",
       " 0.16069958847736632,\n",
       " 0.16141975308641973,\n",
       " 0.16769547325102888,\n",
       " 0.16152263374485598,\n",
       " 0.16141975308641976,\n",
       " 0.1551440329218107,\n",
       " 0.15987654320987657,\n",
       " 0.17530864197530865,\n",
       " 0.1561728395061729,\n",
       " 0.16532921810699588,\n",
       " 0.15627572016460908,\n",
       " 0.15720164609053497,\n",
       " 0.1666666666666667,\n",
       " 0.16697530864197535,\n",
       " 0.1534979423868313,\n",
       " 0.15288065843621398,\n",
       " 0.16584362139917694,\n",
       " 0.16625514403292177,\n",
       " 0.16286008230452675,\n",
       " 0.16831275720164612,\n",
       " 0.16584362139917694,\n",
       " 0.1581275720164609,\n",
       " 0.1502057613168724,\n",
       " 0.16286008230452675,\n",
       " 0.14958847736625513,\n",
       " 0.15843621399176955,\n",
       " 0.16347736625514403,\n",
       " 0.1610082304526749,\n",
       " 0.14835390946502058,\n",
       " 0.15689300411522636,\n",
       " 0.1558641975308642,\n",
       " 0.15833333333333335,\n",
       " 0.15751028806584363,\n",
       " 0.15092592592592596,\n",
       " 0.1472222222222222,\n",
       " 0.14207818930041152,\n",
       " 0.15257201646090535,\n",
       " 0.15041152263374485,\n",
       " 0.1597736625514403,\n",
       " 0.15740740740740744,\n",
       " 0.1577160493827161,\n",
       " 0.15730452674897122,\n",
       " 0.16522633744855966,\n",
       " 0.15751028806584366,\n",
       " 0.1521604938271605,\n",
       " 0.15390946502057612,\n",
       " 0.15205761316872426,\n",
       " 0.14979423868312758,\n",
       " 0.15236625514403296,\n",
       " 0.1627572016460906,\n",
       " 0.16584362139917697,\n",
       " 0.15195473251028807,\n",
       " 0.14701646090534978,\n",
       " 0.14670781893004115,\n",
       " 0.15709876543209877,\n",
       " 0.14979423868312758,\n",
       " 0.15997942386831276,\n",
       " 0.1533950617283951,\n",
       " 0.1529835390946502,\n",
       " ...]"
      ]
     },
     "execution_count": 805,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crbm.training_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.- SRBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Socially Restricted Boltzmann Machine\n",
    "class SRBM :\n",
    "    \n",
    "    def __init__(self, num_visible, num_hidden, num_historic, learning_rate, batch_size, num_epochs):\n",
    "        self.num_visible = num_visible\n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_historic = num_historic\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        \n",
    "        # Initialize weights and biases\n",
    "        self.W = np.random.normal(scale=0.1, size=(num_visible, num_hidden))\n",
    "        self.a = np.zeros(num_visible)\n",
    "        self.b = np.zeros(num_hidden)\n",
    "        \n",
    "        # Initialize autoregreesive parameters\n",
    "        self.A = np.random.normal(scale=0.01, size=(num_visible, num_historic))\n",
    "        self.B = np.random.normal(scale=0.01, size=(num_hidden, num_historic))\n",
    "    \n",
    "    # Calculate the sigmoid of X \n",
    "    def sigmoid(self, X):\n",
    "        return 1 / (1 + np.exp(-1*X))\n",
    "    \n",
    "    # Sample the activations given a certain matrix of probabilities\n",
    "    def sample(self, X):\n",
    "        return X > np.random.random_sample(size=X.shape)\n",
    "    \n",
    "    # Perform a reconstruction of the input data X\n",
    "    def gibbs_sample(self, X):\n",
    "        \n",
    "        # Create Historic layer\n",
    "        H = np.tile(self.historic, (len(X), 1))\n",
    "        \n",
    "        # Separate input vector\n",
    "        V = np.array(X.values[:, :3])\n",
    "\n",
    "        # Positive phase\n",
    "\n",
    "        # Calculate the contributions from the Historic layer\n",
    "        dinamic_b = self.b + H.dot(self.B.T)\n",
    "\n",
    "        # Calculate the activations of the Hidden layer\n",
    "        positive_hidden = sigmoid(V.dot(self.W) + dinamic_b)\n",
    "        hidden_states = sample(positive_hidden)\n",
    "\n",
    "        # Negative phase\n",
    "\n",
    "        #Calculate the contributions from the Historic layer\n",
    "        dinamic_a = self.a + H.dot(self.A.T)\n",
    "        \n",
    "        # Calculate the activations of the Visible layer\n",
    "        negative_visible = sigmoid(hidden_states.dot(self.W.T) + dinamic_a)\n",
    "        visible_states = sample(negative_visible)\n",
    "        return visible_states\n",
    "    \n",
    "    # Get the hidden probabilities for a certain input\n",
    "    def transform(self, X):\n",
    "        # Separate input vector\n",
    "        V = np.array(X.values[:, :3])\n",
    "        # Create Historic layer\n",
    "        H = np.tile(self.historic, (len(X), 1))\n",
    "        dinamic_b = self.b + H.dot(self.B.T)\n",
    "        return self.sigmoid(X.dot(self.W) + dinamic_b)\n",
    "    \n",
    "    def train(self, X):\n",
    "        \n",
    "        # Define matrix to keep track of the training MSE\n",
    "        self.training_errors = []\n",
    "        \n",
    "        self.historic = []\n",
    "        for id in X.values[:, 3:]:\n",
    "            for value in id:\n",
    "                self.historic.append(value)\n",
    "        \n",
    "        for epoch in range(self.num_epochs):\n",
    "            \n",
    "            batch_errors = []\n",
    "            \n",
    "            for batch in batch_iterator(X, batch_size=self.batch_size):\n",
    "                \n",
    "                # Separate input vector\n",
    "                V = np.array(batch.values[:, :3])   \n",
    "                \n",
    "                # Create Historic layer\n",
    "                H = np.tile(self.historic, (len(batch), 1))\n",
    "                #print H.shape\n",
    "                \n",
    "                # Positive phase\n",
    "                # Calculate the contributions from the Historic layer\n",
    "                dinamic_b = self.b + H.dot(self.B.T)\n",
    "                \n",
    "                # Calculate the activations of the hidden layer\n",
    "                positive_hidden_probs = self.sigmoid(V.dot(self.W) + dinamic_b)\n",
    "                positive_hidden_states = self.sample(positive_hidden_probs)\n",
    "                \n",
    "                # Calculate vh_data using the positive hidden probabilities, rather than their activations\n",
    "                # as per Hinton (2010)\n",
    "                vh_data = V.T.dot(positive_hidden_probs)\n",
    "                \n",
    "                # Calculate vH_data (H: Historic layer)\n",
    "                vH_data = V.T.dot(H)\n",
    "                # Calculate hH_data (H: Historic layer)\n",
    "                hH_data = positive_hidden_states.T.dot(H)\n",
    "                \n",
    "                \n",
    "                \n",
    "                # Negative phase\n",
    "                \n",
    "                # Calculate the contributions from the Historic layer\n",
    "                dinamic_a = self.a + H.dot(self.A.T)\n",
    "                \n",
    "                negative_visible_probs = self.sigmoid(positive_hidden_states.dot(self.W.T) + dinamic_a)\n",
    "                negative_visible_states = self.sample(negative_visible_probs)\n",
    "                negative_hidden_probs = self.sigmoid(negative_visible_states.dot(self.W) + dinamic_b)\n",
    "                negative_hidden_states = self.sample(negative_hidden_probs)\n",
    "                \n",
    "                # Calculate vh_reconstruction using the negative hidden states probabilities\n",
    "                vh_reconstruction = negative_visible_states.T.dot(negative_hidden_probs)\n",
    "                \n",
    "                # Calculate vH_reconstruction (H: Historic layer)\n",
    "                vH_reconstruction = negative_visible_states.T.dot(H)\n",
    "                # Calculate hH_reconstruction (H: Historic layer)\n",
    "                hH_reconstruction = negative_hidden_states.T.dot(H)\n",
    "                \n",
    "                # Update weights and biases\n",
    "                self.W += self.learning_rate * (vh_data - vh_reconstruction)\n",
    "                self.b += self.learning_rate * (positive_hidden_probs.sum(axis=0) - negative_hidden_probs.sum(axis=0))\n",
    "                self.a += self.learning_rate * (V.sum(axis=0) - negative_visible_probs.sum(axis=0))\n",
    "                self.B += self.learning_rate * 0.001 * (hH_data - hH_reconstruction)\n",
    "                self.A += self.learning_rate * 0.001 * (vH_data - vH_reconstruction)\n",
    "                #print dinamic_a\n",
    "                #print H.dot(self.A.T).sum()\n",
    "                #print dinamic_b\n",
    "                \n",
    "                batch_errors.append(np.mean((V - negative_visible_states) ** 2))\n",
    "            print \"Epoch \" + str(epoch) + \" - MSE: \" + str(np.mean(batch_errors))                        \n",
    "            self.training_errors.append(np.mean(batch_errors))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "srbm = SRBM(3, 500, 9684, 0.001, 10, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - MSE: 0.39732510288065837\n",
      "Epoch 1 - MSE: 0.38796296296296295\n",
      "Epoch 2 - MSE: 0.3731481481481481\n",
      "Epoch 3 - MSE: 0.38014403292181065\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-9d57c4995af1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msrbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-03fd1204a3c0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mvH_reconstruction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnegative_visible_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0;31m# Calculate hH_reconstruction (H: Historic layer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                 \u001b[0mhH_reconstruction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnegative_hidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0;31m# Update weights and biases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "srbm.train(X_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.- Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = X_0.shape[-1]\n",
    "encoding_dim = 4\n",
    "\n",
    "# Define the input layer\n",
    "inputs = Input(shape=(dim,))\n",
    "\n",
    "# Define the encoding layer (turns inputs into an encoded representation)\n",
    "encoded = Dense(encoding_dim, activation='relu')(inputs)\n",
    "\n",
    "# Define the decoding layer (turns the encoded representation into a decoded output)\n",
    "decoded = Dense(dim, activation='sigmoid')(encoded)\n",
    "\n",
    "# Define the autoencoder\n",
    "autoencoder = Model(inputs, decoded)\n",
    "\n",
    "# Define the encoder (this will be used for the classification purposes)\n",
    "encoder = Model(inputs, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the autoencoder\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1076/1076 [==============================] - 0s 25us/step - loss: 0.6798\n",
      "Epoch 2/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.6430\n",
      "Epoch 3/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.6080\n",
      "Epoch 4/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.5681\n",
      "Epoch 5/500\n",
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.5225\n",
      "Epoch 6/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.4822\n",
      "Epoch 7/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.4526\n",
      "Epoch 8/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.4306\n",
      "Epoch 9/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.4140\n",
      "Epoch 10/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.4007\n",
      "Epoch 11/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.3901\n",
      "Epoch 12/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.3814\n",
      "Epoch 13/500\n",
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.3740\n",
      "Epoch 14/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.3676\n",
      "Epoch 15/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.3620\n",
      "Epoch 16/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.3568\n",
      "Epoch 17/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.3525\n",
      "Epoch 18/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.3482\n",
      "Epoch 19/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.3444\n",
      "Epoch 20/500\n",
      "1076/1076 [==============================] - 0s 34us/step - loss: 0.3410\n",
      "Epoch 21/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.3375\n",
      "Epoch 22/500\n",
      "1076/1076 [==============================] - 0s 35us/step - loss: 0.3344\n",
      "Epoch 23/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.3317\n",
      "Epoch 24/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.3289\n",
      "Epoch 25/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.3262\n",
      "Epoch 26/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.3237\n",
      "Epoch 27/500\n",
      "1076/1076 [==============================] - 0s 25us/step - loss: 0.3215\n",
      "Epoch 28/500\n",
      "1076/1076 [==============================] - 0s 25us/step - loss: 0.3192\n",
      "Epoch 29/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.3170\n",
      "Epoch 30/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.3149\n",
      "Epoch 31/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.3129\n",
      "Epoch 32/500\n",
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.3109\n",
      "Epoch 33/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.3091\n",
      "Epoch 34/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.3073\n",
      "Epoch 35/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.3056\n",
      "Epoch 36/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.3040\n",
      "Epoch 37/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.3022\n",
      "Epoch 38/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.3007\n",
      "Epoch 39/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2992\n",
      "Epoch 40/500\n",
      "1076/1076 [==============================] - 0s 25us/step - loss: 0.2978\n",
      "Epoch 41/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2964\n",
      "Epoch 42/500\n",
      "1076/1076 [==============================] - 0s 25us/step - loss: 0.2947\n",
      "Epoch 43/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2936\n",
      "Epoch 44/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2921\n",
      "Epoch 45/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2909\n",
      "Epoch 46/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2896\n",
      "Epoch 47/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2884\n",
      "Epoch 48/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2870\n",
      "Epoch 49/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2861\n",
      "Epoch 50/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2849\n",
      "Epoch 51/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2837\n",
      "Epoch 52/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2828\n",
      "Epoch 53/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2817\n",
      "Epoch 54/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2806\n",
      "Epoch 55/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2798\n",
      "Epoch 56/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2789\n",
      "Epoch 57/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2778\n",
      "Epoch 58/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2769\n",
      "Epoch 59/500\n",
      "1076/1076 [==============================] - 0s 34us/step - loss: 0.2759\n",
      "Epoch 60/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2752\n",
      "Epoch 61/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2744\n",
      "Epoch 62/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2734\n",
      "Epoch 63/500\n",
      "1076/1076 [==============================] - 0s 34us/step - loss: 0.2726\n",
      "Epoch 64/500\n",
      "1076/1076 [==============================] - 0s 33us/step - loss: 0.2718\n",
      "Epoch 65/500\n",
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.2713\n",
      "Epoch 66/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2704\n",
      "Epoch 67/500\n",
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.2697\n",
      "Epoch 68/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2688\n",
      "Epoch 69/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2682\n",
      "Epoch 70/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2674\n",
      "Epoch 71/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2670\n",
      "Epoch 72/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2662\n",
      "Epoch 73/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2654\n",
      "Epoch 74/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2650\n",
      "Epoch 75/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2644\n",
      "Epoch 76/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2637\n",
      "Epoch 77/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2633\n",
      "Epoch 78/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2625\n",
      "Epoch 79/500\n",
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.2619\n",
      "Epoch 80/500\n",
      "1076/1076 [==============================] - 0s 34us/step - loss: 0.2616\n",
      "Epoch 81/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2607\n",
      "Epoch 82/500\n",
      "1076/1076 [==============================] - 0s 37us/step - loss: 0.2604\n",
      "Epoch 83/500\n",
      "1076/1076 [==============================] - 0s 35us/step - loss: 0.2597\n",
      "Epoch 84/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2592\n",
      "Epoch 85/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2586\n",
      "Epoch 86/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2583\n",
      "Epoch 87/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2579\n",
      "Epoch 88/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2573\n",
      "Epoch 89/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2567\n",
      "Epoch 90/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2562\n",
      "Epoch 91/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2558\n",
      "Epoch 92/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2554\n",
      "Epoch 93/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2548\n",
      "Epoch 94/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2544\n",
      "Epoch 95/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2538\n",
      "Epoch 96/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2533\n",
      "Epoch 97/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2530\n",
      "Epoch 98/500\n",
      "1076/1076 [==============================] - 0s 25us/step - loss: 0.2525\n",
      "Epoch 99/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2522\n",
      "Epoch 100/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2516\n",
      "Epoch 101/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2511\n",
      "Epoch 102/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2508\n",
      "Epoch 103/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2503\n",
      "Epoch 104/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2500\n",
      "Epoch 105/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2496\n",
      "Epoch 106/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2490\n",
      "Epoch 107/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2486\n",
      "Epoch 108/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2481\n",
      "Epoch 109/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2477\n",
      "Epoch 110/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2472\n",
      "Epoch 111/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2470\n",
      "Epoch 112/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2464\n",
      "Epoch 113/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2463\n",
      "Epoch 114/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2457\n",
      "Epoch 115/500\n",
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.2454\n",
      "Epoch 116/500\n",
      "1076/1076 [==============================] - 0s 35us/step - loss: 0.2448\n",
      "Epoch 117/500\n",
      "1076/1076 [==============================] - 0s 36us/step - loss: 0.2444\n",
      "Epoch 118/500\n",
      "1076/1076 [==============================] - 0s 33us/step - loss: 0.2440\n",
      "Epoch 119/500\n",
      "1076/1076 [==============================] - 0s 35us/step - loss: 0.2436\n",
      "Epoch 120/500\n",
      "1076/1076 [==============================] - 0s 33us/step - loss: 0.2432\n",
      "Epoch 121/500\n",
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.2426\n",
      "Epoch 122/500\n",
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.2424\n",
      "Epoch 123/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2419\n",
      "Epoch 124/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2416\n",
      "Epoch 125/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2412\n",
      "Epoch 126/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2408\n",
      "Epoch 127/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2403\n",
      "Epoch 128/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2400\n",
      "Epoch 129/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2397\n",
      "Epoch 130/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2393\n",
      "Epoch 131/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2389\n",
      "Epoch 132/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2385\n",
      "Epoch 133/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2381\n",
      "Epoch 134/500\n",
      "1076/1076 [==============================] - 0s 33us/step - loss: 0.2378\n",
      "Epoch 135/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2374\n",
      "Epoch 136/500\n",
      "1076/1076 [==============================] - 0s 36us/step - loss: 0.2371\n",
      "Epoch 137/500\n",
      "1076/1076 [==============================] - 0s 34us/step - loss: 0.2367\n",
      "Epoch 138/500\n",
      "1076/1076 [==============================] - 0s 34us/step - loss: 0.2364\n",
      "Epoch 139/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2360\n",
      "Epoch 140/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2357\n",
      "Epoch 141/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2353\n",
      "Epoch 142/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2350\n",
      "Epoch 143/500\n",
      "1076/1076 [==============================] - 0s 35us/step - loss: 0.2347\n",
      "Epoch 144/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2344\n",
      "Epoch 145/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2341\n",
      "Epoch 146/500\n",
      "1076/1076 [==============================] - 0s 64us/step - loss: 0.2339\n",
      "Epoch 147/500\n",
      "1076/1076 [==============================] - 0s 37us/step - loss: 0.2336\n",
      "Epoch 148/500\n",
      "1076/1076 [==============================] - 0s 36us/step - loss: 0.2332\n",
      "Epoch 149/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2329\n",
      "Epoch 150/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2328\n",
      "Epoch 151/500\n",
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.2325\n",
      "Epoch 152/500\n",
      "1076/1076 [==============================] - 0s 33us/step - loss: 0.2322\n",
      "Epoch 153/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2321\n",
      "Epoch 154/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2318\n",
      "Epoch 155/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2317\n",
      "Epoch 156/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2313\n",
      "Epoch 157/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2310\n",
      "Epoch 158/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2309\n",
      "Epoch 159/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2307\n",
      "Epoch 160/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2307\n",
      "Epoch 161/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2303\n",
      "Epoch 162/500\n",
      "1076/1076 [==============================] - 0s 42us/step - loss: 0.2301\n",
      "Epoch 163/500\n",
      "1076/1076 [==============================] - 0s 34us/step - loss: 0.2300\n",
      "Epoch 164/500\n",
      "1076/1076 [==============================] - 0s 33us/step - loss: 0.2298\n",
      "Epoch 165/500\n",
      "1076/1076 [==============================] - 0s 33us/step - loss: 0.2296\n",
      "Epoch 166/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2294\n",
      "Epoch 167/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2293\n",
      "Epoch 168/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2290\n",
      "Epoch 169/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2289\n",
      "Epoch 170/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2288\n",
      "Epoch 171/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2287\n",
      "Epoch 172/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2286\n",
      "Epoch 173/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2284\n",
      "Epoch 174/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2283\n",
      "Epoch 175/500\n",
      "1076/1076 [==============================] - 0s 37us/step - loss: 0.2281\n",
      "Epoch 176/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2280\n",
      "Epoch 177/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2278\n",
      "Epoch 178/500\n",
      "1076/1076 [==============================] - 0s 34us/step - loss: 0.2279\n",
      "Epoch 179/500\n",
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.2278\n",
      "Epoch 180/500\n",
      "1076/1076 [==============================] - 0s 33us/step - loss: 0.2275\n",
      "Epoch 181/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2274\n",
      "Epoch 182/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2274\n",
      "Epoch 183/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2272\n",
      "Epoch 184/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2274\n",
      "Epoch 185/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2271\n",
      "Epoch 186/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2271\n",
      "Epoch 187/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2268\n",
      "Epoch 188/500\n",
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.2268\n",
      "Epoch 189/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2267\n",
      "Epoch 190/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2265\n",
      "Epoch 191/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2267\n",
      "Epoch 192/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2266\n",
      "Epoch 193/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2264\n",
      "Epoch 194/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2265\n",
      "Epoch 195/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2262\n",
      "Epoch 196/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2262\n",
      "Epoch 197/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2262\n",
      "Epoch 198/500\n",
      "1076/1076 [==============================] - 0s 43us/step - loss: 0.2261\n",
      "Epoch 199/500\n",
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.2260\n",
      "Epoch 200/500\n",
      "1076/1076 [==============================] - 0s 33us/step - loss: 0.2259\n",
      "Epoch 201/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2258\n",
      "Epoch 202/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2258\n",
      "Epoch 203/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2257\n",
      "Epoch 204/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2255\n",
      "Epoch 205/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2257\n",
      "Epoch 206/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2254\n",
      "Epoch 207/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2255\n",
      "Epoch 208/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2253\n",
      "Epoch 209/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2253\n",
      "Epoch 210/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2252\n",
      "Epoch 211/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2252\n",
      "Epoch 212/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2251\n",
      "Epoch 213/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2252\n",
      "Epoch 214/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2249\n",
      "Epoch 215/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2249\n",
      "Epoch 216/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2248\n",
      "Epoch 217/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2248\n",
      "Epoch 218/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2248\n",
      "Epoch 219/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2249\n",
      "Epoch 220/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2247\n",
      "Epoch 221/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2247\n",
      "Epoch 222/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2246\n",
      "Epoch 223/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2245\n",
      "Epoch 224/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2244\n",
      "Epoch 225/500\n",
      "1076/1076 [==============================] - 0s 33us/step - loss: 0.2244\n",
      "Epoch 226/500\n",
      "1076/1076 [==============================] - 0s 25us/step - loss: 0.2245\n",
      "Epoch 227/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2244\n",
      "Epoch 228/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2243\n",
      "Epoch 229/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2242\n",
      "Epoch 230/500\n",
      "1076/1076 [==============================] - 0s 25us/step - loss: 0.2242\n",
      "Epoch 231/500\n",
      "1076/1076 [==============================] - 0s 25us/step - loss: 0.2240\n",
      "Epoch 232/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2241\n",
      "Epoch 233/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2241\n",
      "Epoch 234/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2241\n",
      "Epoch 235/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2239\n",
      "Epoch 236/500\n",
      "1076/1076 [==============================] - 0s 24us/step - loss: 0.2238\n",
      "Epoch 237/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2241\n",
      "Epoch 238/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2239\n",
      "Epoch 239/500\n",
      "1076/1076 [==============================] - 0s 33us/step - loss: 0.2237\n",
      "Epoch 240/500\n",
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.2239\n",
      "Epoch 241/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2236\n",
      "Epoch 242/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2236\n",
      "Epoch 243/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2237\n",
      "Epoch 244/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2236\n",
      "Epoch 245/500\n",
      "1076/1076 [==============================] - 0s 25us/step - loss: 0.2236\n",
      "Epoch 246/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2235\n",
      "Epoch 247/500\n",
      "1076/1076 [==============================] - 0s 24us/step - loss: 0.2234\n",
      "Epoch 248/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2236\n",
      "Epoch 249/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2233\n",
      "Epoch 250/500\n",
      "1076/1076 [==============================] - 0s 25us/step - loss: 0.2234\n",
      "Epoch 251/500\n",
      "1076/1076 [==============================] - 0s 25us/step - loss: 0.2232\n",
      "Epoch 252/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2233\n",
      "Epoch 253/500\n",
      "1076/1076 [==============================] - 0s 25us/step - loss: 0.2230\n",
      "Epoch 254/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2231\n",
      "Epoch 255/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2234\n",
      "Epoch 256/500\n",
      "1076/1076 [==============================] - 0s 25us/step - loss: 0.2230\n",
      "Epoch 257/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2231\n",
      "Epoch 258/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2230\n",
      "Epoch 259/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2229\n",
      "Epoch 260/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2229\n",
      "Epoch 261/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2230\n",
      "Epoch 262/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2233\n",
      "Epoch 263/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2231\n",
      "Epoch 264/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2227\n",
      "Epoch 265/500\n",
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.2228\n",
      "Epoch 266/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2226\n",
      "Epoch 267/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2228\n",
      "Epoch 268/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2226\n",
      "Epoch 269/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2227\n",
      "Epoch 270/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2227\n",
      "Epoch 271/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2225\n",
      "Epoch 272/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2227\n",
      "Epoch 273/500\n",
      "1076/1076 [==============================] - 0s 33us/step - loss: 0.2226\n",
      "Epoch 274/500\n",
      "1076/1076 [==============================] - 0s 33us/step - loss: 0.2225\n",
      "Epoch 275/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2225\n",
      "Epoch 276/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2224\n",
      "Epoch 277/500\n",
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.2222\n",
      "Epoch 278/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2224\n",
      "Epoch 279/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2223\n",
      "Epoch 280/500\n",
      "1076/1076 [==============================] - 0s 33us/step - loss: 0.2223\n",
      "Epoch 281/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2223\n",
      "Epoch 282/500\n",
      "1076/1076 [==============================] - 0s 34us/step - loss: 0.2224\n",
      "Epoch 283/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2225\n",
      "Epoch 284/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.2223\n",
      "Epoch 285/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2222\n",
      "Epoch 286/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2220\n",
      "Epoch 287/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2223\n",
      "Epoch 288/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2221\n",
      "Epoch 289/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2221\n",
      "Epoch 290/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2221\n",
      "Epoch 291/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2220\n",
      "Epoch 292/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2221\n",
      "Epoch 293/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2221\n",
      "Epoch 294/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2221\n",
      "Epoch 295/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2218\n",
      "Epoch 296/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2220\n",
      "Epoch 297/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2219\n",
      "Epoch 298/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2219\n",
      "Epoch 299/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2219\n",
      "Epoch 300/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2218\n",
      "Epoch 301/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2220\n",
      "Epoch 302/500\n",
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.2219\n",
      "Epoch 303/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2217\n",
      "Epoch 304/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2216\n",
      "Epoch 305/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2217\n",
      "Epoch 306/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2217\n",
      "Epoch 307/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2216\n",
      "Epoch 308/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2215\n",
      "Epoch 309/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2217\n",
      "Epoch 310/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2217\n",
      "Epoch 311/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2216\n",
      "Epoch 312/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2214\n",
      "Epoch 313/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2215\n",
      "Epoch 314/500\n",
      "1076/1076 [==============================] - 0s 34us/step - loss: 0.2215\n",
      "Epoch 315/500\n",
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.2215\n",
      "Epoch 316/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2215\n",
      "Epoch 317/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2213\n",
      "Epoch 318/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2215\n",
      "Epoch 319/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2213\n",
      "Epoch 320/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2213\n",
      "Epoch 321/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2215\n",
      "Epoch 322/500\n",
      "1076/1076 [==============================] - 0s 34us/step - loss: 0.2215\n",
      "Epoch 323/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2214\n",
      "Epoch 324/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2214\n",
      "Epoch 325/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2212\n",
      "Epoch 326/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2212\n",
      "Epoch 327/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2211\n",
      "Epoch 328/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2213\n",
      "Epoch 329/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2212\n",
      "Epoch 330/500\n",
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.2212\n",
      "Epoch 331/500\n",
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.2213\n",
      "Epoch 332/500\n",
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.2212\n",
      "Epoch 333/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2212\n",
      "Epoch 334/500\n",
      "1076/1076 [==============================] - 0s 33us/step - loss: 0.2210\n",
      "Epoch 335/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2210\n",
      "Epoch 336/500\n",
      "1076/1076 [==============================] - 0s 36us/step - loss: 0.2210\n",
      "Epoch 337/500\n",
      "1076/1076 [==============================] - 0s 37us/step - loss: 0.2210\n",
      "Epoch 338/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2212\n",
      "Epoch 339/500\n",
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.2210\n",
      "Epoch 340/500\n",
      "1076/1076 [==============================] - 0s 33us/step - loss: 0.2209\n",
      "Epoch 341/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2209\n",
      "Epoch 342/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2210\n",
      "Epoch 343/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2211\n",
      "Epoch 344/500\n",
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.2209\n",
      "Epoch 345/500\n",
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.2207\n",
      "Epoch 346/500\n",
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.2208\n",
      "Epoch 347/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2209\n",
      "Epoch 348/500\n",
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.2208\n",
      "Epoch 349/500\n",
      "1076/1076 [==============================] - 0s 35us/step - loss: 0.2209\n",
      "Epoch 350/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2208\n",
      "Epoch 351/500\n",
      "1076/1076 [==============================] - 0s 39us/step - loss: 0.2208\n",
      "Epoch 352/500\n",
      "1076/1076 [==============================] - 0s 34us/step - loss: 0.2209\n",
      "Epoch 353/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2208\n",
      "Epoch 354/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2208\n",
      "Epoch 355/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2209\n",
      "Epoch 356/500\n",
      "1076/1076 [==============================] - 0s 35us/step - loss: 0.2207\n",
      "Epoch 357/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2208\n",
      "Epoch 358/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2208\n",
      "Epoch 359/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2209\n",
      "Epoch 360/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2208\n",
      "Epoch 361/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2206\n",
      "Epoch 362/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2207\n",
      "Epoch 363/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2206\n",
      "Epoch 364/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2207\n",
      "Epoch 365/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2204\n",
      "Epoch 366/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2205\n",
      "Epoch 367/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2207\n",
      "Epoch 368/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2206\n",
      "Epoch 369/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2204\n",
      "Epoch 370/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2204\n",
      "Epoch 371/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2203\n",
      "Epoch 372/500\n",
      "1076/1076 [==============================] - 0s 25us/step - loss: 0.2204\n",
      "Epoch 373/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2204\n",
      "Epoch 374/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2205\n",
      "Epoch 375/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2206\n",
      "Epoch 376/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2205\n",
      "Epoch 377/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2205\n",
      "Epoch 378/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2204\n",
      "Epoch 379/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2203\n",
      "Epoch 380/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2202\n",
      "Epoch 381/500\n",
      "1076/1076 [==============================] - 0s 33us/step - loss: 0.2202\n",
      "Epoch 382/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2202\n",
      "Epoch 383/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2204\n",
      "Epoch 384/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2202\n",
      "Epoch 385/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2203\n",
      "Epoch 386/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2203\n",
      "Epoch 387/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2202\n",
      "Epoch 388/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2203\n",
      "Epoch 389/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2203\n",
      "Epoch 390/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2203\n",
      "Epoch 391/500\n",
      "1076/1076 [==============================] - 0s 25us/step - loss: 0.2203\n",
      "Epoch 392/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2202\n",
      "Epoch 393/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2201\n",
      "Epoch 394/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2203\n",
      "Epoch 395/500\n",
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.2202\n",
      "Epoch 396/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2201\n",
      "Epoch 397/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2201\n",
      "Epoch 398/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2202\n",
      "Epoch 399/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2200\n",
      "Epoch 400/500\n",
      "1076/1076 [==============================] - 0s 34us/step - loss: 0.2202\n",
      "Epoch 401/500\n",
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.2199\n",
      "Epoch 402/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2201\n",
      "Epoch 403/500\n",
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.2201\n",
      "Epoch 404/500\n",
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.2200\n",
      "Epoch 405/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2200\n",
      "Epoch 406/500\n",
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.2201\n",
      "Epoch 407/500\n",
      "1076/1076 [==============================] - 0s 33us/step - loss: 0.2201\n",
      "Epoch 408/500\n",
      "1076/1076 [==============================] - 0s 33us/step - loss: 0.2199\n",
      "Epoch 409/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2202\n",
      "Epoch 410/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2199\n",
      "Epoch 411/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2198\n",
      "Epoch 412/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2198\n",
      "Epoch 413/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2200\n",
      "Epoch 414/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2198\n",
      "Epoch 415/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2198\n",
      "Epoch 416/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2199\n",
      "Epoch 417/500\n",
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.2200\n",
      "Epoch 418/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2199\n",
      "Epoch 419/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2199\n",
      "Epoch 420/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2199\n",
      "Epoch 421/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2200\n",
      "Epoch 422/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2197\n",
      "Epoch 423/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2199\n",
      "Epoch 424/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2198\n",
      "Epoch 425/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2197\n",
      "Epoch 426/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2198\n",
      "Epoch 427/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2198\n",
      "Epoch 428/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2197\n",
      "Epoch 429/500\n",
      "1076/1076 [==============================] - 0s 41us/step - loss: 0.2198\n",
      "Epoch 430/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2197\n",
      "Epoch 431/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2197\n",
      "Epoch 432/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2197\n",
      "Epoch 433/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2196\n",
      "Epoch 434/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2195\n",
      "Epoch 435/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2196\n",
      "Epoch 436/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2197\n",
      "Epoch 437/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2198\n",
      "Epoch 438/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2197\n",
      "Epoch 439/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2196\n",
      "Epoch 440/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2198\n",
      "Epoch 441/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2197\n",
      "Epoch 442/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2195\n",
      "Epoch 443/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2198\n",
      "Epoch 444/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2199\n",
      "Epoch 445/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2196\n",
      "Epoch 446/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2196\n",
      "Epoch 447/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2196\n",
      "Epoch 448/500\n",
      "1076/1076 [==============================] - 0s 34us/step - loss: 0.2196\n",
      "Epoch 449/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2197\n",
      "Epoch 450/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2195\n",
      "Epoch 451/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2195\n",
      "Epoch 452/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2194\n",
      "Epoch 453/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2196\n",
      "Epoch 454/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2195\n",
      "Epoch 455/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2196\n",
      "Epoch 456/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2195\n",
      "Epoch 457/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2197\n",
      "Epoch 458/500\n",
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.2196\n",
      "Epoch 459/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2196\n",
      "Epoch 460/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2195\n",
      "Epoch 461/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2197\n",
      "Epoch 462/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2194\n",
      "Epoch 463/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2194\n",
      "Epoch 464/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2194\n",
      "Epoch 465/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2195\n",
      "Epoch 466/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2194\n",
      "Epoch 467/500\n",
      "1076/1076 [==============================] - 0s 32us/step - loss: 0.2197\n",
      "Epoch 468/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2193\n",
      "Epoch 469/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2195\n",
      "Epoch 470/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2194\n",
      "Epoch 471/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2195\n",
      "Epoch 472/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2192\n",
      "Epoch 473/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2194\n",
      "Epoch 474/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2193\n",
      "Epoch 475/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2192\n",
      "Epoch 476/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2194\n",
      "Epoch 477/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2193\n",
      "Epoch 478/500\n",
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.2193\n",
      "Epoch 479/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2193\n",
      "Epoch 480/500\n",
      "1076/1076 [==============================] - 0s 25us/step - loss: 0.2194\n",
      "Epoch 481/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2192\n",
      "Epoch 482/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2192\n",
      "Epoch 483/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2193\n",
      "Epoch 484/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2195\n",
      "Epoch 485/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2195\n",
      "Epoch 486/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2192\n",
      "Epoch 487/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2194\n",
      "Epoch 488/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2193\n",
      "Epoch 489/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2192\n",
      "Epoch 490/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2191\n",
      "Epoch 491/500\n",
      "1076/1076 [==============================] - 0s 26us/step - loss: 0.2192\n",
      "Epoch 492/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2193\n",
      "Epoch 493/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2194\n",
      "Epoch 494/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2194\n",
      "Epoch 495/500\n",
      "1076/1076 [==============================] - 0s 31us/step - loss: 0.2194\n",
      "Epoch 496/500\n",
      "1076/1076 [==============================] - 0s 30us/step - loss: 0.2192\n",
      "Epoch 497/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2192\n",
      "Epoch 498/500\n",
      "1076/1076 [==============================] - 0s 29us/step - loss: 0.2193\n",
      "Epoch 499/500\n",
      "1076/1076 [==============================] - 0s 27us/step - loss: 0.2193\n",
      "Epoch 500/500\n",
      "1076/1076 [==============================] - 0s 28us/step - loss: 0.2194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc5e7a91690>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the autoencoder\n",
    "autoencoder.fit(X_0, X_0, epochs=500, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_X = encoder.predict(X_0)\n",
    "decoded_X = autoencoder.predict(X_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.549894 ,  8.201173 ,  6.5100365,  4.5465355],\n",
       "       [ 4.6182914,  6.4596996,  5.888911 ,  4.7400823],\n",
       "       [10.822655 ,  6.7201233,  5.7032237,  9.387111 ],\n",
       "       ...,\n",
       "       [ 5.1914496,  8.865306 ,  9.464438 ,  6.083227 ],\n",
       "       [ 7.4173737,  7.4129496,  6.1309133,  3.362461 ],\n",
       "       [11.037502 ,  9.183042 ,  8.235109 , 10.911389 ]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01217344, 0.99346644, 0.5123414 , ..., 0.09875391, 0.98932016,\n",
       "        0.1218917 ],\n",
       "       [0.5164573 , 0.9580014 , 0.04775598, ..., 0.49454075, 0.91135323,\n",
       "        0.08655549],\n",
       "       [0.02095297, 0.10780223, 0.99884677, ..., 0.47401494, 0.93418264,\n",
       "        0.2768042 ],\n",
       "       ...,\n",
       "       [0.66328216, 0.9803357 , 0.02693679, ..., 0.92786646, 0.9907569 ,\n",
       "        0.00565449],\n",
       "       [0.01354004, 0.9930161 , 0.18355952, ..., 0.06367269, 0.98509985,\n",
       "        0.0940465 ],\n",
       "       [0.10106573, 0.44928697, 0.9979075 , ..., 0.9099296 , 0.985078  ,\n",
       "        0.09062151]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01217344 0.99346644 0.5123414  0.00775977 0.99670583 0.832999\n",
      " 0.00889827 0.99858946 0.36137763 0.09875391 0.98932016 0.1218917 ]\n",
      "ejer0B       0\n",
      "salud0B      1\n",
      "estres0B     1\n",
      "ejer1B       0\n",
      "salud1B      1\n",
      "estres1B     0\n",
      "ejer5B       0\n",
      "salud5B      1\n",
      "estres5B     1\n",
      "ejer10B      0\n",
      "salud10B     1\n",
      "estres10B    0\n",
      "Name: 1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print decoded_X[0]\n",
    "print X_0.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.- Predicción de Obesidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir entre train y test\n",
    "# Construir un clasificador (perceptron simple) con todos y comparar sus resultados:\n",
    "# Entrenar todos los modelos. 5-fold validation y construir ROC de cada uno. (Ya no nos enfoquemos en los parámetros distintos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for ROC plots\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Libraries for Cross Validation\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Libraries for Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build profile based on excercise, health and stress in the last 0, 1, 5 and 10 years\n",
    "profiles_0_to_10_wO = ndata[[\"ejer0B\", \"salud0B\", \"estres0B\", \"ejer1B\", \"salud1B\", \"estres1B\", \"ejer5B\", \"salud5B\", \"estres5B\", \"ejer10B\", \"salud10B\", \"estres10B\", \"obesity\"]]\n",
    "\n",
    "# Replace \"A\" with 1, and \"B\" with 0, in order to have binary values, and save this in the feature matrix X\n",
    "X_Full = profiles_0_to_10_wO.replace(\"A\", 1).replace(\"B\", 0).replace(\"N\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ejer0B</th>\n",
       "      <th>salud0B</th>\n",
       "      <th>estres0B</th>\n",
       "      <th>ejer1B</th>\n",
       "      <th>salud1B</th>\n",
       "      <th>estres1B</th>\n",
       "      <th>ejer5B</th>\n",
       "      <th>salud5B</th>\n",
       "      <th>estres5B</th>\n",
       "      <th>ejer10B</th>\n",
       "      <th>salud10B</th>\n",
       "      <th>estres10B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dp_folio</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ejer0B  salud0B  estres0B  ejer1B  salud1B  estres1B  ejer5B  \\\n",
       "dp_folio                                                                 \n",
       "1              0        1         1       0        1         0       0   \n",
       "2              0        1         0       0        1         0       1   \n",
       "3              0        0         1       0        0         1       0   \n",
       "4              0        1         0       0        1         1       1   \n",
       "5              0        1         0       0        1         0       0   \n",
       "\n",
       "          salud5B  estres5B  ejer10B  salud10B  estres10B  \n",
       "dp_folio                                                   \n",
       "1               1         1        0         1          0  \n",
       "2               0         1        1         1          0  \n",
       "3               1         1        1         1          1  \n",
       "4               1         0        1         1          0  \n",
       "5               0         0        0         0          1  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Full.iloc[:, :-1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in kf.split(X_Full):\n",
    "    train = []\n",
    "    test = []\n",
    "    for index in train_index:\n",
    "        train.append(X_Full.iloc[index])\n",
    "    train = np.array(train)\n",
    "    for index in test_index:\n",
    "        test.append(X_Full.iloc[index])\n",
    "    test = np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rbm.transform(train[:, :-1])\n",
    "#X_Full.iloc[:, -1:].shape\n",
    "train[:, -1:].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a 5-fold cross validation for several polynomial degrees, and plot the ROCs\n",
    "def run_cv(X, chosen_model, folds, name):\n",
    "    \n",
    "    lr = LogisticRegression(penalty='l1', solver='liblinear', C=1.0)\n",
    "    kf = KFold(n_splits=folds, shuffle=True)\n",
    "    \n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    \n",
    "    j = 0\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        train = []\n",
    "        test = []\n",
    "        for index in train_index:\n",
    "            train.append(X.iloc[index])\n",
    "        train = np.array(train)\n",
    "        for index in test_index:\n",
    "            test.append(X.iloc[index])\n",
    "        test = np.array(test)\n",
    "        lr.fit(chosen_model.transform(train[:, :-1]), train[:, -1:])\n",
    "        #print lr.score(Xv, Yv)\n",
    "        \n",
    "        Yh = lr.predict(Xv)\n",
    "        Yprob = lr.predict_proba(Xv)\n",
    "        \n",
    "        fpr, tpr, thresholds = roc_curve(Yv, Yprob[:,1])\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        aucs.append(roc_auc)\n",
    "        plt.plot(fpr, tpr, lw=1, alpha=0.3, label=\"ROC fold %d (AUC=%0.2f)\" % (j + 1, roc_auc))\n",
    "        j = j + 1\n",
    "        \n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "\n",
    "    plt.plot(mean_fpr, mean_tpr, lw=2, color='b', alpha=0.8, label='Mean ROC (AUC=%0.2f)' % (mean_auc))\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.title(name)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "           label='Random', alpha=.8)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03158819, 0.01143351],\n",
       "       [0.00914015, 0.06884196],\n",
       "       [0.09950659, 0.04133751]])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_rng = np.random.RandomState()\n",
    "weights = 0.1 * np.random.rand(3, 2)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True])"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([0.2, 0.8])\n",
    "y > np.random.random_sample(size=y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm = RBM(12, 10, 0.1, 10, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True, False,  True,  True, False,  True, False,\n",
       "       False,  True, False])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbm.gibbs_sample(X_0.iloc[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for batch in batch_iterator(X_0, batch_size=100):\n",
    "#    print batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([424, 631, 506, 465, 647, 552, 565, 813, 360, 593, 903, 207])"
      ]
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_0.values.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1076, 3)\n",
      "(1076, 3)\n"
     ]
    }
   ],
   "source": [
    "print X_0.values[:, :3].shape\n",
    "print X_0.values[:, 3:6].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_0.iloc[:, 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_visible = 3\n",
    "num_hidden = 10\n",
    "num_historic = 9\n",
    "\n",
    "# Initialize weights and biases\n",
    "W = np.random.normal(scale=0.1, size=(num_visible, num_hidden))\n",
    "a = np.zeros(num_visible)\n",
    "b = np.zeros(num_hidden)\n",
    "        \n",
    "# Initialize autoregreesive parameters\n",
    "A = np.random.normal(scale=0.01, size=(num_visible, num_historic))\n",
    "B = np.random.normal(scale=0.01, size=(num_hidden, num_historic))\n",
    "\n",
    "# Calculate the sigmoid of X \n",
    "def sigmoid(X):\n",
    "    return 1 / (1 + np.exp(-1*X))\n",
    "    \n",
    "# Sample the activations given a certain matrix of probabilities\n",
    "def sample(X):\n",
    "    return X > np.random.random_sample(size=X.shape)\n",
    "\n",
    "# Perform a reconstruction of the input data X\n",
    "def gibbs_sample(X):\n",
    "        \n",
    "    # Separate input vector\n",
    "    V = np.array(X.values[:, :3])\n",
    "    H = np.array(X.values[:, 3:])\n",
    "        \n",
    "    # Positive phase\n",
    "        \n",
    "    # Calculate the contributions from the Historic layer\n",
    "    dinamic_b = b + H.dot(B.T).sum(axis=0)\n",
    "    print b\n",
    "    print dinamic_b\n",
    "        \n",
    "    positive_hidden = sigmoid(V.dot(W) + dinamic_b)\n",
    "    hidden_states = sample(positive_hidden)\n",
    "        \n",
    "    # Negative phase\n",
    "        \n",
    "    #Calculate the contributions from the Historic layer\n",
    "    dinamic_a = a + H.dot(A.T).sum(axis=0)\n",
    "        \n",
    "    negative_visible = sigmoid(hidden_states.dot(W.T) + dinamic_a)\n",
    "    visible_states = sample(negative_visible)\n",
    "    return visible_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gibbs_sample(X_0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
